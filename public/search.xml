<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[jdk8-time笔记]]></title>
    <url>%2Fming%2F9c26946f.html</url>
    <content type="text"><![CDATA[前言在jdk8之前 如果要使用date 的类型 就需要把java.util.Date 之类的类组合起来使用特别是在常用的时间加减、获取特定时间、格式化的时候 都必须要java.util.Calendar 、java.util.TimeZone、java.text.SimpleDateFormat这些类进行封装 或者需要引入第三方工具包来简化操作在jdk8中 time是以jodaTime这个工具包为模板 加入到jdk中的 对于时间的加减、获取特定时间、格式化、变更时区、获取更加精确的时间等等操作变的更加简单 而且是不可变并且线程安全的方法核心类和核心方法说明核心类核心时间对象类名称功能备注Instant获取从1970年开始的时间点类似之前的java.util.Date、通过这个类可以获取到非常精确的时间LocalDate本地年月日Date对象获取当前年月日信息的对象LocalTime本地时分秒Date对象获取当前时分秒信息的对象LocalDateTime本地年月日时分秒Date对象获取当前年月日时分秒信息的对象OffsetTime获取时分秒Date对象并且带上偏移时间信息OffsetDateTime获取带年月日时分秒的Date对象并且带上偏移时间信息ZonedDateTime获取带时区信息的年月日时分秒对象 并且带上时区信息Year年对象YearMonth年月对象MonthDay月日对象Period时间间隔区间对象表示以年、月、日衡量的时长Duration时间间隔区间对象表示以秒和纳秒为基准的时长核心枚举类ChronoUnit 时间单位名称含义备注NANOS纳秒MICROS微秒MILLIS毫秒SECONDS秒MINUTES分HOURS小时HALF_DAYS半天12个小时DAYS一天24个小时WEEKS一周7天MONTHS一个月YEARS一年DECADES十年CENTURIES百年MILLENNIA千年ERAS十亿年FOREVER永远Long.MAX_VALUEDateTimeFormatter 时间格式化格式名称表达式备注ISO_LOCAL_DATEyyyy-MM-ddISO_OFFSET_DATEyyyy-MM-dd+offsetISO_DATE‘yyyy-MM-dd’ or ‘yyyy-MM-dd+offset’ISO_LOCAL_TIMEHH:mm or HH:mm:ssISO_OFFSET_TIMEHH:mm+offset or HH:mm:ss+offsetISO_TIMEHH:mm or HH:mm:ss or HH:mm:ss+offsetISO_LOCAL_DATE_TIMEyyyy-MM-ddTHH:mm:ssISO_OFFSET_DATE_TIMEyyyy-MM-ddTHH:mm:ss+offsetISO_ZONED_DATE_TIMEyyyy-MM-ddTHH:mm:ss+offset[zone]ISO_ORDINAL_DATEyyyy-daysISO_WEEK_DATEyyyy-week-daysISO_INSTANTyyyy-MM-ddTHH:mm:ssZBASIC_ISO_DATEyyyyMMddRFC_1123_DATE_TIME‘Tue, 3 Jun 2008 11:05:30 GMT’核心方法通用核心方法名称功能备注of根据传入的数值转换成相应的时间对象parse根据传入的字符串格式和DateTimeFormatter枚举转换成相应的时间对象get根据时间对象获取相应的时间属性is判断时间的某些属性是否符合方法的意义使用isBefore或者isAfter来判断时间的前后with获取一些特殊时间对象例如这个月第一天之类的plus时间相加可以根据不同的时间单位进行相加minus时间相减可以根据不同的时间单位进行相减to时间类型转换成其他时间类型例如LocalDateTime to 成 LocalTimeat转换成带偏移量、时区之类的时间对象操作format格式化时间类型根据DateTimeFormatter对象来转换特殊方法判断是否是闰年LocalDate#isLeapYear();实际案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289package com.ming;import org.junit.Test;import java.text.SimpleDateFormat;import java.time.*;import java.time.format.DateTimeFormatter;import java.time.temporal.ChronoUnit;import java.time.temporal.TemporalAdjusters;/** * 该包的API提供了大量相关的方法，这些方法一般有一致的方法前缀： * &lt;p&gt; * of：静态工厂方法。 * &lt;p&gt; * parse：静态工厂方法，关注于解析。 * &lt;p&gt; * get：获取某些东西的值。 * &lt;p&gt; * is：检查某些东西的是否是true。 * &lt;p&gt; * with：不可变的setter等价物。 * &lt;p&gt; * plus：加一些量到某个对象。 * &lt;p&gt; * minus：从某个对象减去一些量。 * &lt;p&gt; * to：转换到另一个类型。 * &lt;p&gt; * at：把这个对象与另一个对象组合起来，例如： date.atTime(time)。 * &lt;p&gt; * format：按照合适的格式 格式化成相应的格式的字符串 * &lt;p&gt; * * @author ming * @date 2018-06-30 15:33:10 */public class TestTime &#123; /** * 获取当前时间 * * @author ming * @date 2018-06-30 15:31:33 */ @Test public void testNewDate() &#123; System.out.println(&quot;获取带纳秒的时间:&quot; + Instant.now()); System.out.println(&quot;获取年月日:&quot; + LocalDate.now()); System.out.println(&quot;获取时分秒:&quot; + LocalTime.now()); System.out.println(&quot;获取年月日时分秒:&quot; + LocalDateTime.now()); System.out.println(&quot;获取时分秒带时区:&quot; + OffsetTime.now()); System.out.println(&quot;获取年月日时分秒带时区:&quot; + OffsetDateTime.now()); System.out.println(&quot;获取时分秒带详细时区信息:&quot; + ZonedDateTime.now()); System.out.println(&quot;获取年:&quot; + Year.now()); System.out.println(&quot;获取年月:&quot; + YearMonth.now()); System.out.println(&quot;获取月日:&quot; + MonthDay.now()); &#125; /** * 直接根据参数转换成时间类型 * * @author ming * @date 2018-06-30 15:32:59 */ @Test public void testOf() &#123; System.out.println(&quot;根据秒数获取时间点:&quot; + Instant.ofEpochSecond(1000)); System.out.println(&quot;根据年月日获取年月日时间对象:&quot; + LocalDate.of(2018, 11, 11)); System.out.println(&quot;根据时分秒获取时分秒对象:&quot; + LocalTime.of(11, 11, 11)); System.out.println(&quot;根据年月日时分秒获取年月日时分秒时间对象:&quot; + LocalDateTime.of(2018, 11, 11, 11, 11, 11)); System.out.println(&quot;根据时分秒获取时分秒带时区对象:&quot; + OffsetTime.of(11, 11, 11, 1, ZoneOffset.UTC)); System.out.println(&quot;根据年月日时分秒获取年月日时分秒时间带时区对象:&quot; + OffsetDateTime.of(2018, 11, 11, 11, 11, 11, 11, ZoneOffset.UTC)); System.out.println(&quot;根据年月日时分秒获取年月日时分秒时间带时区对象:&quot; + ZonedDateTime.of(2018, 11, 11, 11, 11, 11, 11, ZoneId.systemDefault())); System.out.println(&quot;根据年数转会成年对象:&quot; + Year.of(2018)); System.out.println(&quot;根据年月数获取年月对象:&quot; + YearMonth.of(2018, 11)); System.out.println(&quot;根据月日数获取月日对象&quot; + MonthDay.of(11, 11)); &#125; /** * 将指定的文本转换成 指定格式的 time对象 * * @author ming * @date 2018-07-02 14:41:23 */ @Test public void testParse() &#123; System.out.println(LocalDateTime.parse(&quot;2011-12-03T10:15:30&quot;, DateTimeFormatter.ISO_LOCAL_DATE_TIME)); //.....略 跟 of差不多 主要是解析字符串成时间相关对象 &#125; /** * 根据时间对象获取 属性 * * @author ming * @date 2018-07-05 16:49:34 */ @Test public void testGet() &#123; System.out.println(&quot;获取当前时间点的时间戳(s)&quot; + Instant.now().getEpochSecond()); System.out.println(LocalDateTime.now().getDayOfWeek()); &#125; /** * 判断某些属性 例如判断时间前后 * * @author ming * @date 2018-07-05 16:50:06 */ @Test public void testIs() &#123; System.out.println(Instant.now().isAfter(Instant.now())); System.out.println(Instant.now().isBefore(Instant.now())); &#125; /** * 获取一些特殊的时间点 * * @author ming * @date 2018-07-05 16:51:36 */ @Test public void testWith() &#123; System.out.println(LocalDateTime.now().with(TemporalAdjusters.firstDayOfMonth())); &#125; /** * 时间相加 * * @author ming * @date 2018-07-05 16:52:49 */ @Test public void testPlus() &#123; System.out.println(Instant.now().plusMillis(999999)); &#125; /** * 时间相减 * * @author ming * @date 2018-07-05 16:52:59 */ @Test public void testMinus() &#123; System.out.println(Instant.now().minusMillis(99999999)); &#125; /** * 将时间对象转换成其他的time对象 * * @author ming * @date 2018-07-05 16:53:16 */ @Test public void testTo() &#123; System.out.println(Instant.now().toEpochMilli()); System.out.println(LocalDateTime.now().toLocalTime()); &#125; /** * 设置时区 * * @author ming * @date 2018-07-05 16:53:29 */ @Test public void testAt() &#123; System.out.println(Instant.now().atOffset(ZoneOffset.UTC)); System.out.println(Instant.now().atZone(ZoneId.systemDefault())); &#125; /** * 时间加减 * ChronoUnit来控制加减的量级 * * @author ming * @date 2018-07-05 16:58:19 * @see ChronoUnit#NANOS 纳秒 * @see ChronoUnit#MICROS 微秒 * @see ChronoUnit#MILLIS 毫秒 * @see ChronoUnit#SECONDS 秒 * @see ChronoUnit#MINUTES 分 * @see ChronoUnit#HOURS 小时 * @see ChronoUnit#HALF_DAYS 半天 12小时 * @see ChronoUnit#DAYS 一天 24小时 * @see ChronoUnit#WEEKS 一周 * @see ChronoUnit#MONTHS 一月 * @see ChronoUnit#YEARS 一年 * @see ChronoUnit#DECADES 十年 * @see ChronoUnit#CENTURIES 百年 * @see ChronoUnit#MILLENNIA 千年 * @see ChronoUnit#ERAS 十亿年 * @see ChronoUnit#FOREVER 永远 Long.MAX_VALUE */ @Test public void testPlusAndMinus() &#123; System.out.println(&quot;加一天&quot; + LocalDateTime.now().plus(1, ChronoUnit.DAYS)); System.out.println(&quot;减一天&quot; + LocalDateTime.now().minus(1, ChronoUnit.DAYS)); &#125; /** * 判断是否是闰年 * * @author ming * @date 2018-07-05 17:09:34 */ @Test public void testLeapYear() &#123; System.out.println(LocalDateTime.now().toLocalDate().isLeapYear()); &#125; /** * 计算两个时间之间的差值 * * @author ming * @date 2018-07-05 17:12:37 */ @Test public void testPeriod() &#123; LocalDateTime localDateTime = LocalDateTime.of(2018, 1, 11, 11, 11, 11); Period period = Period.between(localDateTime.toLocalDate(), LocalDate.now()); System.out.println(&quot;间隔时间:&quot; + period.getYears() + &quot;年&quot; + period.getMonths() + &quot;个月&quot; + period.getDays() + &quot;天&quot;); &#125; /** * 根据formatter枚举格式化时间 * * @author ming * @date 2018-07-05 17:32:32 * @see DateTimeFormatter#ofPattern(String) 自定义格式化格式 * @see DateTimeFormatter#ISO_LOCAL_DATE yyyy-MM-dd * @see DateTimeFormatter#ISO_OFFSET_DATE yyyy-MM-dd+offset * @see DateTimeFormatter#ISO_DATE &apos;yyyy-MM-dd&apos; or &apos;yyyy-MM-dd+offset&apos;. * @see DateTimeFormatter#ISO_LOCAL_TIME HH:mm or HH:mm:ss * @see DateTimeFormatter#ISO_OFFSET_TIME HH:mm+offset or HH:mm:ss+offset * @see DateTimeFormatter#ISO_TIME HH:mm or HH:mm:ss or HH:mm:ss+offset * @see DateTimeFormatter#ISO_LOCAL_DATE_TIME yyyy-MM-ddTHH:mm:ss * @see DateTimeFormatter#ISO_OFFSET_DATE_TIME yyyy-MM-ddTHH:mm:ss+offset * @see DateTimeFormatter#ISO_ZONED_DATE_TIME yyyy-MM-ddTHH:mm:ss+offset[zone] * @see DateTimeFormatter#ISO_ORDINAL_DATE yyyy-days * @see DateTimeFormatter#ISO_WEEK_DATE yyyy-week-days * @see DateTimeFormatter#ISO_INSTANT yyyy-MM-ddTHH:mm:ssZ * @see DateTimeFormatter#BASIC_ISO_DATE yyyyMMdd * @see DateTimeFormatter#RFC_1123_DATE_TIME &apos;Tue, 3 Jun 2008 11:05:30 GMT&apos; */ @Test public void testFormat() &#123; System.out.println(LocalDate.parse(&quot;20181111&quot;, DateTimeFormatter.BASIC_ISO_DATE)); &#125; /** * 将时间 按照格式 格式化成string * * @author ming * @date 2018-07-05 18:23:40 */ @Test public void testFormatString() &#123; System.out.println(LocalDateTime.now().format(DateTimeFormatter.BASIC_ISO_DATE)); &#125; /** * jdk8的time 和jdk8之前的date相关的类型转换 * * @author ming * @date 2018-07-05 18:29:21 */ @Test public void testConverter() &#123; //jdk8 time 转换成Date java.util.Date juDate = java.util.Date.from(Instant.now()); System.out.println(juDate); java.util.Date juDate1 = java.util.Date.from(LocalDateTime.now().toInstant(ZoneOffset.UTC)); System.out.println(juDate1); //Date 转换成jdk8 time java.util.Date date = new java.util.Date(); System.out.println(date.toInstant()); System.out.println(date.toInstant().atZone(ZoneId.systemDefault()).toLocalDate()); &#125;&#125; 总结时间对象的操作在jdk8之前 其实很操蛋 只能通过使用一些自己封装或者 一些组织封装的dateUtils 来操作 有时候一些特殊的时间处理只能单独写工具了 很麻烦现在jdk8 的time包 直接继承了jodaTime的操作 常用操作变成了 不可变而且线程安全的操作了 并且增强了对时间的 偏移和时区的处理 增加了 很多常规的时间处理方法有点蛋疼的是需要考虑 框架之类的对于time包的兼容 特别是jdbc对于time包的对象的支持程度不过 我可以使用Date转换成time的时间对象 在进行操作 然后再转换回去即可]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>jdk8</tag>
        <tag>time</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-lfs使用笔记]]></title>
    <url>%2Fming%2F68597cc5.html</url>
    <content type="text"><![CDATA[前言一直想找个能够存储比较大的文件 而且又能像git一样操作方便快捷开始准备自建svn来达到需求的后来看github的一些文档看到了git lfs (Git Large File Storage)功能干脆了解了一下 顺便记录下这篇笔记 方便以后查阅常见的git 仓库网站都提供 git lfs 存储 例如github笔记中任何命令都在ubuntu中执行过实战安装 git lfsgit lfs支持直接二进制安装、各种包管理工具安装(apt、yum、pacman之类的)1234#安装 git lfs sudo apt install git-lfs # 初始化git lfs sudo git lfs install 配置lfs 管理的文件初始化 lfs的配置文件1git lfs track &quot;&lt;目录&gt;/*&quot; 执行上面的命令会在项目的根目录生成 .gitattributes内容大致如下1&lt;目录&gt;/* filter=lfs diff=lfs merge=lfs -text 添加lfs .gitattributes配置到仓库12sudo git add .gitattributes sudo commit -m &quot;init git lfs config&quot; 添加并且上传大文件将大文件复制到 &lt;目录&gt;123sudo git add &lt;目录&gt;/xxxsudo git commit -m &quot;update xxx&quot;sudo git push 基于git lfs 管理的文件更新会显示成123Git LFS: (1 of 1 files) 9.18 KB / 9.18 KB 对象计数中: 10, 完成.。。。。。。。。 git lfs 卸载 卸载git lfs 1sudo apt --purge remove git-lfs 删除lfs相关的filter 12345678910111213#查看 git的全局配置git config -l #删除和lfs有关的配置## 查看lfs相关的配置git config -l|grep lfs##挨个删除git config --global --unset filter.lfs.cleangit config --global --unset filter.lfs.smudgegit config --global --unset filter.lfs.processgit config --global --unset filter.lfs.requiredgit config --global --unset filter.lfs.required#删除 lfs的仓库地址 按需删除git config --global --unset lfs.https://github.com/xuxianyu/blog.git/info/lfs.access 总结git 的功能越来越吊了 现在能够好好的管理大文件了git只是存储大文件的指针 不负责存储 还是保持了git的高效 易用 但是有能够管理大文件 6的一批]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>git lfs</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码质量监控平台sonar使用笔记]]></title>
    <url>%2Fming%2F8dcd7b21.html</url>
    <content type="text"><![CDATA[前言最近写的代码 太多了 感觉质量有所下降之前本地一直使用 alibaba的code插件 但是没有出团队版本的干脆搞了一个 sonar 检测一波自己的代码质量sonar docker 方式启动12345#安装中文插件的 sonar sudo docker run -d --name sonarqube -p 9000:9000 -p 9092:9092 jiuming/sonar-qube-zh:1.0.0#原版 英文版本的#sudo docker run -d --name sonarqube -p 9000:9000 -p 9092:9092 sonarqube sonar swarm stack配置12345678910111213141516171819version: &apos;3.3&apos;services: sonar: image: jiuming/sonar-qube-zh:1.0.0 ports: - 9000:9000 - 9092:9092 networks: - sonar deploy: replicas: 1 update_config: parallelism: 1 delay: 10s restart_policy: condition: on-failurenetworks: sonar: driver: overlay 打开 http://localhost:9000 默认账户:admin 默认密码:admin sonar qube 官方docker image 安装中文插件方法登录 容器 docker exec -it /bin/sh 执行如下命令ps: sonar 中文插件版本 请按照https://github.com/SonarQubeCommunity/sonar-l10n-zh 文档去下载安装 123#安装 中文插件wget https://github.com/SonarQubeCommunity/sonar-l10n-zh/releases/download/sonar-l10n-zh-plugin-1.21/sonar-l10n-zh-plugin-1.21.jar &amp;&amp; \mv /opt/sonarqube/sonar-l10n-zh-plugin-1.21.jar /opt/sonarqube/extensions/plugins 或者直接使用已经修改好的镜像jiuming/sonar-qube-zh:1.0.0 这个是基于 7.x的sonar maven 添加sonar 插件12345&lt;plugin&gt; &lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt; &lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.4.0.905&lt;/version&gt;&lt;/plugin&gt; 执行 sonar 任务如果在另外一台机器上 加上-Dsonar.host.url=http://ip:port如果使用了密钥 那么需要-Dsonar.login=xxxxxx12345mvn sonar:sonar \ -Dsonar.host.url=http://localhost:9000 #mvn sonar:sonar \# -Dsonar.host.url=http://localhost:9000 \# -Dsonar.login=5cb26b212d30530db172ff6adbfe5d2887698b8c 遇到的问题 报svn认证错误(git认证错误和这个差不多处理方法 )svn: E170001: Authentication required for ‘https://xxxxxx:xxx VisualSVN Server’ -在配置&gt;通用设置&gt;scm&gt;配置svn的username、password或者配置密钥即可 总结大部分检测的规范 都差不多把 本地还是使用alibaba的规范比较和是 直接安装alibaba的code插件也不错sonar 适合团队使用 统一代码风格、减少明显bug]]></content>
      <categories>
        <category>实战</category>
      </categories>
      <tags>
        <tag>代码质量</tag>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[stream集合操作符笔记]]></title>
    <url>%2Fming%2F8486f105.html</url>
    <content type="text"><![CDATA[前言用了这么久的jdk8 的stream集合感觉还是很吊的 特别是作统计计算、集合转化之类的操作虽然有parallelStream 来进行并行计算 但是 不推荐这么去使用 原因如下虽然有并行 但是 parallelStream 的并行数量是按照jvm的核心数量去启动的 这个时候就有点蛋疼了 如果真的需要并行 还是建议使用 threadPool去执行 而不是简单的使用 parallelStreamparallelStream 只是把任务并行了 但是该有的竞争状态 还是有 就是说和你使用线程池是差不多的也是要考虑竞争状态的问题常用操作符列表名称表达式作用备注filtert-&gt;boolean过滤数 据mapt-&gt;r处理数据为每一个数据作map中的操作flatMapt-&gt;r.stream()处理数据并且扁平化为每个数据进行处理 并且会返回一个Stream 处理List&gt; 这种数据的时候可以通过此操作扁平化内部的那个listdistinct-去重并且返回一个新的stream进行数据去重的时候使用 必须是有限的streamsorted-排序并且返回一个新的stream进行stream排序使用 但是这个必须要是有限的streampeekt-&gt;void预览、执行某个不返回的操作 每次返回新的stream 避免消耗stream做一些void的操作使用limit-截断数据截断前x个数据 返回新的streamskip-跳过数据跳过前x个数据 返回新的streamforEacht-&gt;void迭代数据内部迭代 每啥好说的reduce(identity,(x,y)-&gt;result)、((x,y)-&gt;result)计数器做一些复杂的综合统计适合collect(void-&gt;t,r-&gt;void,r-&gt;void)、(collector)收集结果将结果收集返回给其他对象min(o1,o2)-&gt;o1 or o2获取最小的元素必须是有限的元素max(o1,o2)-&gt;o1 or o2获取最大的元素必须是有限的元素count-统计数量统计数量anyMatcht-&gt;boolean匹配只要有一个匹配就返回trueallMatcht-&gt;boolean匹配必须所有元素匹配才返回truenoneMatcht-&gt;boolean匹配必须所有元素不匹配返回truefindFirst-获取第一个元素获取到第一个元素马上返回findAny-获取返回的元素案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254package com.ming;import org.junit.Test;import java.math.BigDecimal;import java.util.ArrayList;import java.util.List;import java.util.Map;import java.util.stream.Collectors;/** * 测试 stream 用法 * * @author ming * @date 2018-06-26 15:45:08 */public class TestStream &#123; /** * 将List&lt;T1&gt; 转换成 Map&lt;id,T1&gt; * * @author ming * @date 2018-06-26 15:54:54 */ @Test public void listToMap() &#123; List&lt;T1&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 3; i++) &#123; list.add(new T1(&quot;id&quot; + i, &quot;name&quot; + i)); &#125; //转换成 id 为key T1为value的map Map&lt;String, T1&gt; map = list.stream().collect(Collectors.toMap(T1::getId, t -&gt; t)); System.out.println(map); //当出现重复值 按照 (oV, nV) -&gt; nV 来选择新的value Map&lt;String, T1&gt; map1 = list.stream().collect(Collectors.toMap(T1::getId, t -&gt; t, (oV, nV) -&gt; nV)); System.out.println(map1); &#125; /** * 获取List&lt;T2&gt; 中的t1的list的合集 * * @author ming * @date 2018-06-26 16:02:35 */ @Test public void ListToFlatList() &#123; List&lt;T2&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 3; i++) &#123; List&lt;T1&gt; t1List = new ArrayList&lt;&gt;(); for (int j = 0; j &lt; 3; j++) &#123; t1List.add(new T1(&quot;id&quot; + i, &quot;name&quot; + i)); &#125; list.add(new T2(&quot;id&quot; + i, &quot;name&quot; + i, t1List)); &#125; List&lt;T1&gt; resultList = list.stream().flatMap(f -&gt; f.getT1List().stream()).collect(Collectors.toList()); System.out.println(resultList); &#125; /** * 将 List&lt;T3&gt;中的num进行累加计数 * * @author ming * @date 2018-06-26 16:06:24 */ @Test public void numReduce() &#123; List&lt;T3&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 3; i++) &#123; list.add(new T3(&quot;id&quot; + i, i)); &#125; Integer countNum = list.stream().map(T3::getNum).reduce(0, (sum, item) -&gt; sum + item); System.out.println(countNum); Integer countNum1 = list.stream().map(T3::getNum).reduce(0, Integer::sum); System.out.println(countNum1); &#125; /** * 将List&lt;T4&gt;按照id 分组并且 累加price * 分两种方案 * 一是先分组 然后map-&gt;reduce * 二直接分组 进行reduce 取巧进行对象的累加 * * @author ming * @date 2018-07-05 09:58:01 */ @Test public void testGroupByAndReduce() &#123; List&lt;T4&gt; list = new ArrayList&lt;&gt;(); list.add(new T4(1, BigDecimal.valueOf(1))); list.add(new T4(1, BigDecimal.valueOf(10))); list.add(new T4(2, BigDecimal.valueOf(1))); list.add(new T4(2, BigDecimal.valueOf(10)));/* //方案一 先分组 然后迭代处理 Map&lt;Integer, BigDecimal&gt; result = new HashMap&lt;&gt;(); list.stream().collect(Collectors.groupingBy(T4::getId, Collectors.toSet())) .forEach((k, v) -&gt; &#123; result.put(k, v.stream().map(T4::getPrice).reduce(BigDecimal.ZERO, BigDecimal::add)); &#125;); System.out.println(result);*//* //方案二 使用取巧的方案 进行对象累加 这样 分组id不变 而且内部的属性也可以按照自己的定义去计算 Map&lt;Integer, T4&gt; result = list.stream() .collect(Collectors.groupingBy(T4::getId , Collectors.reducing(new T4(1, BigDecimal.ZERO), (o, item) -&gt; new T4(o.getId(), o.getPrice().add(item.getPrice()))))); System.out.println(result);*/ &#125;&#125;class T1 &#123; private String id; private String name; public T1() &#123; &#125; public T1(String id, String name) &#123; this.id = id; this.name = name; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125;class T2 &#123; private String id; private String name; private List&lt;T1&gt; t1List; public T2() &#123; &#125; public T2(String id, String name, List&lt;T1&gt; t1List) &#123; this.id = id; this.name = name; this.t1List = t1List; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public List&lt;T1&gt; getT1List() &#123; return t1List; &#125; public void setT1List(List&lt;T1&gt; t1List) &#123; this.t1List = t1List; &#125;&#125;class T3 &#123; private String id; private Integer num; public T3() &#123; &#125; public T3(String id, Integer num) &#123; this.id = id; this.num = num; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public Integer getNum() &#123; return num; &#125; public void setNum(Integer num) &#123; this.num = num; &#125;&#125;class T4 &#123; private Integer id; private BigDecimal price; public T4() &#123; &#125; public T4(Integer id, BigDecimal price) &#123; this.id = id; this.price = price; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public BigDecimal getPrice() &#123; return price; &#125; public void setPrice(BigDecimal price) &#123; this.price = price; &#125; @Override public String toString() &#123; return &quot;T4&#123;&quot; + &quot;id=&quot; + id + &quot;, price=&quot; + price + &apos;&#125;&apos;; &#125;&#125; 总结jdk8 出了很多实用的功能 这个stream只是其中之一 算是常用的 在大多数 集合转换、数据计算类型的操作中 用stream 操作会节省很多代码 而且看起来容易理解 并且性能还稍高一点]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>stream计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[log4j2通过socket发送日志到elk平台]]></title>
    <url>%2Fming%2Fb83d1b10.html</url>
    <content type="text"><![CDATA[前言尝试过很多 spring cloud中日志的方案 好多还是需要 集群的支持但是现在公司还没有那么吊的基础设施 那么 这个时候 就需要 项目能够自己直接通过tcp或者udp直接投递日志到elk或者生成日志文件去采集了但是 项目是使用docker 去部署在swarm或者k8s中 这个时候 生成日志文件 相对来说有点扯淡但是公司的swarm集群又没有办法采集到标准输出和错误输出 那么就需要项目自己去投递日志到elk或者队列中让elk去接受了由于时间较为紧急 直接采用log4j2的socketAppender 来投递日志 使用自定义jsonLayout去格式化 并且适配logstash实践编写jsonLayout123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168package com.ming.log;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import org.apache.commons.lang3.time.DateFormatUtils;import org.apache.logging.log4j.core.Layout;import org.apache.logging.log4j.core.LogEvent;import org.apache.logging.log4j.core.config.Configuration;import org.apache.logging.log4j.core.config.Node;import org.apache.logging.log4j.core.config.plugins.*;import org.apache.logging.log4j.core.layout.AbstractStringLayout;import org.apache.logging.log4j.core.layout.PatternLayout;import org.apache.logging.log4j.core.layout.PatternSelector;import org.apache.logging.log4j.core.pattern.RegexReplacement;import java.io.File;import java.nio.charset.Charset;/** * boss json格式日志 * &lt;p&gt; * 配合elk的配置 使用 * 原作者文章地址: https://blog.csdn.net/lnkToKing/article/details/79563460 * * @author ming * @date 2018-06-22 10:59:56 */@Plugin(name = &quot;MingJsonPatternLayout&quot;, category = Node.CATEGORY, elementType = Layout.ELEMENT_TYPE, printObject = true)public class MingJsonPatternLayout extends AbstractStringLayout &#123; /** * 项目路径 */ private static String PROJECT_PATH; private PatternLayout patternLayout; private String projectName; private String logType; static &#123; PROJECT_PATH = new File(&quot;&quot;).getAbsolutePath(); &#125; private BossJsonPatternLayout(Configuration config, RegexReplacement replace, String eventPattern, PatternSelector patternSelector, Charset charset, boolean alwaysWriteExceptions, boolean noConsoleNoAnsi, String headerPattern, String footerPattern, String projectName, String logType) &#123; super(config, charset, PatternLayout.createSerializer(config, replace, headerPattern, null, patternSelector, alwaysWriteExceptions, noConsoleNoAnsi), PatternLayout.createSerializer(config, replace, footerPattern, null, patternSelector, alwaysWriteExceptions, noConsoleNoAnsi)); this.projectName = projectName; this.logType = logType; this.patternLayout = PatternLayout.newBuilder() .withPattern(eventPattern) .withPatternSelector(patternSelector) .withConfiguration(config) .withRegexReplacement(replace) .withCharset(charset) .withAlwaysWriteExceptions(alwaysWriteExceptions) .withNoConsoleNoAnsi(noConsoleNoAnsi) .withHeader(headerPattern) .withFooter(footerPattern) .build(); &#125; @Override public String toSerializable(LogEvent event) &#123; //在这里处理日志内容 String message = patternLayout.toSerializable(event); String jsonStr = new JsonLoggerInfo(projectName, message, event.getLevel().name(), logType, event.getTimeMillis()).toString(); return jsonStr + &quot;\n&quot;; &#125; @PluginFactory public static BossJsonPatternLayout createLayout( @PluginAttribute(value = &quot;pattern&quot;, defaultString = PatternLayout.DEFAULT_CONVERSION_PATTERN) final String pattern, @PluginElement(&quot;PatternSelector&quot;) final PatternSelector patternSelector, @PluginConfiguration final Configuration config, @PluginElement(&quot;Replace&quot;) final RegexReplacement replace, // LOG4J2-783 use platform default by default, so do not specify defaultString for charset @PluginAttribute(value = &quot;charset&quot;) final Charset charset, @PluginAttribute(value = &quot;alwaysWriteExceptions&quot;, defaultBoolean = true) final boolean alwaysWriteExceptions, @PluginAttribute(value = &quot;noConsoleNoAnsi&quot;, defaultBoolean = false) final boolean noConsoleNoAnsi, @PluginAttribute(&quot;header&quot;) final String headerPattern, @PluginAttribute(&quot;footer&quot;) final String footerPattern, @PluginAttribute(&quot;projectName&quot;) final String projectName, @PluginAttribute(&quot;logType&quot;) final String logType) &#123; return new BossJsonPatternLayout(config, replace, pattern, patternSelector, charset, alwaysWriteExceptions, noConsoleNoAnsi, headerPattern, footerPattern, projectName, logType); &#125; /** * 输出的日志内容 */ public static class JsonLoggerInfo &#123; /** * 项目名 */ private String projectName; /** * 项目目录路径 */ private String projectPath; /** * 日志信息 */ private String message; /** * 日志级别 */ private String level; /** * 日志分类 */ private String logType; /** * 日志时间 */ private String time; public JsonLoggerInfo(String projectName, String message, String level, String logType, long timeMillis) &#123; this.projectName = projectName; this.projectPath = PROJECT_PATH; this.message = message; this.level = level; this.logType = logType; this.time = DateFormatUtils.format(timeMillis, &quot;yyyy-MM-dd HH:mm:ss.SSS&quot;); &#125; public String getProjectName() &#123; return projectName; &#125; public String getProjectPath() &#123; return projectPath; &#125; public String getMessage() &#123; return message; &#125; public String getLevel() &#123; return level; &#125; public String getLogType() &#123; return logType; &#125; public String getTime() &#123; return time; &#125; @Override public String toString() &#123; try &#123; return new ObjectMapper().writeValueAsString(this); &#125; catch (JsonProcessingException e) &#123; e.printStackTrace(); &#125; return null; &#125; &#125;&#125; 配置log4j2.xml123456789101112131415161718192021222324252627&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!-- monitorInterval=&quot;60&quot;表示每60秒配置文件会动态加载一次。在程序运行过程中，如果修改配置文件，程序会随之改变。 --&gt;&lt;configuration status=&quot;warn&quot; monitorInterval=&quot;1&quot;&gt; &lt;!-- 定义通用的属性 --&gt; &lt;Properties&gt; &lt;Property name=&quot;PROJECT_NAME&quot;&gt;ming&lt;/Property&gt; &lt;Property name=&quot;ELK_LOG_PATTERN&quot;&gt;%d&#123;yyyy-MM-dd HH:mm:ss&#125; %-5p thread[%thread] %l %msg %n&lt;/Property&gt; &lt;/Properties&gt; &lt;appenders&gt; &lt;!--测试环境 elk的logstash 入口--&gt; &lt;Socket name=&quot;logstash&quot; host=&quot;&lt;logstash-ip&gt;&quot; port=&quot;&lt;logstash-port&gt;&quot; protocol=&quot;TCP&quot;&gt; &lt;MingJsonPatternLayout pattern=&quot;$&#123;ELK_LOG_PATTERN&#125;&quot; projectName=&quot;$&#123;PROJECT_NAME&#125;&quot; logType=&quot;ming&quot; /&gt; &lt;/Socket&gt; &lt;/appenders&gt; &lt;Loggers&gt; &lt;!-- 配置项目的 日志等级输出 --&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;!-- 通过tcp 传输到logstash--&gt; &lt;appender-ref ref=&quot;logstash&quot;/&gt; &lt;/root&gt; &lt;/Loggers&gt;&lt;/configuration&gt; 替换xml中 为自己的 logstash ip和port 配置 logstash123456789101112131415161718192021222324252627input &#123; #开启远程输入日志服务 tcp &#123; port =&gt; &quot;&lt;logstash-port&gt;&quot; mode =&gt; &quot;server&quot; type =&gt; &quot;log4j2&quot; &#125;&#125;filter &#123; #将日志转成json对象 json &#123; source =&gt; &quot;message&quot; &#125; #将远程客户端的日志时间设置为插入时间，不设置默认为当前系统时间，可能会存在时间误差 date &#123; match =&gt; [&quot;time&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSS&quot;] remove_field =&gt; [&quot;time&quot;] &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;&lt;es-ip&gt;:&lt;es-port&gt;&quot;] index =&gt; &quot;application-%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125; 替换上面配置中的(和log4j2中port保持一致)、、(默认为9200)修改后重启logstash 启动配置 即可 总结其实最终是期望 项目直接输出标准输出和错误输出 由swarm或者k8s直接统一采集 标准输出和错误输出 这样 又避免了生成实际文件 有简化了项目的配置这个直接使用socketAppender投递日志存在缺陷 一是socket比较简略 如果追求高性能需要自己重写 socketAppender 二个 需要logstash的解析和log4j2中的Layout进行匹配否则 输出的日志 一坨翔]]></content>
      <categories>
        <category>实战</category>
      </categories>
      <tags>
        <tag>-log4j2 -socket -elk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[feign切换访问http接口的实现]]></title>
    <url>%2Fming%2F47a3a555.html</url>
    <content type="text"><![CDATA[前言由于feign底层默认使用 jdk的UrlConnection来发送http请求没有连接池之类的 很麻烦 而且bug很多 性能也差经过查看文档和网络上大佬们的博客 发现可以使用 常用的http工具包去替换 如apache的httpClient 、okHttp等Spring Cloud从Brixtion.SR5版本开始支持这种切换feign底层访问http的实现apache httpClient使用apache 的http client 作为feign底层发起http请求的实现增加pom 中feign httpClient依赖123456&lt;!--使用 feign httpclient --&gt;&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;version&gt;8.17.0&lt;/version&gt;&lt;/dependency&gt; 开启 feign的httpClient配置bootstrap.yaml1234# feign 设置feign: httpclient: enabled: true okHttp使用okHttp来作为feign发起请求的实现 增加pom中 feign okHttp的依赖12345&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt; &lt;version&gt;9.7.0&lt;/version&gt;&lt;/dependency&gt; 开启feign的okHttp配置bootstrap.yaml1234# feign 设置feign: okhttp: enabled: true 总结feign 坑还是很多的 这个使用默认的jdk的urlConnection 实现 会出现一些不好理解的异常 而且性能很低切换成httpClient 或者okHttp 可以使用一些优化来增加性能 如连接池之类的至于选择httpClient还是okHttp 看情况吧 没有测试过spring io platform 里面都有 依赖的版本 看项目原本是啥 就用啥]]></content>
      <categories>
        <category>实战</category>
      </categories>
      <tags>
        <tag>-spring cloud - feign - http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作linux系统初始化]]></title>
    <url>%2Fming%2Ffbab8e0.html</url>
    <content type="text"><![CDATA[前言由于强迫症 在工作和学习的时候 必须要用linux 但是linux桌面真的令人为难用了n多版本的linux 什么arch、manjaro、centos系列的、debian系列的等等最后还是觉得ubuntu用来做工作的系统最简单合适 而且少折腾初始化常用软件及工具初始化额外的工具12345678910#安装tmuxsudo apt install tmux#安装 net tools sudo apt install net-tools #安装 traceroutesudo apt install traceroute #安装vimsudo apt install vim #安装google 浏览器sudo apt install chromium-browser 笔记所需的资源笔记所需资源tar包 网易云音乐写代码 不听点音乐 哪里来的干劲12#snap 安装网易云音乐sudo snap install netease-music --devmode --beta 初始化shadowsocks科学上网必备软件 不解释1234567891011121314#安装pipsudo apt install python3-pip#安装sslocalsudo pip3 install shadowsocks#ss 配置echo &apos;&#123; &quot;server&quot;:&quot;地址&quot;, &quot;server_port&quot;:端口, &quot;local_address&quot;:&quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;密码&quot;, &quot;timeout&quot;:3000, &quot;method&quot;:&quot;aes-256-cfb&quot;&#125;&apos; &gt; ss.json 初始化dockerdocker 安装一些 数据库啊之类的软件 还是很方便的 而且docker技术 现在应该是每个工程师必备的技能了 不会简直说不过去1234567891011#安装dockersudo apt install docker docker.io#初始化docker 加速配置sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://o4omo0yw.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 初始化java相关环境12345678#安装sdk man 安装 jvm相关工具 curl -s &quot;https://get.sdkman.io&quot; | bashsource &quot;$HOME/.sdkman/bin/sdkman-init.sh&quot;sdk versionsdk install javasdk install maven sdk install groovy sdk install gradle 初始化wpsubuntu 的liboffice 其实用起来还行就是有点丑 但是有更加好的选择 wps 良心软件 对linux支持很不错就是安装过程略麻烦 后面有时间 可以考虑打包成snap的格式使用 下载wps官方deb包资源tar包中包含 WPS官方网站 ：http://linux.wps.cn/ （区分64位、32位） 安装 libpng12依赖这个依赖是libpng-12.0。不过这个在默认的apt 仓库里没有。所以需要手动下载一下。 资源tar包中包含 或者取官方下载 地址：https://packages.debian.org/zh-cn/wheezy/amd64/libpng12-0/download1sudo dpkg -i libpng12-0_1.2.49-1+deb7u2_amd64.deb 安装wps1sudo dpkg -i &lt;wps&gt;.deb 安装wps 需要的字体资源tar包中包含 下载该字体，解压后将整个wps_symbol_fonts目录拷贝到 /usr/share/fonts/ 目录下12345678910#1.权限设置,执行命令如下 sudo cd /usr/share/fonts/ sudo chmod 755 wps_symbol_fonts sudo cd /usr/share/fonts/wps_symbol_fonts sudo chmod 644 * #2.生成缓存配置信息 sudo cd /usr/share/fonts/wps_symbol_fonts sudo mkfontdir sudo mkfontscale sudo fc-cache 输入法初始化这里使用sogou的deb包来安装 当然也可以根据arch的wiki上 安装sunpinyin或者googlepinyin之类的 安装fcitx输入法框架123456789#安装fcitx 组件 如果不行那么在商店中把所有呆fcitx的软件安装sudo apt install fcitx fcitx-configtool #设置 fcitx相关配置echo &apos;#fcitxexport GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=&quot;@im=fcitx&quot;&apos; &gt;&gt; ~/.xprofile 安装sogou输入法资源tar包中包含 搜狗官方地址: https://pinyin.sogou.com/linux/?r=pinyin 1sudo dpkg -i sogoupinyin_2.2.0.0108_amd64.deb 初始化 oss-browser下载oss-browser压缩包 资源tar包中包含 12# 安装 依赖 sudo apt install libgconf2-4 初始化oss-ftp下载oss-ftp压缩包 资源tar包中包含 12#安装gtk 依赖sudo apt install -y python-gtk2 无法使用脚本初始化的软件开发工具使用idea系列的全家桶安装 toolbox来管理idea系列的全家桶 总结由于我是java开发 我的工作系统肯定最主要就是java以及相关的如maven、gradle、groovy、springbootcli之类的其实把如果真的想折腾linux 建议还是arch 毕竟瞎折腾但是工作还是稳一点 毕竟ubuntu做了这么多年的桌面linux]]></content>
      <categories>
        <category>实战</category>
      </categories>
      <tags>
        <tag>-linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot-mvc的messageConverter处理]]></title>
    <url>%2Fming%2F3174607.html</url>
    <content type="text"><![CDATA[前言最近项目中通过feign调用内部服务和其他系统服务猛然增多在messageConverter这一环节出现n多问题什么xml解析gg什么json 时间格式解析gg什么乱七八糟的骚格式的数据解析gg导致最近一直在作在messageConverter这一块的处理但是feign 的在messageConverter 有一部分是从spring mvc 的在messageConverter列表中获取的所以说总的来说 是要处理spring mvc中在messageConverter的维护spring boot消息转换器配置spring boot 的mvc配置 优先使用 继承WebMvcConfigurerAdapter 方式这样既可以拥有 大量的默认配置 也可以在一定程度上自定义配置重写configureMessageConverters无法保证顺序 也不能清理其他的消息转换器重写这个方法 可以添加自己编写的 messageConverter 到 默认的messageConverter列表中messageConverter如何编写 直接参考 AbstractHttpMessageConverter的下层实现即可这里使用MappingJackson2HttpMessageConverter作为演示12345678910111213141516171819202122232425262728293031323334import com.fasterxml.jackson.databind.ObjectMapper;import com.ming.core.utils.SpringBeanManagerUtils;import org.springframework.context.annotation.Configuration;import org.springframework.http.converter.HttpMessageConverter;import org.springframework.http.converter.json.Jackson2ObjectMapperBuilder;import org.springframework.http.converter.json.MappingJackson2HttpMessageConverter;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.ResourceHandlerRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;import java.text.DateFormat;import java.text.SimpleDateFormat;import java.util.List;/** * 拦截器配置 * * @author ming * @date 2017-08-28 11点 */@Configurationpublic class WebMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; ObjectMapper mapper = SpringBeanManagerUtils.getBeanByType(Jackson2ObjectMapperBuilder.class).build(); // ObjectMapper为了保障线程安全性，里面的配置类都是一个不可变的对象 // 所以这里的setDateFormat的内部原理其实是创建了一个新的配置类 DateFormat dateFormat = mapper.getDateFormat(); mapper.setDateFormat(new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;)); MappingJackson2HttpMessageConverter mappingJsonHttpMessageConverter = new MappingJackson2HttpMessageConverter( mapper); converters.add(mappingJsonHttpMessageConverter); &#125;&#125; 重写extendMessageConverters 可以操控完整的 messageConverter列表 增加、删除等等重写这个方法 方便控制到整个messageConverter 列表的顺序内容这里示例删除所有的 messageConverter列表增加一个简单的简单的FastJsonHttpMessageConverter作为mvc中 唯一一个转换器保证messageConverter顺序 调整list的先后顺序 即可1234567891011121314151617181920212223242526272829import com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter;import com.fasterxml.jackson.databind.ObjectMapper;import com.ming.core.utils.SpringBeanManagerUtils;import org.springframework.context.annotation.Configuration;import org.springframework.http.converter.HttpMessageConverter;import org.springframework.http.converter.json.Jackson2ObjectMapperBuilder;import org.springframework.http.converter.json.MappingJackson2HttpMessageConverter;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.ResourceHandlerRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;import java.text.DateFormat;import java.text.SimpleDateFormat;import java.util.List;/** * 拦截器配置 * * @author ming * @date 2017-08-28 11点 */@Configurationpublic class WebMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void extendMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; FastJsonHttpMessageConverter fastJsonHttpMessageConverter = new FastJsonHttpMessageConverter(); converters.add(fastJsonHttpMessageConverter); &#125; messageConverter 详细规则spring boot 中 所有的消息转换器 需要继承 AbstractHttpMessageConverter抽象类根据其中的方法进行修改 达到转换效果 canRead()判断转换器能不能将请求内容转换成java对象 canWrite()判断转换器能不能将java对象转换成返回内容 read()读取请求内容转换成java对象 write()将返回的java对象写入到返回内容 getSupportedMediaTypes()获取这个转换器支持的MediaType类型 总结控制spring mvc 对于http请求的内容和响应的内容的转换 直接通过重写 messageConverter即可如果只是为了增加特殊情况的处理可以直接重写configureMessageConverters在原有的messageConverter 列表中添加一个接口如果需要完整控制 messageConverter的数量和顺序 那么需要重写extendMessageConverters 来达到控制messageConverter的数量和顺序 feign会从spring mvc的messageConverter的列表中获取对应的messageConverter列表那么这样来说 其实可以通过严格控制spring mvc的messageConverter列表来达到控制feign的messageConverter列表 MediaType解释1spring 中对于http contentType的一些枚举类型 类的全限定名org.springframework.http.MediaType]]></content>
      <categories>
        <category>实战</category>
      </categories>
      <tags>
        <tag>spring boot</tag>
        <tag>mvc</tag>
        <tag>实战</tag>
        <tag>messageConverter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty-传输手段笔记]]></title>
    <url>%2Fming%2F597b09c9.html</url>
    <content type="text"><![CDATA[###传输案例java oio123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.ming;import java.io.IOException;import java.io.OutputStream;import java.net.ServerSocket;import java.net.Socket;import java.nio.charset.Charset;/** * 基于java 阻塞io的 服务端案例 * * @author ming * @date 2018-04-11 14:53 */public class JavaOio &#123; public static void main(String[] args) throws IOException &#123; new JavaOio().Start(20000); &#125; /** * 启动java oio 方法 * * @param port * @author ming * @date 2018-04-11 14:57 */ public void Start(int port) throws IOException &#123; final ServerSocket socket = new ServerSocket(port); for (; ; ) &#123; //接受链接 final Socket clientSocket = socket.accept(); System.out.println(&quot;accept client::&quot; + clientSocket); //建立新线程执行 客户端的请求 new Thread(() -&gt; &#123; OutputStream outputStream = null; try &#123; //获取输出流 outputStream = clientSocket.getOutputStream(); //输出数据 outputStream.write(&quot;hi ming &quot;.getBytes(Charset.forName(&quot;UTF-8&quot;))); //刷新数据 outputStream.flush(); clientSocket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; outputStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; &#125;&#125; java nio1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798package com.ming;import java.io.IOException;import java.net.InetSocketAddress;import java.net.ServerSocket;import java.nio.ByteBuffer;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.util.Set;/** * java 实现nio 模式的服务端 * * @author ming * @date 2018-04-11 15:08 */public class JavaNio &#123; public static void main(String[] args) throws IOException &#123; new JavaNio().Start(20000); &#125; /** * 启动java nio 服务端 * * @param port * @author ming * @date 2018-04-11 15:09 */ public void Start(int port) throws IOException &#123; //打开 server socket channel ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); //设置 为非阻塞队列 serverSocketChannel.configureBlocking(false); //通过socket channel 获取socket ServerSocket socket = serverSocketChannel.socket(); //获取socket 的地址 InetSocketAddress socketAddress = new InetSocketAddress(port); //绑定 socket地址到socket socket.bind(socketAddress); //打开selector Selector selector = Selector.open(); //将socket channel 注册到selector上 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); //返回客户端的消息 final ByteBuffer msg = ByteBuffer.wrap(&quot;hi ming &quot;.getBytes(&quot;UTF-8&quot;)); for (; ; ) &#123; try &#123; //阻塞等待需要处理的新事件 selector.select(); &#125; catch (IOException e) &#123; e.printStackTrace(); break; &#125; //获取所有连接事件的 select key Set&lt;SelectionKey&gt; readyKeys = selector.selectedKeys(); readyKeys.forEach(key -&gt; &#123; try &#123; //检查时间 是否是一个新的 可以被接受的链接 if (key.isAcceptable()) &#123; ServerSocketChannel server = (ServerSocketChannel) key.channel(); SocketChannel client = server.accept(); if (null == client) &#123; return; &#125; client.configureBlocking(false); client.register(selector, SelectionKey.OP_WRITE | SelectionKey.OP_READ, msg.duplicate()); System.out.println(&quot;accept from &quot; + client); &#125; //检查socket是否准备好写数据 if (key.isWritable()) &#123; SocketChannel client = (SocketChannel) key.channel(); ByteBuffer byteBuffer = (ByteBuffer) key.attachment(); while (byteBuffer.hasRemaining()) &#123; if (client.write(byteBuffer) == 0) &#123; break; &#125; &#125; client.close(); &#125; &#125; catch (IOException e) &#123; key.cancel(); try &#123; key.channel().close(); &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; &#125; &#125; ); &#125; &#125;&#125; netty oio12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.ming;import io.netty.bootstrap.ServerBootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.*;import io.netty.channel.oio.OioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.oio.OioServerSocketChannel;import io.netty.util.CharsetUtil;import java.net.InetSocketAddress;/** * netty oio 实现 * * @author ming * @date 2018-04-16 15:56 */public class NettyOio &#123; public static void main(String[] args) throws InterruptedException &#123; new NettyOio().Start(20000); &#125; /** * netty oio bootstrap * * @author ming * @date 2018-04-16 15:56 */ public void Start(int port) throws InterruptedException &#123; final ByteBuf byteBuf = Unpooled.unreleasableBuffer(Unpooled.copiedBuffer(&quot;hi ming &quot;, CharsetUtil.UTF_8)); // 使用 oio 事件循环处理 EventLoopGroup eventLoopGroup = new OioEventLoopGroup(); try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(eventLoopGroup) //使用oio 渠道 .channel(OioServerSocketChannel.class) .localAddress(new InetSocketAddress(port)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(&quot;accept &quot; + ctx); //输出一条信息 关闭 渠道 ctx.writeAndFlush(byteBuf.duplicate()) .addListener(ChannelFutureListener.CLOSE); &#125; &#125;); &#125; &#125;); //绑定服务器 ChannelFuture future = serverBootstrap.bind().sync(); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; eventLoopGroup.shutdownGracefully().sync(); &#125; &#125;&#125; netty nio12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.ming;import io.netty.bootstrap.ServerBootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.*;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.util.CharsetUtil;import java.net.InetSocketAddress;/** * netty nio 实现 * * @author ming * @date 2018-04-16 16:11 */public class NettyNio &#123; public static void main(String[] args) throws InterruptedException &#123; new NettyNio().Start(20000); &#125; /** * 启动 netty nio server * * @author ming * @date 2018-04-16 16:12 */ public void Start(int port) throws InterruptedException &#123; final ByteBuf byteBuf = Unpooled.unreleasableBuffer(Unpooled.copiedBuffer(&quot;hi ming &quot;, CharsetUtil.UTF_8)); //使用 nio 事件循环处理器 EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(eventLoopGroup) //使用nio渠道 .channel(NioServerSocketChannel.class) .localAddress(new InetSocketAddress(port)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(&quot;accept &quot; + ctx); ctx.writeAndFlush(byteBuf.duplicate()).addListener(ChannelFutureListener.CLOSE); &#125; &#125;); &#125; &#125;); ChannelFuture future = serverBootstrap.bind().sync(); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; eventLoopGroup.shutdownGracefully().sync(); &#125; &#125;&#125; epoll123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.ming;import io.netty.bootstrap.ServerBootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.*;import io.netty.channel.epoll.EpollEventLoopGroup;import io.netty.channel.epoll.EpollServerSocketChannel;import io.netty.channel.socket.SocketChannel;import io.netty.util.CharsetUtil;import java.net.InetSocketAddress;/** * 基于linux 的Epoll 非阻塞 方式实现的 io传输 * * @author ming * @date 2018-04-16 17:28 */public class NettyEpoll &#123; public static void main(String[] args) throws InterruptedException &#123; new NettyEpoll().Start(20000); &#125; /** * 启动 基于 epoll 的server * * @author ming * @date 2018-04-16 17:29 */ public void Start(int port) throws InterruptedException &#123; final ByteBuf byteBuf = Unpooled.unreleasableBuffer(Unpooled.copiedBuffer(&quot;hi ming &quot;, CharsetUtil.UTF_8)); //使用epoll EventLoopGroup eventLoopGroup = new EpollEventLoopGroup(); try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(eventLoopGroup) .channel(EpollServerSocketChannel.class) .localAddress(new InetSocketAddress(port)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(&quot;accept&quot; + ctx); ctx.writeAndFlush(byteBuf.duplicate()).addListener(ChannelFutureListener.CLOSE); &#125; &#125;); &#125; &#125;); ChannelFuture future = serverBootstrap.bind().sync(); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; eventLoopGroup.shutdownGracefully().sync(); &#125; &#125;&#125; jvm local1:jvm local server12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.ming.JvmLocal;import io.netty.bootstrap.ServerBootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.*;import io.netty.channel.local.LocalAddress;import io.netty.channel.local.LocalChannel;import io.netty.channel.local.LocalEventLoopGroup;import io.netty.channel.local.LocalServerChannel;import io.netty.util.CharsetUtil;/** * netty 基于jvm内部本地通信 server实现 * * @author ming * @date 2018-04-17 13:45 */public class NettyJvmLocalServer &#123; /** * 启动方法 * * @author ming * @date 2018-04-17 13:50 */ public void Start() throws InterruptedException &#123; final ByteBuf byteBuf = Unpooled.unreleasableBuffer(Unpooled.copiedBuffer(&quot;hi ming &quot;, CharsetUtil.UTF_8)); //注册 local 事件处理器 EventLoopGroup eventLoopGroup = new LocalEventLoopGroup(); try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(eventLoopGroup) //使用Local server channel .channel(LocalServerChannel.class) //使用 local 地址 .localAddress(new LocalAddress(NettyJvmLocal.LOCAL_ADDRESS)) .childHandler(new ChannelInitializer&lt;LocalChannel&gt;() &#123; @Override protected void initChannel(LocalChannel ch) throws Exception &#123; ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(&quot;accept &quot; + ctx); ctx.writeAndFlush(byteBuf).addListener(ChannelFutureListener.CLOSE); &#125; &#125;); &#125; &#125;); ChannelFuture future = serverBootstrap.bind().sync(); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; eventLoopGroup.shutdownGracefully().sync(); &#125; &#125;&#125; 2: jvm local client123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.ming.JvmLocal;import io.netty.bootstrap.Bootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.*;import io.netty.channel.local.LocalAddress;import io.netty.channel.local.LocalChannel;import io.netty.channel.local.LocalEventLoopGroup;import io.netty.util.CharsetUtil;/** * netty 基于jvm内部本地通信 client 实现 * * @author ming * @date 2018-04-17 13:45 */public class NettyJvmLocalClient &#123; /** * 启动方法 * * @author ming * @date 2018-04-17 13:50 */ public void Start() throws InterruptedException &#123; final ByteBuf byteBuf = Unpooled.unreleasableBuffer(Unpooled.copiedBuffer(&quot;hi ming client&quot;, CharsetUtil.UTF_8)); //注册 local 事件处理器 EventLoopGroup eventLoopGroup = new LocalEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.group(eventLoopGroup) //使用 localChannel渠道 .channel(LocalChannel.class) //注册 local模式的地址 .remoteAddress(new LocalAddress(NettyJvmLocal.LOCAL_ADDRESS)) .handler(new ChannelInitializer&lt;LocalChannel&gt;() &#123; @Override protected void initChannel(LocalChannel ch) throws Exception &#123; ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println(&quot;connect &quot; + ctx); ctx.writeAndFlush(byteBuf).addListener(ChannelFutureListener.CLOSE); &#125; &#125;); &#125; &#125;); ChannelFuture future = bootstrap.connect().sync(); future.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; eventLoopGroup.shutdownGracefully().sync(); &#125; &#125;&#125; 3:jvm local demo1234567891011121314151617181920212223242526272829303132333435363738394041package com.ming.JvmLocal;/** * 调用 netty jvm local server 和client 的客户端 * * @author ming * @date 2018-04-17 14:09 */public class NettyJvmLocal &#123; /** * 本地地址 * * @author ming * @date 2018-04-17 14:16 */ public static final String LOCAL_ADDRESS = &quot;ming&quot;; public static void main(String[] args) throws InterruptedException &#123; // 启动 server new Thread(() -&gt; &#123; try &#123; new NettyJvmLocalServer().Start(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); //暂停 线程 1s 等待server 启动完毕 Thread.sleep(1000L); //启动client new Thread(() -&gt; &#123; try &#123; new NettyJvmLocalClient().Start(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; 传输传输是基于channel 的 channel是有顺序的 因为继承 java.lang.ComparablechannelHandler:常规用途 数据格式转换 异常处理 提供channel 状态变更通知 提供channel 注册或者注销 EventLoop中的通知 提供用户自定义事件通知 channel 线程安全 并且保证顺序发送 内置传输手段 名称 包 备注 NIO io.netty.channel.socket.nio 使用java nio Epoll io.netty.channel.epoll 基于jni驱动的epoll()和非阻塞io 只能在linux上支持 比NIO快 并且完全非阻塞 OIO io.netty.channel.socket.oio 使用java net包 阻塞流 Local io.netty.channel.local 直接使用jvm内部管道通信 Embedded io.netty.channel.embedded 测试channelHandler使用的不依赖网络 nio 非阻塞 io基于selector状态变化: 新的channel 已经被接受并且准备就绪 channel 链接完成 channel 有就绪的可供读取的数据 channel 可用于写数据通过java.nio.channels.SelectionKey定义的位 组合成一组应用程序正在请求通知的状态变化集合|名称|描述||:–|:–||OP_ACCEPT|请求接受新链接创建channel获得通知||OP_CONNECT|请求建立第一个链接时候获得通知||OP_READ|请求数据就绪 可从channel 读取时获得通知||OP_WRITE|请求当可以向 channel中写入数据时候 获得通知、| Epoll 基于linux的本地非阻塞传输在linux 2.5.44内核引入的功能 比POSIX 的select poll 更加牛逼不考虑 夸平台 只考虑linux 的话 epoll 直接走起 oio 阻塞io基于jdk java.net包的阻塞io是netty 为了兼容 可能存在的老旧的系统 保留的 oio支持 基于jvm内部的local传输在同一个jvm中运行的客户端和服务端程序直接的异步通信使用这种 可以大幅度提高速度 总结：java实现oio和nio的代码 提供的api 区别比较大oio 不需要selector 直接server socket接受 处理nio 通过selector 协调 分配给相应的 socket 处理netty 实现oio和nio 提供的api 基本相同 就是在使用发送方式和发送渠道时候 需要保持一致例如 使用NioEventLoopGroup 那么传输渠道必须是NioServerChannelSocket使用OioEventLoopGroup那么必须使用OioServerChannelSocket 传输支持的协议 传输类型 支持类型 NIO tcp、udp、sctp、udt Epoll(linux) tcp、udp OIO tcp、udp、sctp、udt sctp 增强版本的tcpudt 增强版本的udp 传输类型选择: 需求类型 推荐传输类型 备注 非阻塞代码、常规套路 nio、或者epoll 如果不考虑跨平台等功能 并且只考虑linux 平台运行 那么 epoll 是肯定的 毕竟是个特殊优化的非阻塞模式 阻塞代码 oio 处理遗留代码的时候选择 同jvm通信 jvm local 在同一个jvm中 进行通信的话 选择jvm local 可以直接省掉网络io的开销 测试ChannelHandler Embedded 只有写单元测试用用 零拷贝:12345零拷贝(zero-copy)是一种目前只有在使用 NIO 和 Epoll 传输时才可使用的特性。它使你可以快速高效地将数据从文件系统移动到网络接口,而不需要将其从内核空间复制到用户空间,其在像 FTP 或者HTTP 这样的协议中可以显著地提升性能。但是,并不是所有的操作系统都支持这一特性。特别地,它对于实现了数据加密或者压缩的文件系统是不可用的——只能传输文件的原始内容。反过来说,传输已被加密的文件则不是问题。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>netty</tag>
        <tag>传输协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-swarm集群搭建]]></title>
    <url>%2Fming%2Fe855d436.html</url>
    <content type="text"><![CDATA[swarm编排吧 首先肯定比不上k8s犀利 但是呢 胜在 使用简单 部署简单docker直接集成 可以使用docker、docker-compose 原生api我个人认为 没有十来台服务器 部署k8s集群 完全是浪费 毕竟k8s 是非常需要 master 高可用的 服务器少了 部署k8s 浪费资源太多了 so 开发环境直接使用 swarm 来编排docker环境:centos 7.xdocker 版本新点 至少 要集成swarm 模块1： 安装基本docker 环境centos-docker环境搭建使用 如下命令测试是否有swarm模块1docker swarm swarm 默认集成到docker中的 2：基于 docker swarm 配置portainer管理页面123456789101112131415161718# 初始化 swarm 集群 sudo docker swarm init # 创建 portainer 挂载目录sudo mkdir -p /opt/portainer# 以 swarm service 建立 portainer 管理 sudo docker service create \--name portainer \--publish 9000:9000 \--replicas=1 \--constraint &apos;node.role == manager&apos; \--mount type=bind,src=//var/run/docker.sock,dst=/var/run/docker.sock \--mount type=bind,src=//opt/portainer,dst=/data \portainer/portainer \-H unix:///var/run/docker.sock http://:9000 访问即可 3:遇到问题参考地址:http://blog.51cto.com/zpf666/19080671:无法通过服务名访问服务需要建立一个overlay网络swarm上默认已有一个名为ingress的overlay 网络, 可以直接使用也可以从新建立 2:遗忘swarm 添加节点时候的token12sudo docker swarm join-token mastersudo docker swarm jon-token worker 总结swarm 一两台服务器的docker编排 还是很轻松的 而且也不需要 k8s那么麻烦虽然k8s 一统天下 但是个人电脑用个swarm管理管理 还是简简单单 轻轻松松的]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux</tag>
        <tag>swarm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos-docker环境搭建]]></title>
    <url>%2Fming%2Faef2102a.html</url>
    <content type="text"><![CDATA[环境:centos 7.xdocker1:安装docker12345678910#安装 一些组件sudo yum install -y yum-utils device-mapper-persistent-data lvm2# 拉取阿里云中 docker-ce的reposudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 刷新 yum 缓存sudo yum makecache fast# 安装 docker-cesudo yum -y install docker-ce# 启动 docker servicesudo systemctl start docker 2：配置阿里云加速12345678910sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://7vm1yv9c.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker# 设置开机自启动sudo systemctl enable docker 3:关闭SELinux firewalld12345678910111213Redhat系列使用了SELinux来增强安全，关闭的办法为：1. 永久有效修改 vi /etc/selinux/config 文件中的 SELINUX=&quot;&quot; 为 disabled ，然后重启。2. 即时生效#setenforce 0#3:查看是否关闭sestatus#### 关闭 firewalldsystemctl stop firewalld### 禁止开机自动启动firewalldsystemctl disable firewalld]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s集群日志采集方案选择]]></title>
    <url>%2Fming%2Fd8147fe2.html</url>
    <content type="text"><![CDATA[日志采集方案常规的日志采集总的来说 分为 收集–》处理–》存储–》查看比较出名 并且用的比较多的 应该是elk模式常用组合应该是如下 三种 至于还有其他采集工具 其实都差不多elk: es + kibana + logstash最经典的做法 es+kibana 做 存储 查询 logstash 做日志采集和管道处理缺陷是logstash 功能复杂 除非是搭建所有项目的统一日志 这种同集群的 logstash并不是特别好用efk: es +kibana + filebeat最直接的做法 es+kibana 做存储查询 filebeat采集数据 直接发送到es上 不经过logstash管道处理elkf: es+ kibana+logstash +filebeat功能最齐全的做法 es+kibana做存储查询 logstash做管道处理 filebeat 做采集为何选择filebeat做采集 因为短小精悍 go语言开发 占用资源少具体的可以查询官网:https://www.elastic.co/cn/ 随便搭配 总归就是一个收集处理存储查看的过程k8s集群配置日志采集方案1：在node上配置一个filebeat 所有的镜像的日志 按照一定规则映射到filebeat采集的目录下这种 配置简单 不过需要制定一套 项目的日志记录规范2:使用k8s的daemon set 为每个pod 绑定一个filebeat 利用的是k8s的pod 共享数据卷的套路这种较为消耗资源 一个filebeat20m内存 那么 100个容器 就是 2000m内存了 有点得不偿失好处就是如果资源足够可以很容易的进行动态伸缩容器 新开node不需要配置 只要有kubelet就行个人更加倾向 efk 因为 filebeat 非常适合 通过daemon set 去绑定到k8s pod中并且不是很需要 logstashk8s集群+efk日志采集 实践0:启动 es+kibana通过镜像去启动 方便点 真实环境 请尽量采用 直接安装在服务器上 因为要映射数据文件乱七八糟的 不是很方便nshou/elasticsearch-kibana latest版本 es=6.2.1 kibana=6.2.11sudo docker run -d -p 9200:9200 -p 5601:5601 --name es-kibana-test nshou/elasticsearch-kibana 直接在服务器上安装 请参考官网即可 1:搭建k8s实验环境使用minikube 快速搭建一个k8s实验环境minikube快速搭建k8s测试环境 2：建立并且修改deployment1234``` ###### 3：建立并且调整daemon set ```$xslt 4：建立并且调整 service####]]></content>
      <categories>
        <category>使用</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
        <tag>日志采集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rancher搭建k8s集群-国内加速]]></title>
    <url>%2Fming%2Fb52bf00b.html</url>
    <content type="text"><![CDATA[通过rancher部署k8s如果不考虑gfw 是非常简单的 但是在国内部署 不得不考虑gfw的问题默认有个 组件镜像是从 google上下载的 所以需要修改一些参数配置提供国内加速环境:centos 7.xrancher：1.6.xdocker 支持rancher:1.6.x的版本即可1： 安装基本docker 环境centos-docker环境搭建2：启动rancher server1234# 建立存放 rancher 相关数据文件存储mkdir -p /root/rancher# 启动 rancher server 容器 sudo docker run -d -v /root/rancher:/var/lib/mysql --restart=unless-stopped -p 40000:8080 --name rancher-server rancher/server:stable 3:登陆rancher访问 http://:40000 4:自定义 k8s模板 使用 国内可用镜像按照 https://www.cnrancher.com/kubernetes-installation/ 文档进行修改注意：文档中标记红线的值 必须如下 设置 否则 无法启动 共四个值需要修改Private Registry for Add-Ons and Pod Infra Container Image = registry.cn-shenzhen.aliyuncs.comImage namespace for Add-Ons and Pod Infra Container Image = rancher_cnImage namespace for kubernetes-helm Image = rancher_cnPod Infra Container Image = rancher_cn/pause-amd64:3.0 5:创建 环境根据刚刚创建的 k8s模板创建环境 即可 总结部署rancher 很简单 注意是有时候是gfw导致组件无法创建 略坑rancher 部署的k8s集群 有两个dns 一个是k8s中 kube-system 中的dns服务 一个是rancher的network 应用 两个都可以用部署rancher 如果资源相对充足 rancher server和rancher agent分开部署在rancher1.x版本中 rancher部署的k8s集群 是在rancher agent 上部署的 扩展起来很困难而且由于 rancher也提供一套cni网络 这样就导致 k8s的网络和rancher的网络复合起来 显得较为复杂 不好处理]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
        <tag>rancher</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springCloudConfigServer的git、svn版本实现及相关实战案例]]></title>
    <url>%2Fming%2F7ced3fa5.html</url>
    <content type="text"><![CDATA[配置中心在分布式 环境中 配置中心是必不可少的一个组件 不管是国内的 disconf 、Apollo之类 还是spring cloud的config server 都是一个套路将配置统一管理 通过namespace、项目名称之类的 进行区分 加入一些操作审计、配置加密之类的功能 有的是基于数据库、有的是基于文件+版本管理由于技术栈和个人习惯 我个人更加喜欢spring 社区的config server 基于文件和版本管理来实现的配置 可以很方便的管理配置的版本和内容个人觉得 在整个集群中管踏马是什么配置 都可以丢进配置中心进行统一管理 例如app的打包配置、集群的参数配置等等 反正只要是配置都可以放进去spring cloud config server这个是属于spring cloud 项目中的一个组件它基于 svn或者git 去管理配置文件 提供各种各样的配置文件的管理 、提供敏感配置加密(对称、非对称都支持)、访问控制等等java中使用 config server client 客户端读取配置直接提供不停机更新配置功能 等等非java项目 可以通过http接口获取配置需要技能git、svn熟练java相关技能熟练 例如maven之类的docker 熟练 涉及到项目打包成docker imagegit版本git版本就简单了 毕竟git好用 大部分书籍、博客都是介绍git版本的1：新建maven java项目pom配置12345678910111213141516171819202122232425262728&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;parent&lt;/artifactId&gt; &lt;groupId&gt;ming&lt;/groupId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;configServer&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt;--&gt; &lt;/dependencies&gt;&lt;/project&gt; 2:application.yml配置1234567891011121314151617181920spring: application: name: config cloud: config: server: git: uri: &quot;https://github.com/xuxianyu/springcloud.git&quot; #仓库的搜索路径 这里可以指定 git的目录 config/spring-repo/&#123;目录&#125; 这种方式就可以按照项目区分配置目录了 search-paths: config/spring-repo/ming#config server 访问账户密码security: user: name: ming password: ming#设定 对称加密密钥#encrypt:# key: ming #username: 18120580001@163.com #password: 3：配置启动类123456789101112131415161718192021222324package com.ming;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.config.server.EnableConfigServer;/** * config server 启动类 * * @author ming * @date 2017-10-30 11:18 *///开启config 服务@EnableConfigServer//注册到注册中心@EnableDiscoveryClient@SpringBootApplicationpublic class StartConfig &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(StartConfig.class).web(true).run(args); &#125;&#125; 4：访问配置在git仓库中建立ming/config-dev.yaml master分支1name: ming 浏览器访问 http://localhost:8888/master/config-dev.yaml 实例地址: https://github.com/xuxianyu/springcloud/tree/master/configServer svn版本1:新建maven java项目pom配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.onlyedu&lt;/groupId&gt; &lt;artifactId&gt;configServer&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.1.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;!-- spring cloud version --&gt; &lt;spring.cloud.version&gt;Camden.SR5&lt;/spring.cloud.version&gt; &lt;!-- svnkit version --&gt; &lt;svnkit.version&gt;1.9.0&lt;/svnkit.version&gt; &lt;/properties&gt; &lt;!--仓库--&gt; &lt;repositories&gt; &lt;!--aliyun repository--&gt; &lt;repository&gt; &lt;id&gt;aliyun&lt;/id&gt; &lt;name&gt;aliyun nexus repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;dependencies&gt; &lt;!-- spring cloud config --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring cloud config svn repository --&gt; &lt;dependency&gt; &lt;groupId&gt;org.tmatesoft.svnkit&lt;/groupId&gt; &lt;artifactId&gt;svnkit&lt;/artifactId&gt; &lt;version&gt;$&#123;svnkit.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring boot security 访问控制 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;!--spring cloud parent pom--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--构建插件--&gt; &lt;build&gt; &lt;plugins&gt; &lt;!--docker 插件--&gt; &lt;!--&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.docker.version&#125;&lt;/version&gt; &lt;configuration&gt; &amp;lt;!&amp;ndash;镜像名称&amp;ndash;&amp;gt; &lt;imageName&gt;$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125;&lt;/imageName&gt; &amp;lt;!&amp;ndash;docker file位置&amp;ndash;&amp;gt; &lt;dockerDirectory&gt;src/main/docker&lt;/dockerDirectory&gt; &lt;resources&gt; &lt;resource&gt; &amp;lt;!&amp;ndash; 编译jar路径 &amp;ndash;&amp;gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &amp;lt;!&amp;ndash;编译jar 所在文件夹&amp;ndash;&amp;gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &amp;lt;!&amp;ndash;编译的jar 名称&amp;ndash;&amp;gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt;--&gt; &lt;!--指定编译jdk版本 默认为1.5--&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- 解决资源文件的编码问题 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2：配置 application.yml12345678910111213141516171819202122232425262728293031323334# default portserver: port: 8888spring: cloud: config: server: svn: # svn 配置仓库地址 uri: https://repo.xujiuming.com/svn/ming/trunk/confDir # svn 访问账户 username: ming # svn 访问密码 password: mingpwd # 这个设置是访问时候没有带label默认的label 用处不大 default-label: trunk # 使用 svn 作仓库 必须要填写 profiles: active: subversion# 访问控制security: user: name: ming password: mingencrypt: # rsa 密钥 设定 使用resources 下的 configServer.keystore key-store: location: configServer.keystore alias: configServer # 生成 密钥时候的密码 password: ming2 # 生成 密钥时候的签名 secret: ming1 3：生成敏感数据密钥包必须替换jce相关jar 或者直接使用我选择的docker 镜像 那个镜像是替换好jce相关jar包的 因为 config server 使用的是aes256 加密 所以必须替换jce 相关jar就算使用rsa 加密方式 也是需要jce相关jar 的 因为他还是用的aes256加密rsa 加密方式配置 生成 rsa 密钥包 直接到控制台执行即可 使用的是jdk 的keytool 1234567configserver rsa 秘钥生成命令 有效时间 10000天keytool -genkeypair -alias configServer -keyalg RSA \-dname &quot;CN=ming,OU=ming,O=ming,L=ming,ST=ming,C=ming&quot; \-keypass ming1 \-keystore configServer.keystore \-storepass ming2 \-validity 10000 \ 配置中使用 数据加密 使用加密字符串替换 原始字符串1234567访问 configServer的 &#123;[/encrypt],methods=[POST]&#125; 接口 参数为要加密的字符串 返回加密字符串例如 加密前 字符串a 通过接口获取加密后字符串 b在a配置的地方 使用 &#123;cipher&#125;b 替换a 即可 加密前passwd=a加密后passwd=&#123;cipher&#125;b 将生成的configServer.keystore 文件复制到resources目录中去4:配置spring boot 项目启动类12345678910111213141516171819package com.ming;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.config.server.EnableConfigServer;/** config server start class * * @author ming * @date 2017-12-06 10:08 * */@EnableConfigServer@SpringBootApplicationpublic class StartConfigServer &#123; public static void main(String[] args) &#123; SpringApplication.run(StartConfigServer.class,args); &#125;&#125; 5:配置dockerfile1234567891011FROM docker.io/fabric8/java-alpine-openjdk8-jdkMAINTAINER &quot;ming&quot;# create workspaceRUN mkdir /workspace# copy app.jarCOPY target/configServer-1.0-SNAPSHOT.jar /workspace# open portEXPOSE 8888# 运行jarCMD java -jar /workspace/configServer-1.0-SNAPSHOT.jar 6:打包成docker12mvn package sudo docker build -t config-server-ming:1.0.0 . 7：启动容器1sudo docker run -d -p 8888:8888 --name mingconfigserver config-server-ming:1.0.0 8：访问配置在svn仓库中建立ming/config-dev.yaml1name: ming 浏览器访问 http://localhost:8888/ming/config-dev.yaml 实例地址: https://github.com/xuxianyu/springcloud/tree/master/configServerSvn 访问配置文件url 详细解释参数解释:1:git在git仓库中目录 配置文件的目录/配置文件前缀-配置文件后缀.配置文件类型 如在svn仓库目录下的ming/app-dev.yaml master分支 那么 master就是label app就是name profiles就是dev path就是app-dev.yaml git配置可以通过配置 区分文件夹 不是跟svn一样 把文件夹当作label 1234name: 前缀profiles: 后缀label: 分支path： 完整文件名 2:svn在svn仓库中目录 配置文件的目录/配置文件前缀-配置文件后缀.配置文件类型 如在svn仓库目录下的ming/app-dev.yaml 那么 ming就是label app就是name profiles就是dev path就是app-dev.yaml1234name: 配置文件前缀profiles: 配置文件后缀label: 文件夹目录名称path:配置文件全称包含.后面的类型 访问properties、yaml、json格式 访问方式/{name}/{profiles:.*[^-].*}/{name}/{profiles}/{label:.*}/{name}-{profiles}.properties/{label}/{name}/{profiles}.properties/{name}-{profiles}.json/{label}/{name}-{profiles}.json 访问非 java适配的配置文件 只能以文本模式 读取参考博客地址:http://www.voidcn.com/article/p-yhrhfyla-bqr.html/{name}/{profile}/{label}/{path} 实际案例1：java web项目启动拉取配置中心配置在spring cloud 接入config server的项目中bootstrap.yml 优先级最高 在一启动就会加载 在这里配置 链接config server的配置、链接配置中心的配置 等等application.yml是在config client 拉取配置后才加载 如果在这里配置链接config server配置不会生效 增加pom依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 配置bootstrap.yml12345678910111213141516171819202122232425262728293031spring: cloud: config: # 拉取后缀为dev的配置 profile: dev # 拉取master分支的配置 label: master username: ming password: ming uri: &quot;http://localhost:8888&quot; #开启 以服务方式访问配置中心 #discovery: # enabled: true # service-id: CONFIG #开启预检 #fail-fast: true #重试参数 #retry: #重试间隔 #multiplier: 2000 #下一个间隔 #initial-interval: 2000 #最大间隔 #max-interval: 5000 #最大重试次数 #max-attempts: 3 application: # 拉取前缀为ming的配置 name: ming #fail-fast: true 在配置仓库配置相关配置然后启动项目 打个断点 查询spring env bean 即可查看是否加载到配置中心的配置 2: docker启动 时候拉取容器环境配置思路: 重写镜像的 启动命令 在启动的时候拉取配置中心的配置覆盖容器中的配置文件如果配置中心设置的账户密码 需要获取配置中心 访问接口的token浏览器访问一下配置输入账户密码 抓http请求包 报头中有个 Authorization: Basic xxxxxxx 报头使用curl命令获取配置1curl -H &quot;Authorization: Basic xxxxxxx&quot; http://configServer地址//&#123;name&#125;/&#123;profile&#125;/&#123;label&#125;/&#123;path&#125; &gt; /etc/nginx/conf.d/default.conf 调整dockerfile中的默认启动命令CMD 或者ENTRYPOINT 一定要用&amp;&amp; 不能使用&amp; 这个是并行执行 但是大部分容器是需要先加载完毕配置才能启动的1ENTRYPOINT curl -H &quot;Authorization: Basic xxxxxxx&quot; http://configServer地址//&#123;name&#125;/&#123;profile&#125;/&#123;label&#125;/&#123;path&#125; &gt; /etc/nginx/conf.d/default.conf &amp;&amp; run.sh 总结:总的来说 spring cloud config server基本满足需求如果需要什么配置操作审计 完全可以在svn或者git操作上进行如果是java项目可以通过引入 spring cloud config client jar来使用非java项目 可以通过http接口获取配置信息关于高可用 就是多启动几台config server 注册到注册中心就行 客户端通过注册中心去访问http接口]]></content>
      <categories>
        <category>实例</category>
      </categories>
      <tags>
        <tag>实用</tag>
        <tag>spring cloud</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k8s集群暴露集群服务的各种方案的优劣]]></title>
    <url>%2Fming%2Fc013ae57.html</url>
    <content type="text"><![CDATA[参考文档:http://blog.csdn.net/liyingke112/article/details/76022267https://www.kubernetes.org.cn/1885.htmlk8s集群暴露服务 常见的就四种1: clusterIpclusterIp就是service的ip k8s在创建service的时候 会给service一个ip 集群内部可以通过这个clusterIp访问相应的service这种方式呢稍微麻烦 最终要暴露外部服务 还是要建立nginx之类的反向代理 然后再暴露出集群实践:这个需要在集群中的一个节点去访问登陆集群中同一个命名空间的容器 直接ping 对应的clusterIp 或者直接telnet 访问clusterIp:clusterPort clusterPort就是service配置中的targetPort12ping &lt;clusterIp&gt;telnet &lt;clusterIp&gt; &lt;targetPort&gt; 2:nodePortnode在k8s中表示是一台物理机或者虚拟机 nodePort是k8s集群在创建service的时候 会在每个node上暴露出nodePort 外部可以直接通过nodeIp:nodePort访问 服务这种方式 很容易实现 但是不太符合实际生产环境 因为在新开服务或者新增node的时候需要增加配置 会导致依赖一个外部的负载均衡器去分发各个node配置太多了 不利于维护 nodePort模式依旧存在clusterIp 依旧可以通过第一种方式访问实例:配置 service1kubectl edit service &lt;serviceName&gt; type 为NodePort 拥有port、targetPort、nodePort这个如果不是这个配置 可以修改1234567891011121314。。。spec: clusterIP: 10.103.100.161 externalTrafficPolicy: Cluster ports: - nodePort: 30115 port: 8080 protocol: TCP targetPort: 8080 selector: run: hello-node sessionAffinity: None type: NodePort 。。。 直接ping node的ip 或者直接通过telnet 访问nodeIp:nodePort12ping &lt;nodeIp&gt;telnet &lt;nodeIp&gt; &lt;nodePort&gt; 3:loadbalance必须要在支持 这个模式的云平台上才能用 基于nodePort 只不过 这个模式会请求底层云平台的服务创建一个负载均衡器 来访问这种方式 要看各个云平台的支持 例如阿里云就有点坑爹 每个服务都为你申请一个负载均衡器 贵的很 而且还不如直接用nodePort模式然后自己做负载均衡来的直接 简单 这个 哎 懒的尝试没必要 直接请求云平台的负载均衡服务 略坑 太贵 而且不好管理 建议就算了把 有用这个 不如直接使用nodePort 或者ic 或者自己维护nginx方式来做 4:ingress这个是k8s 算是比较官方的一种解决方案了大神也总结的有文档http://blog.csdn.net/liyingke112/article/details/77066814https://www.kubernetes.org.cn/1885.htmlhttps://mritd.me/2017/03/04/how-to-use-nginx-ingress/#%E4%B8%80ingress-%E4%BB%8B%E7%BB%8Dhttps://mritd.me/2016/12/06/try-traefik-on-kubernetes/比较麻烦 只有当集群大了之后 可以 小集群 需求并不大主要就是 ingress 和ingress controller 、代理负载均衡器(例如nginx 之类的)ingress : 配置规则的地方ingress controller :将ingress中配置的规则 生成相应的配置 例如生成nginx的配置负载均衡器: 例如nginx 具体分发流量的软件 ingress controller 通过ingress获取配置 自动刷新nginx中的配置 5：自定义方案nginx+config server用nginx 直接分发service 配置通过config server 进行刷新其实跟ingress差不多 只不过 由开发去维护 这个代理作用的nginx的pod 而不是直接由k8s直接管理 因为懂nginx配置的人多 懂ingress的人并不多这个方案缺点就是要配置很多不同的service的配置 比较麻烦 只能手动配置 但是 这个配合loadbalancer 就可以很不错的做到代理分发 并且屏蔽底层serviceIp变化最后通过暴露nginx的nodePort去给外部服务访问1:按照http://docs.kubernetes.org.cn/126.html 这个教程搭建 minikube 的hello-node 服务 这个时候可以通过nodePort 访问hello-node服务的2:通过如下配置启动一个nginx-all deployment123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990&#123; &quot;kind&quot;: &quot;Deployment&quot;, &quot;apiVersion&quot;: &quot;extensions/v1beta1&quot;, &quot;metadata&quot;: &#123; &quot;name&quot;: &quot;nginx-all&quot;, &quot;namespace&quot;: &quot;default&quot;, &quot;selfLink&quot;: &quot;/apis/extensions/v1beta1/namespaces/default/deployments/nginx-all&quot;, &quot;uid&quot;: &quot;050be590-1b6d-11e8-a211-080027fc8712&quot;, &quot;resourceVersion&quot;: &quot;45623&quot;, &quot;generation&quot;: 1, &quot;creationTimestamp&quot;: &quot;2018-02-27T03:19:28Z&quot;, &quot;labels&quot;: &#123; &quot;k8s-app&quot;: &quot;nginx-all&quot; &#125;, &quot;annotations&quot;: &#123; &quot;deployment.kubernetes.io/revision&quot;: &quot;1&quot; &#125; &#125;, &quot;spec&quot;: &#123; &quot;replicas&quot;: 1, &quot;selector&quot;: &#123; &quot;matchLabels&quot;: &#123; &quot;k8s-app&quot;: &quot;nginx-all&quot; &#125; &#125;, &quot;template&quot;: &#123; &quot;metadata&quot;: &#123; &quot;name&quot;: &quot;nginx-all&quot;, &quot;creationTimestamp&quot;: null, &quot;labels&quot;: &#123; &quot;k8s-app&quot;: &quot;nginx-all&quot; &#125; &#125;, &quot;spec&quot;: &#123; &quot;containers&quot;: [ &#123; &quot;name&quot;: &quot;nginx-all&quot;, &quot;image&quot;: &quot;nginx:1.13.8-alpine&quot;, &quot;resources&quot;: &#123;&#125;, &quot;terminationMessagePath&quot;: &quot;/dev/termination-log&quot;, &quot;terminationMessagePolicy&quot;: &quot;File&quot;, &quot;imagePullPolicy&quot;: &quot;IfNotPresent&quot;, &quot;securityContext&quot;: &#123; &quot;privileged&quot;: false &#125; &#125; ], &quot;restartPolicy&quot;: &quot;Always&quot;, &quot;terminationGracePeriodSeconds&quot;: 30, &quot;dnsPolicy&quot;: &quot;ClusterFirst&quot;, &quot;securityContext&quot;: &#123;&#125;, &quot;schedulerName&quot;: &quot;default-scheduler&quot; &#125; &#125;, &quot;strategy&quot;: &#123; &quot;type&quot;: &quot;RollingUpdate&quot;, &quot;rollingUpdate&quot;: &#123; &quot;maxUnavailable&quot;: &quot;25%&quot;, &quot;maxSurge&quot;: &quot;25%&quot; &#125; &#125;, &quot;revisionHistoryLimit&quot;: 10, &quot;progressDeadlineSeconds&quot;: 600 &#125;, &quot;status&quot;: &#123; &quot;observedGeneration&quot;: 1, &quot;replicas&quot;: 1, &quot;updatedReplicas&quot;: 1, &quot;readyReplicas&quot;: 1, &quot;availableReplicas&quot;: 1, &quot;conditions&quot;: [ &#123; &quot;type&quot;: &quot;Available&quot;, &quot;status&quot;: &quot;True&quot;, &quot;lastUpdateTime&quot;: &quot;2018-02-27T03:19:29Z&quot;, &quot;lastTransitionTime&quot;: &quot;2018-02-27T03:19:29Z&quot;, &quot;reason&quot;: &quot;MinimumReplicasAvailable&quot;, &quot;message&quot;: &quot;Deployment has minimum availability.&quot; &#125;, &#123; &quot;type&quot;: &quot;Progressing&quot;, &quot;status&quot;: &quot;True&quot;, &quot;lastUpdateTime&quot;: &quot;2018-02-27T03:19:29Z&quot;, &quot;lastTransitionTime&quot;: &quot;2018-02-27T03:19:28Z&quot;, &quot;reason&quot;: &quot;NewReplicaSetAvailable&quot;, &quot;message&quot;: &quot;ReplicaSet \&quot;nginx-all-9bf75995b\&quot; has successfully progressed.&quot; &#125; ] &#125;&#125; 3:登陆 nginx-all容器 修改/etc/nginx/conf.d/default.conf 这一步 可以通过配合config server 来实现重启容器更新配置来实现配置的刷新 12345678910111213141516171819202122232425server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location / &#123; root /usr/share/nginx/html; index index.html index.htm; &#125; location /test&#123; # 配置 服务名称+port 不需要使用nodePort直接使用启动容器时候映射的那个port hello-node 启动参数为-p 8080:80 所以这里使用8080 即可 proxy_pass http://hello-node:8080; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125;&#125; 4：配置nginx service配置 nginx service的nodePort1kubectl edit service nginx-all 修改配置如下 就是配置 nodePort123456789101112131415161718192021222324252627282930313233343536&#123; &quot;kind&quot;: &quot;Service&quot;, &quot;apiVersion&quot;: &quot;v1&quot;, &quot;metadata&quot;: &#123; &quot;name&quot;: &quot;nginx-all&quot;, &quot;namespace&quot;: &quot;default&quot;, &quot;selfLink&quot;: &quot;/api/v1/namespaces/default/services/nginx-all&quot;, &quot;uid&quot;: &quot;050ea702-1b6d-11e8-a211-080027fc8712&quot;, &quot;resourceVersion&quot;: &quot;45659&quot;, &quot;creationTimestamp&quot;: &quot;2018-02-27T03:19:28Z&quot;, &quot;labels&quot;: &#123; &quot;k8s-app&quot;: &quot;nginx-all&quot; &#125; &#125;, &quot;spec&quot;: &#123; &quot;ports&quot;: [ &#123; &quot;name&quot;: &quot;tcp-8080-80-cvw8l&quot;, &quot;protocol&quot;: &quot;TCP&quot;, &quot;port&quot;: 8080, &quot;targetPort&quot;: 80, &quot;nodePort&quot;: 31000 &#125; ], &quot;selector&quot;: &#123; &quot;k8s-app&quot;: &quot;nginx-all&quot; &#125;, &quot;clusterIP&quot;: &quot;10.102.241.166&quot;, &quot;type&quot;: &quot;NodePort&quot;, &quot;sessionAffinity&quot;: &quot;None&quot;, &quot;externalTrafficPolicy&quot;: &quot;Cluster&quot; &#125;, &quot;status&quot;: &#123; &quot;loadBalancer&quot;: &#123;&#125; &#125;&#125; 6:通过nginx访问hello-node服务minikube的 node ip 默认为192.168.99.100访问 http://192.168.99.100:31000/test 就是通过nginx代理访问了hello-node 服务 6: service loadbalancer可以用一个clusterIP 共享一个ip配合自定义代理可以做到一个ip 多个不同端口访问不同服务 配合nginx做代理 做到不受服务的变更 只需要一个clusterIp即可配置nginx 屏蔽底层的serviceIp变化这种方案 有单点故障的隐患 和性能问题 暂时不成熟 总结:说到底 暴露服务还是要通过k8s内部的网络去做如果像我一样懒 那就选择ingress当然我最终选择还是 自定义方案没啥别的 就是nginx配置 之前就有 ingress的配置 特么还要我自己写 肯定选择自定义方案如果是新项目 或者不偷懒 建议选择ingress方案 因为毕竟是官方的套路 很多人实践过 后续简单 自定义方案最终还是需要一个基佬去维护配置的这里有个坑 就是 如果为了方便 配置 建议所有服务节点一定要有一个统一前缀 如果没有 请尽量推动各位基佬增加一个统一前缀 不然写配置 要写疯]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
        <tag>实用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[minikube快速搭建k8s测试环境]]></title>
    <url>%2Fming%2Fba1e0f81.html</url>
    <content type="text"><![CDATA[有朋友问我 k8s测试环境如何快速搭建 官方推荐的是minikube其实吧 阿里云上这种文档一抓一大把参考文档:https://yq.aliyun.com/articles/221687运行环境ubuntu 16.04 至少这个版本 低了不行 没有snap可以访问互联网安装步骤0:更新系统apt包相关资源需要手动调整到国内的镜像源 不然要慢死人了安装snap snapd 方便后续安装kubectl12sudo apt update &amp;&amp; sudo apt upgrade sudo apt install snap snapd 1：安装kubectl比较懒 采用 snap(类似apt的东西) 安装kubectl1sudo snap install kubectl 2：安装golang使用apt 安装golang1sudo apt install golang 3: 安装minikube1curl -Lo minikube http://kubernetes.oss-cn-hangzhou.aliyuncs.com/minikube/releases/v0.25.0/minikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/ 4:启动minikube1minikube start --registry-mirror=https://registry.docker-cn.com 5:尝试kubectl是否可用在启动minikube的时候 它会自动覆盖kubectl之前的链接配置 直接使用就是链接到minikube创建的k8s集群中1kubectl get all 6:打开k8s web ui1minikube dashboard 执行完毕后会自动弹出浏览器 如果没有 请尝试 http://192.168.99.100:300007:现在就可以在web ui中或者终端中使用kubectl操控k8s集群了此集群k8s版本为1.9 总结: 这个方法只能在本地快速搭建起来一套测试环境 如果是真实运行环境还是要手动的去安装 高版本的k8s 安装基本上对于一个熟悉linux的用户来说没啥难度 总的就是安装各个组件、配置各个组件 即可]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker启动jenkins]]></title>
    <url>%2Fming%2F5e5f86c0.html</url>
    <content type="text"><![CDATA[####在2.x版本jenkins 中 出现了 pipe 所以决定通过较为新的方式去从新部署一套基于jenkins 的docker 项目 自动化部署https://dzone.com/refcardz/continuous-delivery-with-jenkins-workflow安装 jenkins docker版本1:jenkins 默认密码还是jenkins 容器中的安装目录下的老位置 ${jenkins安装位置}/secrets/initialAdminPassword2:jenkins 容器内部运行 docker相关命令方案1:docker-in-docker 就是 在容器内部 安装容器这种方案 需要在jenkins 镜像上进行修改 比较麻烦 因为 docker里面是经过高度简化的系统 安装起来麻烦遇到错误:因为 docker主线程 是jenkins 而docker是需要在root权限下运行要把jenkins用户加入到docker用户组中 即可用jenkins 用户执行docker 命令alpine 没有找到如何切换 用户组 usermod 之类的命令 alpine 没有方案2:【jenkins官网方案】docker-out-docker 通过目录影射 把docker.sock 影射到jenkins docker中这种方式 安全性很差 容器 能够访问宿主机的功能如果做好 虚拟机或者物理机级别的隔离 其实还不错1sudo docker run -u root --rm -d -p 20000:8080 -v jenkins-data:/var/jenkins_home -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/docker:/var/lib/docker --privileged jenkinsci/blueocean 方案3:【危险方案】把 docker socket暴露出去 调用看到这种方案 玩度不想玩 放弃]]></content>
  </entry>
  <entry>
    <title><![CDATA[基于jenkins2.X和docker的持续集成的实例]]></title>
    <url>%2Fming%2F4732d3fc.html</url>
    <content type="text"><![CDATA[实例功能自动编译、打包自动分发、部署钉钉消息通知交互式部署通过jenkins部署一个index.html首页实现所需技能jenkinsdockergroovy 写脚本项目打包linux常用技术java步骤以这个目录为root目录: https://github.com/xuxianyu/info/tree/master/mingJenkins/simple0:创建index.html12345678910&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;ming&lt;/title&gt;&lt;/head&gt;&lt;body&gt;ming&lt;/body&gt;&lt;/html&gt; 1：创建docker file在项目目录下建立 Dockerfile1234FROM docker.io/nginx:1.13-alpineMAINTAINER &apos;ming&apos;# 复制index.html 到nginx 工作目录 COPY index.html /usr/share/nginx/html 2：创建JenkinsfileJenkinsfile 是jenkins出的用一套用来定义流水线模式的任务的脚本其中有两种模式 pipeline jenkins标准的 配置脚本模式 script 使用groovy dsl 实现的jenkins 流水线模式脚本 我采用的是script模式 因为灵活 好用 两者区别请参考jenkins官网123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424import java.text.SimpleDateFormat/**jenkinsfile 使用groovy dsl方式实现 * 采用 基于groovy 控制流程 groovy dsl +shell 共同协作 部署发布 * 先在 dev rc 环境使用 单节点 直接停止之后部署 等待寻找对环境稳定影响较少的 多节点部署+dev rc uat 环境单节点部署方案 * 多节点部署: * 当前想法是使用 用空间换取时间的方式 * 提供两套nginx 配置 * 每次先启动 然后切换配置 * 需要项目提供监听接口 监听当前是否有在执行的任务 * 需要事务由一定的全局事务 或者一定的补偿机制 保证最终一致性 * * * * * 修改此脚本需要的技能点: * 0: 熟悉 项目版本管理工具 如 svn git * 1:熟悉 java groovy 此脚步使用是groovy 和部分jdk的语法书写 * 2:熟悉jenkins 熟悉 2.x以上的pipe 方式的 jenkins task 由于jenkins官方文档 保持一贯的简略的风格 查阅资料请直接上github 或者stack overflow 之类的干货网站 * 3:熟悉项目打包 如java的 maven打包 、 h5的 npm 打包、php的打包 、c# 打包 * 4:熟悉 linux相关功能 及其原理 例如 ssh密钥验证原理 * 5:熟悉docker 基础原理 及其相关命令 * 6:了解 自动化测试 大致使用方法 如接口测试、ui测试 如何实现 * 7:了解代码审查相关工具 使用 * 8:了解钉钉、mail、jira 通知方式、如钉钉的webhook mail发送原理、jira webhook * * * * 编码规范: * 0:注释一定要写全 特别是方法的注释 * 1:遵循java 编码规范 只能说尽量遵循 毕竟不是java * 2:尽可能的使用 jenkins插件中的方法 而不是groovy dsl 调用 shell * 3:使用默认参数时候 请尽量在最顶层方法使用 基础性的方法 尽量避免使用默认参数 * 4:由于groovy的sdk 可拆分的特性 jenkins对于部分groovy写法不支持 * 5:groovy dsl 可以使用jdk的写法去写 支持完整的jdk 前提是环境里面有jdk 没有就不行 * 6:为了保持 灵活性 只能使用 script pipe 禁止改称pipeline 模式书写 * * @author ming * @mail 18120580001@163.com * @date 2017-12-21 16:44 * */node &#123; //启动任务的参数 properties([ parameters([ //项目名称 string(defaultValue: &quot;&#123;项目名称 只能是小写英文 和-&#125;&quot;, description: &quot;项目名称&quot;, name: &quot;projectName&quot;), //项目版本 string(defaultValue: &quot;2.0.0&quot;, description: &quot;项目版本&quot;, name: &quot;projectVersion&quot;), //项目默认部署端口 string(defaultValue: &quot;10000&quot;, description: &quot;项目默认部署端口&quot;, name: &quot;defaultPort&quot;), // 容器内部端口 string(defaultValue: &quot;80&quot;, description: &quot;项目默认部署端口&quot;, name: &quot;imagePort&quot;), // dev 环境服务器 string(defaultValue: &quot;&#123;dev环境服务器地址&#125;&quot;, description: &quot;dev环境服务器地址&quot;, name: &quot;devHost&quot;), //dev 环境 ssh 端口 string(defaultValue: &quot;&#123;dev环境服务器ssh登陆端口&#125;&quot;, description: &quot;dev环境服务器ssh端口&quot;, name: &quot;devHostPort&quot;), //docker 私服地址 string(defaultValue: &quot;&#123;docker 私服仓库地址 &#125;&quot;, description: &quot;docker仓库地址&quot;, name: &quot;dockerRegistry&quot;), // 项目通知用户组 钉钉艾特方式 string(defaultValue: &apos;&quot;&#123;注册钉钉的电话号码&#125;&quot;&apos;, description: &quot;项目组成员钉钉通知电话号码&quot;, name: &quot;mobilesGroup&quot;), //容器名称 string(defaultValue: &quot;&#123;容器启动之后的名称&#125;&quot;, description: &quot;容器名称&quot;, name: &quot;containerName&quot;), // 获取配置方式 // $&#123;params.$&#123;name&#125;&#125; ]) ]) svnScmParams = checkout(scm) //全局变量 // docker镜像私服 String dockerRegistryHost if (&quot;$&#123;params.dockerRegistry&#125;&quot;.startsWith(&quot;http://&quot;)) &#123; dockerRegistryHost = &quot;$&#123;params.dockerRegistry&#125;&quot;.substring(7) &#125; else if (&quot;$&#123;params.dockerRegistry&#125;&quot;.startsWith(&quot;https://&quot;)) &#123; dockerRegistryHost = &quot;$&#123;params.dockerRegistry&#125;&quot;.substring(8) &#125; else &#123; throw new Exception(&quot;docker镜像仓库前缀必须是http:// 或者https：//&quot;) &#125; //dev 仓库镜像名称 String devRegistryImageName // 刷新db的 镜像名称 //流程定义 try &#123; //建立编译环境 node+ docker in docker 环境 docker.image(&apos;car2godeveloper/dind-node-build-runner&apos;).inside(&apos;--privileged&apos;) &#123; stage(&apos;编译项目&apos;) &#123; //闭包 递归 调用自己 Closure compile = &#123; -&gt; try &#123; print &apos;编译项目&apos; //存放编译相关指令 sendDD(&quot;编译通过&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) &#125; catch (e) &#123; if (isStop(e)) &#123; sendDD(&quot;编译失败::$&#123;e.getMessage()&#125;&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) throw e &#125; else &#123; sendDD(&quot;编译失败重新执行::$&#123;e.getMessage()&#125;&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) call() &#125; &#125; &#125; compile.call() &#125; stage(&apos;构建发布项目docker image&apos;) &#123; Closure buildProjectDockerImage = &#123; -&gt; try &#123; sh &apos;docker --version&apos; //发布到私服仓库 &#123;镜像仓库地址&#125;/&#123;镜像命名空间&#125;/&#123;镜像名称&#125;:&#123;tag标签&#125; //imageName=$&#123;dockerRepository&#125;/$&#123;namespace&#125;/$&#123;projectName&#125;-$&#123;projectVersion&#125;-$&#123;环境&#125;:$&#123;localDate&#125; String localDate = geFormatterLocalDate(&quot;yyyyMMdd.HHmmss&quot;) imageName = &quot;$&#123;params.projectName&#125;-$&#123;params.projectVersion&#125;-dev:$&#123;localDate&#125;&quot; docker.withRegistry(&quot;$&#123;params.dockerRegistry&#125;&quot;) &#123; docker.build(imageName).push() devRegistryImageName = &quot;$&#123;dockerRegistryHost&#125;/$&#123;imageName&#125;&quot; &#125; sendDD(&quot;构建发布镜像成功&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) &#125; catch (e) &#123; if (isStop(e)) &#123; sendDD(&quot;构建发布镜像失败::$&#123;e.getMessage()&#125;&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) throw e &#125; else &#123; sendDD(&quot;构建发布镜像失败重新执行::$&#123;e.getMessage()&#125;&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) call() &#125; &#125; &#125; buildProjectDockerImage.call() &#125; stage(&apos;部署dev环境&apos;) &#123; Closure deployDev = &#123; -&gt; try &#123; print &apos;部署dev环境&apos; deploy(&quot;$&#123;params.devHost&#125;&quot;, &quot;$&#123;params.defaultPort&#125;&quot;, &quot;$&#123;params.containerName&#125;&quot;, &quot;$&#123;devRegistryImageName&#125;&quot;, &quot;&quot;,&quot;$&#123;params.imagePort&#125;&quot;, &quot;$&#123;params.devHostPort&#125;&quot;) //ssh远程部署 sendDD(&quot;部署dev成功&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) &#125; catch (e) &#123; if (isStop(e)) &#123; sendDD(&quot;部署dev失败::$&#123;e.getMessage()&#125;&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) throw e &#125; else &#123; sendDD(&quot;部署dev失败重新执行::$&#123;e.getMessage()&#125;&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) call() &#125; &#125; &#125; deployDev.call() &#125; stage(&apos;dev环境自动化测试&apos;) &#123; Closure autoTestDev = &#123; -&gt; try &#123; print &apos;dev环境自动化测试&apos; //自动化测试指令 sendDD(&quot;自动化测试dev环境成功&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) &#125; catch (e) &#123; if (isStop(e)) &#123; sendDD(&quot;自动化测试dev环境失败::$&#123;e.getMessage()&#125;&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) throw e &#125; else &#123; sendDD(&quot;自动化测试dev环境失败重新执行::$&#123;e.getMessage()&#125;&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) call() &#125; &#125; &#125; autoTestDev.call() &#125; stage(&apos;dev环境功能确认？(发布rc环境镜像)&apos;) &#123; Closure releaseDev = &#123; -&gt; try &#123; def userInput = input( id: &apos;userInput&apos;, message: &apos;发布备注:&apos;, parameters: [ [$class: &apos;TextParameterDefinition&apos;, defaultValue: &apos;无&apos;, description: &apos;发布备注:&apos;, name: &apos;memo&apos;], ]) print userInput //替换 名称中的 dev标记 在dev 机器上完成 rcRegistryImageName = devRegistryImageName.replaceAll(&quot;-dev&quot;, &quot;-rc&quot;) release(rcRegistryImageName, devRegistryImageName, &quot;$&#123;params.devHost&#125;&quot;, &quot;$&#123;params.devHostPort&#125;&quot;) sh &apos;echo dev环境功能测试确定&apos; sendDD(&quot;dev环境发布到rc仓库成功&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) &#125; catch (e) &#123; if (isStop(e)) &#123; sendDD(&quot;dev环境发布到rc仓库失败::$&#123;e.getMessage()&#125;&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) throw e &#125; else &#123; sendDD(&quot;dev环境发布到rc仓库失败重新执行::$&#123;e.getMessage()&#125;&quot;, &quot;$&#123;params.mobilesGroup&#125;&quot;) call() &#125; &#125; &#125; releaseDev.call() &#125; //........ 后面都是重复性的节点 直接复制改改就是的 &#125; &#125; catch (e) &#123; print currentBuild.result sendDD(&quot;持续集成构建失败&quot; + e.getMessage(), &quot;$&#123;params.mobilesGroup&#125;&quot;) throw e &#125;&#125;/** 发送到钉钉 使用 shell脚本发送 因为 jenkins 的groovy不是完整的gdk功能 调jdk 又比较麻烦 干脆直接拼写 shell命令执行算了 * 默认钉钉 url 发版通知群jenkins 机器人 * @param info 消息内容 * @param mobiles 艾特电话号码组&#123;@link *MobilesGroup &#125; * @author ming * @date 2017-12-22 18:58 * */def sendDD(String info, String mobiles , String url = &apos;https://oapi.dingtalk.com/robot/send?access_token=&#123;钉钉机器人的token&#125;&apos;) &#123; String headers = &apos;Content-Type: application/json&apos; String atStr = &quot;&quot; String[] mobilesArr = mobiles.split(&quot;,&quot;) for (int i = 0; i &lt; mobilesArr.length; i++) &#123; //截取 2&lt;=n &lt;13中间11 位电话号码 String tmp = &quot;$&#123;mobilesArr[i]&#125;&quot;.substring(1, 12) atStr = atStr + &quot; @$&#123;tmp&#125;&quot; &#125; String jsonStr = &quot;&#123; \&quot;msgtype\&quot;: \&quot;markdown\&quot;&quot; + &quot;, \&quot;markdown\&quot;: &#123; \&quot;title\&quot;:\&quot;执行结果通知\&quot;, \&quot;text\&quot;: \&quot;#### $&#123;atStr&#125; 执行结果通知:$&#123;params.projectName&#125;项目:$&#123;info&#125;\&quot; &#125;,&quot; + &quot; \&quot;at\&quot;: &#123; \&quot;atMobiles\&quot;: [$&#123;mobiles&#125;], \&quot;isAtAll\&quot;: false &#125; &#125;&quot; String script = &quot;curl \&apos;$&#123;url&#125;\&apos; -H \&apos;$&#123;headers&#125;\&apos; -d \&apos;$&#123;jsonStr&#125;\&apos; &amp;&amp; exit 0 &quot; sh script&#125;/** 预留方法 发送邮件 * * @author ming * @date 2017-12-22 19:01 * */def sendMail() &#123;&#125;/**根据时间格式化格式 获取当前时间 默认 yyyy-MM-dd HH:mm:ss * @param patten * @return dateStr * @author ming * @date 2017-12-22 23:39 * */def geFormatterLocalDate(String patten = &quot;yyyy-MM-dd HH:mm:ss&quot;) &#123; Date date = new Date() SimpleDateFormat formatter = new SimpleDateFormat(patten) formatter.format(date)&#125;/**流程错误 处理 * * @author ming * @date 2017-12-27 22:29 * */def boolean isStop(Exception e) &#123; print e.getMessage() def userInput = input( id: &apos;userInput&apos;, message: &apos;是否中止 此次流程:&apos;, parameters: [ [$class: &apos;TextParameterDefinition&apos;, defaultValue: &apos;true&apos;, description: &apos;是否中止此次流程&apos;, name: &apos;flag&apos;], ]) print userInput if (&apos;true&apos;.equalsIgnoreCase(userInput)) &#123; return true &#125; else if (&apos;false&apos;.equalsIgnoreCase(userInput)) &#123; return false &#125;&#125;/** 运行容器 * * @param port * @param containerName * @param registryImageName * @param host * @param sshKey * @author ming * @date 2017-12-26 23:36 * */def runSSHDocker(String port, String containerName, String registryImageName, String env, String imagePort,String host, String sshPort, String sshKey) &#123; // jenkins 配置的sshkey id sshagent([sshKey]) &#123; //登陆服务器之后启动容器的命令 String runCmd = &quot;docker run -d -p $&#123;port&#125;:$&#123;imagePort&#125; $&#123;env&#125; --name $&#123;containerName&#125; $&#123;registryImageName&#125;&quot; // 登陆 服务器 运行容器 sh &quot;ssh -o StrictHostKeyChecking=no -t -t -p $&#123;sshPort&#125; root@$&#123;host&#125; &apos;$&#123;runCmd&#125;&apos;&quot; &#125;&#125;/** 删除容器 * * @param containerName * @param host * @param sshKey * @author ming * @date 2017-12-26 23:36 * */def removeSSHContainer(String containerName, String host, String sshPort, String sshKey) &#123; sshagent([sshKey]) &#123; //登陆服务器之后启动容器的命令 String runCmd = &quot;docker rm -f $&#123;containerName&#125;&quot; // 登陆 服务器 运行容器 sh &quot;ssh -o StrictHostKeyChecking=no -t -t -p $&#123;sshPort&#125; root@$&#123;host&#125; &apos;$&#123;runCmd&#125;&apos;&quot; &#125;&#125;/** 删除镜像 * * @param registryImageName * @param host * @param sshKey * @author ming * @date 2017-12-26 23:36 * */def removeSSHImage(String registryImageName, String host, String sshPort, String sshKey) &#123; sshagent([sshKey]) &#123; //登陆服务器之后启动容器的命令 String runCmd = &quot;docker rmi $&#123;registryImageName&#125;&quot; // 登陆 服务器 运行容器 sh &quot;ssh -o StrictHostKeyChecking=no -t -t -p $&#123;sshPort&#125; root@$&#123;host&#125; &apos;$&#123;runCmd&#125;&apos;&quot; &#125;&#125;/**修改远程服务中的 imagename * 这里的imagename 必须是 仓库地址/镜像名:tag * @param newImageName * @param oldImageName * @author ming * @date 2017-12-27 10:04 * */def updateSSHImamgeName(String newImageName, String oldImageName, String host, String sshPort, String sshKey) &#123; sshagent([sshKey]) &#123; String runCmd = &quot;docker tag $&#123;oldImageName&#125; $&#123;newImageName&#125;&quot; sh &quot;ssh -o StrictHostKeyChecking=no -t -t -p $&#123;sshPort&#125; root@$&#123;host&#125; &apos;$&#123;runCmd&#125;&apos;&quot; &#125;&#125;/** 推送远程服务器上的镜像 * 这里镜像名称 必须是 仓库地址/镜像名:tag 格式 * @param imageName * @author ming * @date 2017-12-27 10:08 * */def pushSSHImage(String imageName, String host, String sshPort, String sshKey) &#123; sshagent([sshKey]) &#123; String runCmd = &quot;docker push $&#123;imageName&#125;&quot; sh &quot;ssh -o StrictHostKeyChecking=no -t -t -p $&#123;sshPort&#125; root@$&#123;host&#125; &apos;$&#123;runCmd&#125;&apos;&quot; &#125;&#125;/** 部署 * @param host * @param port * @param containerName * @param imageName * @author ming * @date 2017-12-27 09:43 * */def deploy(String host, String port, String containerName, String imageName, String env ,String imagePort, String sshPort = &quot;22&quot;, String sshKey = &apos;efa90668-61e3-47f0-9730-b0e53ea7f97e&apos;) &#123; boolean flag = true while (flag) &#123; try &#123; //运行docker runSSHDocker(port, containerName, imageName, env,imagePort, host, sshPort, sshKey) flag = false &#125; catch (e) &#123; print e.getMessage() //删除运行中 的容器 removeSSHContainer(containerName, host, sshPort, sshKey) //删除服务器上的image removeSSHImage(imageName, host, sshPort, sshKey) &#125; &#125;&#125;/**发布镜像到下一个阶段 * @param newImageName * @param oldImageName * @param host * @param sshKey * @author ming * @date 2017-12-27 10:15 * */def release(String newImageName, String oldImageName, String host, String sshPort = &quot;22&quot;, String sshKey = &apos;efa90668-61e3-47f0-9730-b0e53ea7f97e&apos;) &#123; updateSSHImamgeName(newImageName, oldImageName, host, sshPort, sshKey) pushSSHImage(newImageName, host, sshPort, sshKey) removeSSHImage(oldImageName, host, sshPort, sshKey)&#125;/** ui自动化测试 * * @author ming * @date 2017-12-27 22:12 * */def uiAutoTest() &#123;&#125;/**代码审查 并且发送报告 * * @author ming * @date 2017-12-27 22:12 * */def codeReview() &#123;&#125; 将其中的用{} 包含的中文 替换成相应的参数即可sshKey 是jenkins配置sshAgent插件的id 3:安装启动 jenkinsdocker 方式启动 参考: 4: 安装插件主要是要安装 sshAgent 、 docker相关插件、5:jenkins 引入项目定义的Jenkinsfile 形成流水线任务 新增jenkins 流水线任务配置流水线相关配置 定义选择 Pipeline script from SCM 》 scm选择git 配置git地址等相关属性 》script path 选择 Jenkinsfile 即可保存项目 》 启动项目]]></content>
      <categories>
        <category>实例</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux</tag>
        <tag>jenkins</tag>
        <tag>groovy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用阿里云的oss+cdn搭建高速访问的静态博客]]></title>
    <url>%2Fming%2F3c3d59e1.html</url>
    <content type="text"><![CDATA[之前一直想搭建一个博客 但是一直没找到便宜 并且访问速度快的方案 前几种方案1:git pages + cdn国内访问速度简直吃屎 不知道 同行是如何忍受的 cdn从源站拉取资源的时候 慢到无法忍受2:coding pages+cdn不想用 coding pages 还不如直接用git pages3: 购买vps或者静态托管服务器博客初期完全用不起 太特么贵了 穷吊 用不起综上所述 我需要的博客大致需要1:源站访问速度快2:cdn 好用3:域名4:https http2访问5:价格相对便宜6:管理相对方便7:增加ca证书方便最终选择方案全部使用阿里云的相关资源域名：万网cdn:阿里云 cdn源站:使用阿里云的oss对象存储12oss 原本只是 阿里云的一个放文件的一个功能 后来他支持设定首页 就可以用来托管静态页面 速度不用说 肯定快 而且支持 https ca证书:阿里云 ca免费赛门铁克证书静态博客:hexo + next主题 其实这些主要是选择 具体如何使用 直接操作阿里云控制台就是的 没啥难度 遇到的麻烦的点:1: oss 存储hexo生成的静态资源 路由问题由于oss 里面 文件夹也是可访问的一种资源 这就导致 hexo初始生成的路由 例如/tags/ming/ 这个时候他访问的是oss里面的/tags/ming/ 文件夹 然后是空白解决办法: 修改站点配置_config.yaml 中permalink参数我是用abbrlink 来重写url了 如果不用 就是在hexo的permalink中 后面加上.html 即可123# 使用abbrlink 来重写固定url https://segmentfault.com/a/1190000005799711permalink: ming/:abbrlink.htmlpermalink_defaults: 标签、归档、分页相关路由 调整修改 当前目录下node_modules/hexo/lib/plugins/helper/index.js 中关于 标签、归档、分页相关的插件12345678910111213141516171819202122232425&apos;use strict&apos;;module.exports = function (ctx) &#123;。。。//重写 归档 js 增加index.html 路径 配合 oss 访问// helper.register(&apos;list_categories&apos;, require(&apos;./list_categories&apos;)); helper.register(&apos;list_categories&apos;, require(&apos;./ming_list_categories&apos;)); 。。。 //重写分页相关地址 配合oss// helper.register(&apos;paginator&apos;, require(&apos;./paginator&apos;)); helper.register(&apos;paginator&apos;, require(&apos;./ming_paginator&apos;)); 。。。// var tagcloud = require(&apos;./tagcloud&apos;);// helper.register(&apos;tagcloud&apos;, tagcloud);// helper.register(&apos;tag_cloud&apos;, tagcloud); //引入 自定义 tag cloud 标签 修改生成路径的函数 适应oss var ming_tag = require(&apos;./ming_tag&apos;) helper.register(&apos;tagcloud&apos;, ming_tag); helper.register(&apos;tag_cloud&apos;, ming_tag);。。。 在index.js目录下新增下面三个文件 归档插件的实现新增 ming_list_categories.js文件复制如下内容进去123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125&apos;use strict&apos;;function listCategoriesHelper(categories, options) &#123; if (!options &amp;&amp; (!categories || !categories.hasOwnProperty(&apos;length&apos;))) &#123; options = categories; categories = this.site.categories; &#125; if (!categories || !categories.length) return &apos;&apos;; options = options || &#123;&#125;; var style = options.hasOwnProperty(&apos;style&apos;) ? options.style : &apos;list&apos;; var showCount = options.hasOwnProperty(&apos;show_count&apos;) ? options.show_count : true; var className = options.class || &apos;category&apos;; var depth = options.depth ? parseInt(options.depth, 10) : 0; var orderby = options.orderby || &apos;name&apos;; var order = options.order || 1; var transform = options.transform; var separator = options.hasOwnProperty(&apos;separator&apos;) ? options.separator : &apos;, &apos;; var showCurrent = options.show_current || false; // 添加 /index.html 配合oss 访问 //var suffix = options.suffix || &apos;&apos;; var suffix = &quot;index.html&quot;; var childrenIndicator = options.hasOwnProperty(&apos;children_indicator&apos;) ? options.children_indicator : false; var result = &apos;&apos;; var self = this; function prepareQuery(parent) &#123; var query = &#123;&#125;; if (parent) &#123; query.parent = parent; &#125; else &#123; query.parent = &#123;$exists: false&#125;; &#125; return categories.find(query).sort(orderby, order).filter(function(cat) &#123; return cat.length; &#125;); &#125; function hierarchicalList(level, parent) &#123; var result = &apos;&apos;; prepareQuery(parent).forEach(function(cat, i) &#123; var child; if (!depth || level + 1 &lt; depth) &#123; child = hierarchicalList(level + 1, cat._id); &#125; var isCurrent = false; if (showCurrent &amp;&amp; self.page) &#123; for (var j = 0; j &lt; cat.length; j++) &#123; var post = cat.posts.data[j]; if (post &amp;&amp; post._id === self.page._id) &#123; isCurrent = true; break; &#125; &#125; // special case: category page if (!isCurrent &amp;&amp; self.page.base) &#123; if (self.page.base.indexOf(cat.path) === 0) &#123; isCurrent = true; &#125; &#125; &#125; var additionalClassName = &apos;&apos;; if (child &amp;&amp; childrenIndicator) &#123; additionalClassName = &apos; &apos; + childrenIndicator; &#125; result += &apos;&lt;li class=&quot;&apos; + className + &apos;-list-item&apos; + additionalClassName + &apos;&quot;&gt;&apos;; result += &apos;&lt;a class=&quot;&apos; + className + &apos;-list-link&apos; + (isCurrent ? &apos; current&apos; : &apos;&apos;) + &apos;&quot; href=&quot;&apos; + self.url_for(cat.path) + suffix + &apos;&quot;&gt;&apos;; result += transform ? transform(cat.name) : cat.name; result += &apos;&lt;/a&gt;&apos;; if (showCount) &#123; result += &apos;&lt;span class=&quot;&apos; + className + &apos;-list-count&quot;&gt;&apos; + cat.length + &apos;&lt;/span&gt;&apos;; &#125; if (child) &#123; result += &apos;&lt;ul class=&quot;&apos; + className + &apos;-list-child&quot;&gt;&apos; + child + &apos;&lt;/ul&gt;&apos;; &#125; result += &apos;&lt;/li&gt;&apos;; &#125;); return result; &#125; function flatList(level, parent) &#123; var result = &apos;&apos;; prepareQuery(parent).forEach(function(cat, i) &#123; if (i || level) result += separator; result += &apos;&lt;a class=&quot;&apos; + className + &apos;-link&quot; href=&quot;&apos; + self.url_for(cat.path) + suffix + &apos;&quot;&gt;&apos;; result += transform ? transform(cat.name) : cat.name; if (showCount) &#123; result += &apos;&lt;span class=&quot;&apos; + className + &apos;-count&quot;&gt;&apos; + cat.length + &apos;&lt;/span&gt;&apos;; &#125; result += &apos;&lt;/a&gt;&apos;; if (!depth || level + 1 &lt; depth) &#123; result += flatList(level + 1, cat._id); &#125; &#125;); return result; &#125; if (style === &apos;list&apos;) &#123; result += &apos;&lt;ul class=&quot;&apos; + className + &apos;-list&quot;&gt;&apos; + hierarchicalList(0) + &apos;&lt;/ul&gt;&apos;; &#125; else &#123; result += flatList(0); &#125; return result;&#125;module.exports = listCategoriesHelper; 分页插件的实现新增 ming_paginator.js文件复制如下内容进去123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112&apos;use strict&apos;;function paginatorHelper(options) &#123; options = options || &#123;&#125;; var current = options.current || this.page.current || 0; var total = options.total || this.page.total || 1; var endSize = options.hasOwnProperty(&apos;end_size&apos;) ? +options.end_size : 1; var midSize = options.hasOwnProperty(&apos;mid_size&apos;) ? +options.mid_size : 2; var space = options.hasOwnProperty(&apos;space&apos;) ? options.space : &apos;&amp;hellip;&apos;; var base = options.base || this.page.base || &apos;&apos;; var format = options.format || this.config.pagination_dir + &apos;/%d/&apos;; var prevText = options.prev_text || &apos;Prev&apos;; var nextText = options.next_text || &apos;Next&apos;; var prevNext = options.hasOwnProperty(&apos;prev_next&apos;) ? options.prev_next : true; var transform = options.transform; var self = this; var result = &apos;&apos;; var i; //配合 oss 使用index.html var suffix = &quot;index.html&quot;; if (!current) return &apos;&apos;; var currentPage = &apos;&lt;span class=&quot;page-number current&quot;&gt;&apos; + (transform ? transform(current) : current) + &apos;&lt;/span&gt;&apos;; function link(i) &#123; return self.url_for(i === 1 ? base : base + format.replace(&apos;%d&apos;, i)); &#125; function pageLink(i) &#123; return &apos;&lt;a class=&quot;page-number&quot; href=&quot;&apos; + link(i) + suffix +&apos;&quot;&gt;&apos; + (transform ? transform(i) : i) + &apos;&lt;/a&gt;&apos;; &#125; // Display the link to the previous page if (prevNext &amp;&amp; current &gt; 1) &#123; result += &apos;&lt;a class=&quot;extend prev&quot; rel=&quot;prev&quot; href=&quot;&apos; + link(current - 1) + suffix +&apos;&quot;&gt;&apos; + prevText + &apos;&lt;/a&gt;&apos;; &#125; if (options.show_all) &#123; // Display pages on the left side of the current page for (i = 1; i &lt; current; i++) &#123; result += pageLink(i); &#125; // Display the current page result += currentPage; // Display pages on the right side of the current page for (i = current + 1; i &lt;= total; i++) &#123; result += pageLink(i); &#125; &#125; else &#123; // It&apos;s too complicated. May need refactor. var leftEnd = current &lt;= endSize ? current - 1 : endSize; var rightEnd = total - current &lt;= endSize ? current + 1 : total - endSize + 1; var leftMid = current - midSize &lt;= endSize ? leftEnd + 1 : current - midSize; var rightMid = current + midSize + endSize &gt; total ? rightEnd - 1 : current + midSize; var spaceHtml = &apos;&lt;span class=&quot;space&quot;&gt;&apos; + space + &apos;&lt;/span&gt;&apos;; // Display pages on the left edge for (i = 1; i &lt;= leftEnd; i++) &#123; result += pageLink(i); &#125; // Display spaces between edges and middle pages if (space &amp;&amp; current - endSize - midSize &gt; 1) &#123; result += spaceHtml; &#125; // Display left middle pages if (leftMid &gt; leftEnd) &#123; for (i = leftMid; i &lt; current; i++) &#123; result += pageLink(i); &#125; &#125; // Display the current page result += currentPage; // Display right middle pages if (rightMid &lt; rightEnd) &#123; for (i = current + 1; i &lt;= rightMid; i++) &#123; result += pageLink(i); &#125; &#125; // Display spaces between edges and middle pages if (space &amp;&amp; total - endSize - midSize &gt; current) &#123; result += spaceHtml; &#125; // Dispaly pages on the right edge for (i = rightEnd; i &lt;= total; i++) &#123; result += pageLink(i); &#125; &#125; // Display the link to the next page if (prevNext &amp;&amp; current &lt; total) &#123; result += &apos;&lt;a class=&quot;extend next&quot; rel=&quot;next&quot; href=&quot;&apos; + link(current + 1) + suffix+ &apos;&quot;&gt;&apos; + nextText + &apos;&lt;/a&gt;&apos;; &#125; return result;&#125;module.exports = paginatorHelper; 标签插件的实现新增 ming_tag.js文件复制如下内容进去123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387&apos;use strict&apos;;// https://github.com/imathis/hsl-picker/blob/master/assets/javascripts/modules/color.coffeevar rHex3 = /^#([0-9a-f]&#123;3&#125;)$/;var rHex6 = /^#([0-9a-f]&#123;6&#125;)$/;var rRGB = /^rgba?\(\s*(\d&#123;1,3&#125;)\s*,\s*(\d&#123;1,3&#125;)\s*,\s*(\d&#123;1,3&#125;)\s*,?\s*(0?\.?\d+)?\s*\)$/;var rHSL = /^hsla?\(\s*(\d&#123;1,3&#125;)\s*,\s*(\d&#123;1,3&#125;)%\s*,\s*(\d&#123;1,3&#125;)%\s*,?\s*(0?\.?\d+)?\s*\)$/;// http://www.w3.org/TR/css3-color/#svg-colorvar colorNames = &#123; aliceblue: &#123;r: 240, g: 248, b: 255, a: 1&#125;, antiquewhite: &#123;r: 250, g: 235, b: 215, a: 1&#125;, aqua: &#123;r: 0, g: 255, b: 255, a: 1&#125;, aquamarine: &#123;r: 127, g: 255, b: 212, a: 1&#125;, azure: &#123;r: 240, g: 255, b: 255, a: 1&#125;, beige: &#123;r: 245, g: 245, b: 220, a: 1&#125;, bisque: &#123;r: 255, g: 228, b: 196, a: 1&#125;, black: &#123;r: 0, g: 0, b: 0, a: 1&#125;, blanchedalmond: &#123;r: 255, g: 235, b: 205, a: 1&#125;, blue: &#123;r: 0, g: 0, b: 255, a: 1&#125;, blueviolet: &#123;r: 138, g: 43, b: 226, a: 1&#125;, brown: &#123;r: 165, g: 42, b: 42, a: 1&#125;, burlywood: &#123;r: 222, g: 184, b: 135, a: 1&#125;, cadetblue: &#123;r: 95, g: 158, b: 160, a: 1&#125;, chartreuse: &#123;r: 127, g: 255, b: 0, a: 1&#125;, chocolate: &#123;r: 210, g: 105, b: 30, a: 1&#125;, coral: &#123;r: 255, g: 127, b: 80, a: 1&#125;, cornflowerblue: &#123;r: 100, g: 149, b: 237, a: 1&#125;, cornsilk: &#123;r: 255, g: 248, b: 220, a: 1&#125;, crimson: &#123;r: 220, g: 20, b: 60, a: 1&#125;, cyan: &#123;r: 0, g: 255, b: 255, a: 1&#125;, darkblue: &#123;r: 0, g: 0, b: 139, a: 1&#125;, darkcyan: &#123;r: 0, g: 139, b: 139, a: 1&#125;, darkgoldenrod: &#123;r: 184, g: 134, b: 11, a: 1&#125;, darkgray: &#123;r: 169, g: 169, b: 169, a: 1&#125;, darkgreen: &#123;r: 0, g: 100, b: 0, a: 1&#125;, darkgrey: &#123;r: 169, g: 169, b: 169, a: 1&#125;, darkkhaki: &#123;r: 189, g: 183, b: 107, a: 1&#125;, darkmagenta: &#123;r: 139, g: 0, b: 139, a: 1&#125;, darkolivegreen: &#123;r: 85, g: 107, b: 47, a: 1&#125;, darkorange: &#123;r: 255, g: 140, b: 0, a: 1&#125;, darkorchid: &#123;r: 153, g: 50, b: 204, a: 1&#125;, darkred: &#123;r: 139, g: 0, b: 0, a: 1&#125;, darksalmon: &#123;r: 233, g: 150, b: 122, a: 1&#125;, darkseagreen: &#123;r: 143, g: 188, b: 143, a: 1&#125;, darkslateblue: &#123;r: 72, g: 61, b: 139, a: 1&#125;, darkslategray: &#123;r: 47, g: 79, b: 79, a: 1&#125;, darkslategrey: &#123;r: 47, g: 79, b: 79, a: 1&#125;, darkturquoise: &#123;r: 0, g: 206, b: 209, a: 1&#125;, darkviolet: &#123;r: 148, g: 0, b: 211, a: 1&#125;, deeppink: &#123;r: 255, g: 20, b: 147, a: 1&#125;, deepskyblue: &#123;r: 0, g: 191, b: 255, a: 1&#125;, dimgray: &#123;r: 105, g: 105, b: 105, a: 1&#125;, dimgrey: &#123;r: 105, g: 105, b: 105, a: 1&#125;, dodgerblue: &#123;r: 30, g: 144, b: 255, a: 1&#125;, firebrick: &#123;r: 178, g: 34, b: 34, a: 1&#125;, floralwhite: &#123;r: 255, g: 250, b: 240, a: 1&#125;, forestgreen: &#123;r: 34, g: 139, b: 34, a: 1&#125;, fuchsia: &#123;r: 255, g: 0, b: 255, a: 1&#125;, gainsboro: &#123;r: 220, g: 220, b: 220, a: 1&#125;, ghostwhite: &#123;r: 248, g: 248, b: 255, a: 1&#125;, gold: &#123;r: 255, g: 215, b: 0, a: 1&#125;, goldenrod: &#123;r: 218, g: 165, b: 32, a: 1&#125;, gray: &#123;r: 128, g: 128, b: 128, a: 1&#125;, green: &#123;r: 0, g: 128, b: 0, a: 1&#125;, greenyellow: &#123;r: 173, g: 255, b: 47, a: 1&#125;, grey: &#123;r: 128, g: 128, b: 128, a: 1&#125;, honeydew: &#123;r: 240, g: 255, b: 240, a: 1&#125;, hotpink: &#123;r: 255, g: 105, b: 180, a: 1&#125;, indianred: &#123;r: 205, g: 92, b: 92, a: 1&#125;, indigo: &#123;r: 75, g: 0, b: 130, a: 1&#125;, ivory: &#123;r: 255, g: 255, b: 240, a: 1&#125;, khaki: &#123;r: 240, g: 230, b: 140, a: 1&#125;, lavender: &#123;r: 230, g: 230, b: 250, a: 1&#125;, lavenderblush: &#123;r: 255, g: 240, b: 245, a: 1&#125;, lawngreen: &#123;r: 124, g: 252, b: 0, a: 1&#125;, lemonchiffon: &#123;r: 255, g: 250, b: 205, a: 1&#125;, lightblue: &#123;r: 173, g: 216, b: 230, a: 1&#125;, lightcoral: &#123;r: 240, g: 128, b: 128, a: 1&#125;, lightcyan: &#123;r: 224, g: 255, b: 255, a: 1&#125;, lightgoldenrodyellow: &#123;r: 250, g: 250, b: 210, a: 1&#125;, lightgray: &#123;r: 211, g: 211, b: 211, a: 1&#125;, lightgreen: &#123;r: 144, g: 238, b: 144, a: 1&#125;, lightgrey: &#123;r: 211, g: 211, b: 211, a: 1&#125;, lightpink: &#123;r: 255, g: 182, b: 193, a: 1&#125;, lightsalmon: &#123;r: 255, g: 160, b: 122, a: 1&#125;, lightseagreen: &#123;r: 32, g: 178, b: 170, a: 1&#125;, lightskyblue: &#123;r: 135, g: 206, b: 250, a: 1&#125;, lightslategray: &#123;r: 119, g: 136, b: 153, a: 1&#125;, lightslategrey: &#123;r: 119, g: 136, b: 153, a: 1&#125;, lightsteelblue: &#123;r: 176, g: 196, b: 222, a: 1&#125;, lightyellow: &#123;r: 255, g: 255, b: 224, a: 1&#125;, lime: &#123;r: 0, g: 255, b: 0, a: 1&#125;, limegreen: &#123;r: 50, g: 205, b: 50, a: 1&#125;, linen: &#123;r: 250, g: 240, b: 230, a: 1&#125;, magenta: &#123;r: 255, g: 0, b: 255, a: 1&#125;, maroon: &#123;r: 128, g: 0, b: 0, a: 1&#125;, mediumaquamarine: &#123;r: 102, g: 205, b: 170, a: 1&#125;, mediumblue: &#123;r: 0, g: 0, b: 205, a: 1&#125;, mediumorchid: &#123;r: 186, g: 85, b: 211, a: 1&#125;, mediumpurple: &#123;r: 147, g: 112, b: 219, a: 1&#125;, mediumseagreen: &#123;r: 60, g: 179, b: 113, a: 1&#125;, mediumslateblue: &#123;r: 123, g: 104, b: 238, a: 1&#125;, mediumspringgreen: &#123;r: 0, g: 250, b: 154, a: 1&#125;, mediumturquoise: &#123;r: 72, g: 209, b: 204, a: 1&#125;, mediumvioletred: &#123;r: 199, g: 21, b: 133, a: 1&#125;, midnightblue: &#123;r: 25, g: 25, b: 112, a: 1&#125;, mintcream: &#123;r: 245, g: 255, b: 250, a: 1&#125;, mistyrose: &#123;r: 255, g: 228, b: 225, a: 1&#125;, moccasin: &#123;r: 255, g: 228, b: 181, a: 1&#125;, navajowhite: &#123;r: 255, g: 222, b: 173, a: 1&#125;, navy: &#123;r: 0, g: 0, b: 128, a: 1&#125;, oldlace: &#123;r: 253, g: 245, b: 230, a: 1&#125;, olive: &#123;r: 128, g: 128, b: 0, a: 1&#125;, olivedrab: &#123;r: 107, g: 142, b: 35, a: 1&#125;, orange: &#123;r: 255, g: 165, b: 0, a: 1&#125;, orangered: &#123;r: 255, g: 69, b: 0, a: 1&#125;, orchid: &#123;r: 218, g: 112, b: 214, a: 1&#125;, palegoldenrod: &#123;r: 238, g: 232, b: 170, a: 1&#125;, palegreen: &#123;r: 152, g: 251, b: 152, a: 1&#125;, paleturquoise: &#123;r: 175, g: 238, b: 238, a: 1&#125;, palevioletred: &#123;r: 219, g: 112, b: 147, a: 1&#125;, papayawhip: &#123;r: 255, g: 239, b: 213, a: 1&#125;, peachpuff: &#123;r: 255, g: 218, b: 185, a: 1&#125;, peru: &#123;r: 205, g: 133, b: 63, a: 1&#125;, pink: &#123;r: 255, g: 192, b: 203, a: 1&#125;, plum: &#123;r: 221, g: 160, b: 221, a: 1&#125;, powderblue: &#123;r: 176, g: 224, b: 230, a: 1&#125;, purple: &#123;r: 128, g: 0, b: 128, a: 1&#125;, red: &#123;r: 255, g: 0, b: 0, a: 1&#125;, rosybrown: &#123;r: 188, g: 143, b: 143, a: 1&#125;, royalblue: &#123;r: 65, g: 105, b: 225, a: 1&#125;, saddlebrown: &#123;r: 139, g: 69, b: 19, a: 1&#125;, salmon: &#123;r: 250, g: 128, b: 114, a: 1&#125;, sandybrown: &#123;r: 244, g: 164, b: 96, a: 1&#125;, seagreen: &#123;r: 46, g: 139, b: 87, a: 1&#125;, seashell: &#123;r: 255, g: 245, b: 238, a: 1&#125;, sienna: &#123;r: 160, g: 82, b: 45, a: 1&#125;, silver: &#123;r: 192, g: 192, b: 192, a: 1&#125;, skyblue: &#123;r: 135, g: 206, b: 235, a: 1&#125;, slateblue: &#123;r: 106, g: 90, b: 205, a: 1&#125;, slategray: &#123;r: 112, g: 128, b: 144, a: 1&#125;, slategrey: &#123;r: 112, g: 128, b: 144, a: 1&#125;, snow: &#123;r: 255, g: 250, b: 250, a: 1&#125;, springgreen: &#123;r: 0, g: 255, b: 127, a: 1&#125;, steelblue: &#123;r: 70, g: 130, b: 180, a: 1&#125;, tan: &#123;r: 210, g: 180, b: 140, a: 1&#125;, teal: &#123;r: 0, g: 128, b: 128, a: 1&#125;, thistle: &#123;r: 216, g: 191, b: 216, a: 1&#125;, tomato: &#123;r: 255, g: 99, b: 71, a: 1&#125;, turquoise: &#123;r: 64, g: 224, b: 208, a: 1&#125;, violet: &#123;r: 238, g: 130, b: 238, a: 1&#125;, wheat: &#123;r: 245, g: 222, b: 179, a: 1&#125;, white: &#123;r: 255, g: 255, b: 255, a: 1&#125;, whitesmoke: &#123;r: 245, g: 245, b: 245, a: 1&#125;, yellow: &#123;r: 255, g: 255, b: 0, a: 1&#125;, yellowgreen: &#123;r: 154, g: 205, b: 50, a: 1&#125;&#125;;function tagcloudHelper(tags, options) &#123; if (!options &amp;&amp; (!tags || !tags.hasOwnProperty(&apos;length&apos;))) &#123; options = tags; tags = this.site.tags; &#125; if (!tags || !tags.length) return &apos;&apos;; options = options || &#123;&#125;; var min = options.min_font || 10; var max = options.max_font || 20; var orderby = options.orderby || &apos;name&apos;; var order = options.order || 1; var unit = options.unit || &apos;px&apos;; var color = options.color; var transform = options.transform; var separator = options.separator || &apos; &apos;; var result = []; var self = this; var startColor, endColor; if (color) &#123; startColor = new Color(options.start_color); endColor = new Color(options.end_color); if (!startColor || !endColor) color = false; &#125; // Sort the tags if (orderby === &apos;random&apos; || orderby === &apos;rand&apos;) &#123; tags = tags.random(); &#125; else &#123; tags = tags.sort(orderby, order); &#125; // Ignore tags with zero posts tags = tags.filter(function(tag) &#123; return tag.length; &#125;); // Limit the number of tags if (options.amount) &#123; tags = tags.limit(options.amount); &#125; var sizes = []; tags.sort(&apos;length&apos;).forEach(function(tag) &#123; var length = tag.length; if (~sizes.indexOf(length)) return; sizes.push(length); &#125;); var length = sizes.length - 1; tags.forEach(function(tag) &#123; var ratio = length ? sizes.indexOf(tag.length) / length : 0; var size = min + ((max - min) * ratio); var style = &apos;font-size: &apos; + parseFloat(size.toFixed(2)) + unit + &apos;;&apos;; if (color) &#123; var midColor = startColor.mix(endColor, ratio); style += &apos; color: &apos; + midColor.toString(); &#125; result.push( // 增加/index.html 跳转地址 &apos;&lt;a href=&quot;&apos; + self.url_for(tag.path) + &apos;index.html&quot; style=&quot;&apos; + style + &apos;&quot;&gt;&apos; + (transform ? transform(tag.name) : tag.name) + &apos;&lt;/a&gt;&apos; ); &#125;); return result.join(separator);&#125;function Color(color) &#123; if (typeof color === &apos;object&apos;) &#123; this.r = color.r; this.g = color.g; this.b = color.b; this.a = color.a; &#125; else if (typeof color === &apos;string&apos;) &#123; this.parse(color); &#125; else &#123; throw new TypeError(&apos;color is required!&apos;); &#125; if (this.r &lt; 0 || this.r &gt; 255 || this.g &lt; 0 || this.g &gt; 255 || this.b &lt; 0 || this.b &gt; 255 || this.a &lt; 0 || this.a &gt; 1) &#123; throw new Error(color + &apos; is invalid.&apos;); &#125;&#125;Color.prototype.parse = function(color) &#123; color = color.toLowerCase(); if (colorNames.hasOwnProperty(color)) &#123; var obj = colorNames[color]; this.r = obj.r; this.g = obj.g; this.b = obj.b; this.a = obj.a; return; &#125; var match, txt, code; if (rHex3.test(color)) &#123; txt = color.substring(1); code = parseInt(txt, 16); this.r = ((code &amp; 0xF00) &gt;&gt; 8) * 17; this.g = ((code &amp; 0xF0) &gt;&gt; 4) * 17; this.b = (code &amp; 0xF) * 17; this.a = 1; &#125; else if (rHex6.test(color)) &#123; txt = color.substring(1); code = parseInt(txt, 16); this.r = (code &amp; 0xFF0000) &gt;&gt; 16; this.g = (code &amp; 0xFF00) &gt;&gt; 8; this.b = code &amp; 0xFF; this.a = 1; &#125; else if (rRGB.test(color)) &#123; match = color.match(rRGB); this.r = match[1] | 0; this.g = match[2] | 0; this.b = match[3] | 0; this.a = match[4] ? +match[4] : 1; &#125; else if (rHSL.test(color)) &#123; match = color.match(rHSL); var h = +match[1] / 360; var s = +match[2] / 100; var l = +match[3] / 100; this.a = match[4] ? +match[4] : 1; if (!s) &#123; this.r = this.g = this.b = l * 255; &#125; var q = l &lt; 0.5 ? l * (1 + s) : l + s - (l * s); var p = (2 * l) - q; var rt = h + (1 / 3); var gt = h; var bt = h - (1 / 3); this.r = convertHue(p, q, rt); this.g = convertHue(p, q, gt); this.b = convertHue(p, q, bt); &#125; else &#123; throw new Error(color + &apos; is not a supported color format.&apos;); &#125;&#125;;Color.prototype.toString = function() &#123; if (this.a === 1) &#123; var r = convertRGB(this.r); var g = convertRGB(this.g); var b = convertRGB(this.b); if (this.r % 17 || this.g % 17 || this.b % 17) &#123; return &apos;#&apos; + r + g + b; &#125; return &apos;#&apos; + r[0] + g[0] + b[0]; &#125; return &apos;rgba(&apos; + this.r + &apos;, &apos; + this.g + &apos;, &apos; + this.b + &apos;, &apos; + parseFloat(this.a.toFixed(2)) + &apos;)&apos;;&#125;;Color.prototype.mix = function(color, ratio) &#123; switch (ratio) &#123; case 0: return new Color(this); case 1: return new Color(color); &#125; return new Color(&#123; r: Math.round(mixValue(this.r, color.r, ratio)), g: Math.round(mixValue(this.g, color.g, ratio)), b: Math.round(mixValue(this.b, color.b, ratio)), a: mixValue(this.a, color.a, ratio) &#125;);&#125;;function convertHue(p, q, h) &#123; if (h &lt; 0) h++; if (h &gt; 1) h--; var color; if (h * 6 &lt; 1) &#123; color = p + ((q - p) * h * 6); &#125; else if (h * 2 &lt; 1) &#123; color = q; &#125; else if (h * 3 &lt; 2) &#123; color = p + ((q - p) * ((2 / 3) - h) * 6); &#125; else &#123; color = p; &#125; return Math.round(color * 255);&#125;function convertRGB(value) &#123; var str = value.toString(16); if (value &lt; 16) return &apos;0&apos; + str; return str;&#125;function mixValue(a, b, ratio) &#123; return a + ((b - a) * ratio);&#125;module.exports = tagcloudHelper; 参考地址: https://github.com/xuxianyu/ming/tree/master/hexo 实例地址: https://www.xujiuming.com 本网站就是采用这种方法实现的]]></content>
      <categories>
        <category>骚想法</category>
      </categories>
      <tags>
        <tag>cdn</tag>
        <tag>oss</tag>
        <tag>http/https</tag>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[alias笔记]]></title>
    <url>%2Fming%2Fd0a7cd2b.html</url>
    <content type="text"><![CDATA[#####linux alias 别名设置####有时候有些命令常用 例如 ‘ls -a’ ‘ps -aux’ 这样的 如果每次输入全部 麻烦的很 通过设置别名 可以快速使用1:设定临时 alias 只能在当前shell可用 退出shell 失效12alias asliasNname=&apos;命令&apos;例如: alias psa = &apos;ps -aux&apos; 2:设定永久 alias只需要吧 alias 加入 环境变量配置文件中即可 例如加入 全局环境变量/etc/profile 或者当前用户的环境变量配置中 例如～/.bashrc123456tee -a /etc/profilealias psa=&apos;ps -aux&apos;# ctrl +c 结束录入后 应用 环境变量source /etc/profile 注意: psa = ‘ps -aux’ 这样不行 因为shell语法的格式问题 写python写多了 吗买皮 #####总结: linux别名 可以将一些常用的 但是直接输入 比较长的命令封装起来 向文件追加内容 不一定用tee echo &gt;&gt; 也是可以的 cat都行 不局限命令 能达成功能即可]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用或者有趣的linux命令]]></title>
    <url>%2Fming%2F5e1b0665.html</url>
    <content type="text"><![CDATA[linux版本命令功能描述实例ubuntunautilusubuntu下面 从终端打开文件夹nautilus .*traceroute跟踪域名解析traceroute 域名*hexdump将文件转换成hex码hexdump 文件*tcpdump、wireshark抓包工具*sl一个会动的火车*nohup忽略退出终端信号nohup renwu &amp;*tmux将单个控制台页面切分的工具tmux 启动即可 功能巨强大 适合熟悉linux平台并且有一定的精分症的孩子使用 边编译源码边安装二进制包边解压 简直无敌*netstat查看端口占用情况 配合grep可以查看指定端口的占用情况sudo netstat -apn*top动态查看系统的相关状态如cpu占用等top*grep正则选取*cat输出某个文件内容 或者往某个文件写入内容cat /etc/profile*tee往某个文件中追加内容 以指定字符结尾 未指定 则是EOF结尾tee ./a.txt*alias命名别名alias psa=‘ps -aux’*sed按行操作文本sed ‘$d’ ./fileubuntugnome-screenshot -a局域截图]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 解压windows文件乱码处理]]></title>
    <url>%2Fming%2F5c7769e6.html</url>
    <content type="text"><![CDATA[通过unzip行命令解压，指定字符集unzip -O CP936 xxx.zip (用GBK, GB18030也可以)有趣的是unzip的manual中并无这个选项的说明, unzip –help对这个参数有一行简单的说明。在环境变量中，指定unzip参数，总是以指定的字符集显示和解压文件/etc/environment中加入2行?12UNZIP=”-O CP936”ZIPINFO=”-O CP936”这样Gnome桌面的归档文件管理器(file-roller)可以正常使用unzip解压中文，但是file-roller本身并不能设置编码传递给unzip。]]></content>
      <categories>
        <category>坑</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用docker搭建ssServer]]></title>
    <url>%2Fming%2F409db0cf.html</url>
    <content type="text"><![CDATA[由于gfw的存在 经常需要翻墙 自己手动搭建 ssServer又麻烦 使用docker 使用现成的image简单方便快捷######docker只能在3.10以上的内核的linux系统或者差不多版本的其他系统中运行 所以在购买vps的时候要看清楚是什么架构 内核是否支持docker######docker 下载ssServer镜像 (无法翻墙的请参考 另一篇笔记 docker使用aliyun加速器)···docker pull mritd/shadowsocks···这个镜像是我认识的一个大佬写的、在dockerhub上也是排名第一的shadowsocksServer容器image######启动 ssServer镜像(相关文档地址:https://hub.docker.com/r/mritd/shadowsocks/)···docker run -dt –name ss -p 6443:6443 mritd/shadowsocks -s “-s 0.0.0.0 -p 6443 -m aes-256-cfb -k test123 –fast-open”···本地的ssClient设置ip是你vpsip端口 6443加密方式是aes-256-cfb密码是test123######总结：用已经有的docker容器来做ssServer能够快速的搭建起一个配置好的ssServer 避免自己手工安装配置的繁琐感觉这篇要被查水表]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux使用ss笔记]]></title>
    <url>%2Fming%2F5624ab1d.html</url>
    <content type="text"><![CDATA[由于有个朋友对于在linux上使用ss翻墙不会 特别写个简单的笔记、#######基于ubunut17.04、python3、####1:安装pip31sudo apt install pip3 ####2:通过pip3安装shadowsocks1sudo pip3 install shadowsocks ####3:设置shadowsocksServer属性配置123456789&#123; &quot;server&quot;:&quot;ss服务器ip&quot;, &quot;server_port&quot;:端口, &quot;local_address&quot;:&quot;127.0.0.1&quot;,(本地socks5地址) &quot;local_port&quot;:1080,(本地socks5端口) &quot;password&quot;:&quot;ss服务器密码&quot;, &quot;timeout&quot;:300,(超时时间 ms), “method”:&quot;aes-256-cfb&quot;(加密方式)尽量选择这个 &#125; ####4:启动本地ss1sudo sslocal -c 配置文件地址 ####5:设置代理这里设置代理有很多方式 先说两种常用的1:直接设置整个系统的代理 、通过gfwlist生成ip表 去判别国内国外网站选择性加速2:对某部分程序设置代理、如chrome浏览器 下载个switch代理工具 可以自己设定路由规则也可以通过gfwlist生成相应的ip表 ######总结:ss翻墙 总的来说就是 发起访问—&gt;从本地服务器代理访问、判断是否需要代理—&gt;需要代理的连接远程ssServer 进行代理—-&gt;访问gfw之外的内容]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前端包管理工具npm切换国内源]]></title>
    <url>%2Fming%2F3ff0ec3c.html</url>
    <content type="text"><![CDATA[##在学ng2的时候接触到npm管理包、插件的方式 但是npm默认的源是国外的如果懒的科学上网 又想快速使用 只能使用国内的镜像站点 例如aliyun####当安装npm 完成 可以通过如下的方法去修改npm的源####1.通过config命令npm config set registry https://registry.npm.taobao.orgnpm info underscore （如果上面配置正确这个命令会有字符串response）####2.命令行指定npm –registry https://registry.npm.taobao.org info underscore####3.编辑 ~/.npmrc 加入下面内容(linux 在你的用户目录下 没有就创建 windows在c盘下)registry = https://registry.npm.taobao.org]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分屏工具tmux使用笔记]]></title>
    <url>%2Fming%2F885dd8c4.html</url>
    <content type="text"><![CDATA[linux中 经常使用 终端 一次打开多个终端 很麻烦 不好用 有个很强悍的工具 tmux 很出名的分屏工具ubuntu安装1sudo apt install tmux 然后 在终端输入1tmux 这个时候 终端已经启动tmux 默认是ctrl+b 是快捷键 就是进入tmux切换操作的命令中 例如将当前终端水平分屏 进入 tmux操作 按下双引号1ctrl+b ----&gt;“ 垂直分屏幕 进入tmux 按下%1ctrl+b----&gt;% 可以启动多个不同的窗口 每个窗口可以按照水平垂直分成不同的窗体窗体之间 切换1ctrl+b ----&gt;方向键 改变窗体的大小1ctrl+b----&gt;按住ctrl 然后方向键改变 #####其他操作 请查阅 man tmux]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派组装运行]]></title>
    <url>%2Fming%2F4c838b91.html</url>
    <content type="text"><![CDATA[####自己闲的蛋疼 购买了个树莓派3b 由于不太懂这个 买配件 组装运行起来耗费了好久 特此做个笔记#####树莓派配件组成:1:板子:就是生产好的树莓派的电子板2:电源:3b版本需要5v 2.5A的电源 如果外接设备多的话要按需增加电源3:sd卡:做系统启动 存储的sd存储卡4:散热装备:散热片两个(cpu、gpu)、风扇一个5:外壳:还是需要一个外壳的 不然贼丑#####树莓派组装1:先把sd卡刷个系统 随便刷 个官方的系统就行2:把散热片贴好 。风扇接好 风扇接46脚 红色4(供电) 黑色6 如果想可关闭电风扇或者控温自动控制 需要一个继电器、一个温度感应模块3:插上网线4:接上电源5:开机需要会自己搭建内网或者扫描设备ip然后通过ssh协议连接上树莓派即可#####总结:成本大概在300-400左右 其实很不错了 这个价位能有这个配置这个玩法 很满足了 就是有点麻烦什么都要自己折腾 树莓派可以做很多东西 据大佬说 树莓派最终梦想就是自己造一架基于树莓派的无人机]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派链接wifi]]></title>
    <url>%2Fming%2F8634a6bb.html</url>
    <content type="text"><![CDATA[####买回来好久 一直都是被舍友拿去垫电脑去了 今天有时间 拿出来把wifi模块启动起来 以后 就算垫桌子 也能用起来#####前提条件1:pi能正常启动2:能链接pi的shell3:pi的版本必须由无线网卡 pi 3b版本 带了无线网卡了#####具体操作1:登录shell2:查看 附近wifi (多个无线网卡的大兄弟 请使用 ifconfig 查看选择一个网卡) 一般一个无线网卡 是wlan01sudo iwlist wlan0 scan 每一个cell都是一个wifi热点 essid 是名字(中文的wifi名字是显示的\xSS这种忽略即可 反正设置的时候直接输入中文即可) 注意:如果由中文的wifi热点名字 会转成其他格式的字符串 会出现\xAs\xDD….这样的 如果你需要转换成相应的中文 可以尝试用python来转看看具体操作如下: 打开python控制台 输入12str=b&apos;乱码的字符串&apos;print (str.decode(&apos;utf-8&apos;)) 3:编辑 wifi模块的配置文件 /etc/wpa_supplicant/wpa_supoplicant.conf12345##设置network中的参数 network=&#123; ssid=&quot;wifi热点名称(中文直接输入 不需要转码)&quot; psk=&quot;wifi密码&quot; &#125; 4:重启12#重启shutdown -r now 5:还是先用线链接pi的shell 然后查看 network的信息1ifconfig 123456789101112131415161718192021222324eth0 Link encap:Ethernet HWaddr b8:27:eb:43:64:4d UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:224 errors:0 dropped:0 overruns:0 frame:0 TX packets:166 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:20583 (20.1 KiB) TX bytes:23454 (22.9 KiB)lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:136 errors:0 dropped:0 overruns:0 frame:0 TX packets:136 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:11472 (11.2 KiB) TX bytes:11472 (11.2 KiB)wlan0 Link encap:Ethernet HWaddr b8:27:eb:16:31:18 inet addr:192.168.3.111 Bcast:192.168.3.255 Mask:255.255.255.0 inet6 addr: fe80::bd80:706f:310d:a21b/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:89315 errors:0 dropped:31 overruns:0 frame:0 TX packets:63804 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:125457894 (119.6 MiB) TX bytes:6884073 (6.5 MiB) 无线网卡的ip是 wlan0中的 第二行 inet addr:192.168.3.111这个时候可以拔掉网线使用 wlan0中的ip链接pi了 ####总结:树莓派 3b版本中已经集成了wifi模块 只需要配置wifi热点信息重启就行了]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派vnc链接]]></title>
    <url>%2Fming%2F52f5e4f0.html</url>
    <content type="text"><![CDATA[###树莓派开启wifi模块后 想看看树莓派的桌面 然后就开启了vnc服务 玩玩####安装vnc服务1sudo apt-get install tightvncserver ####设置vnc链接的密码（最长只能8位 超过的截取前8位）1vncpasswd ####添加开机启动1sudo vim /etc/init.d/vncserver 内容:12345678910111213141516171819202122#!/bin/sh#如果不是 pi用户 请 改这里的user 登录的时候 也用这里的userexport USER=&apos;pi&apos; eval cd ~$USER case &quot;$1&quot; in start) # 启动命令行。此处自定义分辨率、控制台号码或其它参数。 su $USER -c &apos;/usr/bin/vncserver -depth 16 -geometry 1024x768 :1&apos; echo &quot;Starting VNC server for $USER &quot; ;; stop) # 终止命令行。此处控制台号码与启动一致。 su $USER -c &apos;/usr/bin/vncserver -kill :1&apos; echo &quot;vncserver stopped&quot; ;; *) echo &quot;Usage: /etc/init.d/vncserver &#123;start|stop&#125;&quot; exit 1 ;;esacexit 0 添加执行权限 更新开机启动12sudo chmod 755 /etc/init.d/vncserversudo update-rc.d vncserver defaults ###登录通过vnc工具登录账户 pi(脚本中的user)密码 设置的vnc密码 不是ssh密码 ###多个桌面开启默认是端口:5900 如果第一个窗口推荐在5900+1。。。以此类推 不要用默认的 有坑 ####总结: vnc链接树莓派的桌面 感觉卡卡的 玛格及]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring bean 加载顺序解决办法]]></title>
    <url>%2Fming%2F50d1ed2b.html</url>
    <content type="text"><![CDATA[在使用SpringBeanManager工具类的时候 发现 spring boot 是根据目录取扫描装配bean 的由于我把 这个工具类放在com.ming.core.utils下 导致 这个加载顺序在一些初始化服务之后看了一下相关资料有四种解决方法在配置中调整顺序先加载的 写在最上面 但是呢 我懒的写配置文件123&lt;!--bean声明--&gt; &lt;bean class=&quot;com.ming.core.utils.SpringBeanManager&quot;/&gt; &lt;bean class=&quot;com.ming.base.init.SystemInit&quot; init-method=&quot;init&quot; destroy-method=&quot;destroy&quot; /&gt; 使用@Autowired 注入到所需的服务中其实就是跟在配置中写 ref差不多的功能 spring 会解析到这个会依赖springBeanManager 所以会先加载springBeanManager这种方式 有点丑 但是可以解决问题 123456789101112131415161718@Componentpublic class SystemInit &#123; /** * 使 SpringBeanManager在SystemInit之前初始化 * * @author ming * @date 2017-11-09 17:52 */ @Autowired private SpringBeanManager springBeanManager; @PostConstruct public void init() &#123; //初始化 script job bean GroovyBeanInit.InitScriptJob(); &#125;&#125; 使用DependsOn这个是要配置一个或者多个 注册的bean的名称 而不是类的名称 123456789101112// 等待springBeanManager 装载完毕 初始化本类@DependsOn(value = &quot;springBeanManager&quot;)@Componentpublic class SystemInit &#123; @PostConstruct public void init() &#123; //初始化 script job bean GroovyBeanInit.InitScriptJob(); &#125;&#125; 使用@Order注解此方式 在spring boot 中暂时无法使用 等找到相关文档 再看看是什么原因 无法使用####总结：一般来说 对于加载顺序有强烈要求的地方 不是很多 如果有 使用DependsOn 基本能解决了]]></content>
      <categories>
        <category>坑</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cloud 总览]]></title>
    <url>%2Fming%2F73f341d0.html</url>
    <content type="text"><![CDATA[公司想切换到spring cloud上所以我找了本书看看 大致上知道了spring cloud的各部分组件 也算是用的比较熟练了但是好记性不如烂笔头 所以写一波笔记 防止遗忘####目录综述注册中心(eureka、consul、zk)微服务服务端、客户端(feign)容错、负载均衡(ribbon、hystrix)配置中心(config)网关(zuul)消息总线(bus、stream)定时任务调度(qz)分布式调用链日志(sleuth:基于zipkin的)搭建个人基于spring cloud 的脚手架遇到的问题####综述spring cloud 提供一整套分布式微服务的解决方案联系到云原生(cloud native)这个概念我个人觉得 他是把微服务的架构+容器+自动化运维整合到一起提出的概念在基于docker+k8s这样的或者类似的平台下 快速开发、切入到已有的分布式环境中的应用####注册中心在微服务架构中 较为核心的应该就是注册中心了 服务的治理、使用都需要注册中心的协助spring cloud支持比较好的注册中心 大致有三种 eureka、consul、zookeeper这三个 各有各的好 不过现在来说 consul可能功能更加齐全 更加好用一点 这个在后续的详细的笔记详说####微服务的服务端、客户端######服务端:这个就是很普通的http接口 莓什么好说的 现在http大部分还是使用1.0。或者1.1 性能说实话一般 不过差不多够用 如果有特殊需求 完全可以选择其他协议例如我北京的有个大佬朋友 他们也是spring cloud +docker +k8s技术栈 他们就要把http协议切换到tcp协议 照样刚但是后续http2.0出来后 我觉得性能差别应该不会太大了 毕竟 http2.0也是基于二进制 还有其它的功能 我比较看好 http2.0######客户端:简陋点直接用restTemplate也是可以访问调用的 但是不好管理 而且麻烦 建议使用feign去申明接口即可调用但是这个也有点坑举个例子 在spring mvc 4.3 之后 是提供GetMapping这样的封装RequestMapping的接口 但是feign不支持的 还有其他的坑 到详细的笔记细说####容错、负载均衡######容错:spring cloud 是基于hystrix来做容错的 容错其实就是 发现错误 马上关闭停止对错误的节点的访问、有相应的降级措施情况下 进行服务降级 保证服务的可用当然也提供请求缓存、请求合并 turbine也可以基于hystrix、dashboard来进行集群的状态监控######负载均衡:spring cloud 是基于ribbon来做客户端负载均衡的 首先 会去注册中心找到注册列表 通过轮寻方式 去负载均衡 当然可以重写负载均衡器(LoadBalancerClient) 也是可以使用其他更加优越的算法的 毕竟spring cloud 只是提供基础实现####配置中心国内的话 各个大公司基本都有各自的配置中心的实现 我们公司用的是baidu的disconf 用起来也就那回事吧 不如spring cloud configconfig 是使用 git 或者svn 来做配置仓库 这天生站在巨人肩膀上config 可以实现集中管理各个集群的配置 而且安全性较高 访问安全、数据的加密解密(对称加密需要替换jre、还支持rsa这种非对称加密)还可以通过配合bus组件 进行动态修改集群配置 这一点是很重要的 因为很多参数根据实际情况进行微调是非常需要的####网关就是统一对访问进行管理的地方 例如鉴权、限制等等网关 说实话 如果实力强劲 就不会选择这个来用zuulnginx+lua功能不比这个东西强？####消息总线说的这么高端其实就是一个mq的使用 bus主要是消息传递 stream主要是发布订阅事件没什么特别的spring cloud bus 或者stream 天然支持 rabbit或者kafka 都差不多吧 看具体情况选择 个人比较倾向rabbit####定时任务调度定时任务 是每个系统必须的一个模块一般也就三种方式1:基于jdk的timer timerTask方式 这种方式简单粗暴 但是需要自己实现一些复杂的功能2:基于spring 的 scheduled task 这个也是不太适合企业级使用3:qz(quartz)功能多 支持集群环境下调度 但是需要数据库支持 不用说 肯定qz的 不然要写死####分布式调用链日志sleuth 是基于zipkin的一套分布式调用链跟踪组件说起这个 公司的zipkin还是我们组负责的 老大带我们去引入zipkin 搞死人了调用链呢 是跟踪每个请求从发起 到调用各个服务 一直到db操作一整链记录这些日志 方便优化、跟踪错误这个到详细笔记细说 这个和业务日志、操作日志是不同的####遇到的问题这个说实话还是遇到很多问题的 因为我基于公司已有的架构 使用spirng cloud 从新整合 还是有点坑的 详细笔记再说####总结:spring cloud 基本上就这些组件 spring cloud + docker + k8s 这一套可以说是现在做微服务 云原生的标准套路了]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot 监控模块 actuator笔记]]></title>
    <url>%2Fming%2F1a1c1aa1.html</url>
    <content type="text"><![CDATA[###actuator 是spring boot 提供的一个监控的工具直接访问 相应端点(rest 接口)端点分为三种:应用配置类/autoconfig 获取应用的自动配置相关参数/beans 获取应用的所有bean/configprops 应用中配置的属性信息 设置enabled = false 关闭这个端点/env 获取应用可以用的环境信息/mappings 返回 mvc控制器 映射关系 也就是接口的信息/info 返回自定义信息 设置 info.app.name=ming info返回ming度量指标类/metrics 返回各类重要的度量指标 内存、线程、垃圾回收信息 通过使用 counterServices 来自定义 信息/metrics/{name} 获取指定的信息/health 获取各类健康的指标 磁盘、数据库链接是否可以用、rabbit、solr、redis是否可用/dump 项目线程信息/trace 返回基本http跟踪 保留100条操作控制类/shutdown 关闭应用 post请求 需要设定开启endpoints.shutdown.enabled: true]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot 项目打包docker image 插件方式]]></title>
    <url>%2Fming%2Fdbafeaad.html</url>
    <content type="text"><![CDATA[####spring boot 打包成docker image 会更加方便使用1:配置编译jar选项2:配置maven docker 插件3:上传到私服4:自动化脚本####配置编译jar如果是继承spring boot 的pom 直接如下配置即可1234&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&lt;/plugin&gt; 然后 mvn package 即可 这个时候 打包的jar 里面带有main-class的默认配置 也会有需要的依赖包可以直接 java -jar ming.jar 方式运行 ####配置 maven docker 插件这个插件略坑 在windows上 docker build比较操蛋 linux下docker又需要root权限运行 略坑123456789101112131415161718192021&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;maven.docker.version&#125;&lt;/version&gt; &lt;configuration&gt; &lt;!--镜像名称--&gt; &lt;imageName&gt;$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125;&lt;/imageName&gt; &lt;!--docker file位置--&gt; &lt;dockerDirectory&gt;src/main/docker&lt;/dockerDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;!-- 编译jar路径 --&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;!--编译jar 所在文件夹--&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;!--编译的jar 名称--&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt;&lt;/plugin&gt; 然后使用 mvn package docker:build 编译构建即可 最好是在linux环境下 使用root 权限 ####上传到私服我这里选择的是上传到 aliyun 提供的镜像仓库123$ sudo docker login --username=18120580001@163.com registry.cn-hangzhou.aliyuncs.com$ sudo docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/mingimages/ming:[镜像版本号]$ sudo docker push registry.cn-hangzhou.aliyuncs.com/mingimages/ming:[镜像版本号] ####参考地址:https://github.com/xuxianyu/ming]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cloud 注册中心模块笔记]]></title>
    <url>%2Fming%2F4c352ff0.html</url>
    <content type="text"><![CDATA[eureka客户端:服务注册相关配置 注册的中心、心跳、注册信息缓存时间 org.springframework.cloud.netflix.eureka.EurekaClientConfigBean服务实列配置信息 服务实列的名称、地址、健康检查路径 org.springframework.cloud.netflix.eureka.EurekaInstanceConfigBeaneureka服务端:配置相关检测 eureka.server中配置 org.springframework.cloud.netflix.eureka.server.EurekaServerConfigBean 服务端相关配置配置名称说明备注eureka.client.register-with-eureka=true是否向注册中心注册自己true=注册，false=不注册eureka.instance.lease-renewal-interval-in-seconds=30续约服务间隔 心跳间隔心跳间隔 30seureka.instance.lease-expiration-duration-in-seconds=90服务失效时间，当90s后没有成功续约，服务失效默认失效时间 90seureka.client.registry-fetch-interval-seconds=30注册信息缓存时间默认30seureka.instance.hostname=nameeureka服务地址域名或者ipeureka.server.enable-self-preservation=false是否开启自我保护 默认trueeureka server自我保护机制: 十五分钟内心跳失败低于85% 出现 自我保护机制eureka.client.serviceUrl.defaultZone指定默认zone(可用区)如果没有为region(区域)配置zone(可用区)那么使用默认zone(可用区) 多个用,分割,带安全校验的格式(http://:@localhost:10000/eureka)eureka.client.availability-zoneszone(可用区)列表region一个对应多个zone(可用区) 一个区域可以有多个可用区eureka.instance.instanceId=${spring.application.name}:${random.int}设定 客户端的明名规则防止冲突和server.port=0结合使用management.context-path设置 上下文前缀如果设置了这个 需要再eurekaclient相应设置/health 和/info端点 否则eureka server端无法获取 客户端的健康情况eureka.instance.statusPageUrlPath=${management.context-path}/info设置info端点如果客户端修改了端点相应信息 必须要设置这个eureka.instance.healthCheckUrlPath=${}/health设置health端点如果客户端修改了端点相应信息 必须要设置这个]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot data jpa 扩充JpsRepository]]></title>
    <url>%2Fming%2F19f1b366.html</url>
    <content type="text"><![CDATA[#####jpa扩充jpaRepository接口的方法1:定义一个接口 继承于 JpaRepository2:定义接口实现类3:定义 接口加载工厂方法4:repository 继承自定义接口5:启动类使用 自定义加载工厂####1:定义扩充方法接口123456789101112131415161718/** * 基于jpa的默认jpaRepository实现自己的repository接口 * NoRepositoryBean 不会创建接口的实例 必须要加这个注解 * * @author ming * @date 2017-08-28 11点 */@NoRepositoryBeanpublic interface BaseRepository&lt;T, ID extends Serializable&gt; extends JpaRepository&lt;T, ID&gt; &#123; /** * 使用原生sql 查询 list列表 * * @author ming * @date 2017-08-29 16点 */ List&lt;T&gt; findListByNativeSql(String sql, Class&lt;T&gt; clzss);&#125; 2:定义这个接口的实现类12345678910111213141516public class BaseRepositoryImpl&lt;T, TD extends Serializable&gt; extends SimpleJpaRepository&lt;T, TD&gt; implements BaseRepository&lt;T, TD&gt; &#123; private final EntityManager entityManager; //父类没有不带参数的构造方法，这里手动构造父类 public BaseRepositoryImpl(Class&lt;T&gt; domainClass, EntityManager entityManager) &#123; super(domainClass, entityManager); this.entityManager = entityManager; &#125; @Override @SuppressWarnings(&quot;unchecked&quot;) public List&lt;T&gt; findListByNativeSql(String sql, Class&lt;T&gt; clzss) &#123; return entityManager.createNativeQuery(sql, clzss).getResultList(); &#125;&#125; 3: 定义加载自定义repository接口工厂12345678910111213141516171819202122232425262728293031323334353637public class BaseRepositoryFactoryBean&lt;R extends JpaRepository&lt;T, ID&gt;, T, ID extends Serializable&gt; extends JpaRepositoryFactoryBean&lt;R, T, ID&gt; &#123; public BaseRepositoryFactoryBean(Class&lt;? extends R&gt; repositoryInterface) &#123; super(repositoryInterface); &#125; @Override protected RepositoryFactorySupport createRepositoryFactory(EntityManager entityManager) &#123; return new BaseRepositoryFactory(entityManager); &#125; //创建一个内部类，该类不用在外部访问 private static class BaseRepositoryFactory&lt;T, ID extends Serializable&gt; extends JpaRepositoryFactory &#123; private final EntityManager em; public BaseRepositoryFactory(EntityManager em) &#123; super(em); this.em = em; &#125; //设置具体的实现类是BaseRepositoryImpl @SuppressWarnings(&quot;unchecked&quot;) @Override protected Object getTargetRepository(RepositoryInformation information) &#123; return new BaseRepositoryImpl&lt;T, ID&gt;((Class&lt;T&gt;) information.getDomainType(), em); &#125; //设置具体的实现类的class @Override protected Class&lt;?&gt; getRepositoryBaseClass(RepositoryMetadata metadata) &#123; return BaseRepositoryImpl.class; &#125; &#125;&#125; 4:repository继承自定义接口123@Repositorypublic interface UserRepository extends BaseRepository&lt;User, Long&gt; &#123;&#125; 5:启动类使用自定义加载工厂12345678910111213141516/** * 启动类 要位于最顶层包 他只会扫描 同级包和子包 * * @author ming * @date 2017-06-17 */@SpringBootApplication(scanBasePackages = &quot;com.ming&quot;, excludeName = &#123;&quot;classpath*:application.yml&quot;, &quot;classpath*:application-aliyun.yml&quot;&#125;)// jpa使用自定义加载工厂@EnableJpaRepositories(repositoryFactoryBeanClass = BaseRepositoryFactoryBean.class)public class Start &#123; public static void main(String[] args) &#123; SpringApplication.run(Start.class, args); &#125;&#125; 总结:和之前spring中使用jpa差不多套路 主要是自定义一个加载工厂 有点变化]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring resourc笔记]]></title>
    <url>%2Fming%2Fd7cd3a26.html</url>
    <content type="text"><![CDATA[##1:resource接口Resource是spring 中加载资源的顶级接口 主要方法有:boolean exists(); 是否存在资源boolean isOpen(); 资源是否打开 是否开启URL getURL(); 返回可抽象成url的资源的URL对象FIle getFile()；返回底层资源的文件流InputStream getInputStream;返回资源的输入流resource接口关系图：WritableResource： 可写资源接口ByteArrayResource:二进制数组表示资源ClassPathResource:类路径下资源FileSystemResource:文件系统中的资源(绝对路径)InputStreamResource：用输入流返回表示资源ServletContextResource: web容器上下文资源UrlResource:能够访问任何能用URL表示的资源(文件系统、http、ftp等 )PathResource:java7.0以上 能够访问任何通过URL、Path、系统文件路径表示的资源spring可以通过资源地址的特殊标识符来访问相应资源如下表 支持Ant风格去描述资源地址1234在项目中 会出现 &apos;classpath:*.xml&apos; 和&apos;classpath*:*.xml&apos; 在：之前有个* 这个意思是在所有的目录下面寻找 举个例子: 一个项目分为 a(web模块)、b(common模块)、core(核心模块)如果不带* 那么只会加载一个模块的配置 其它模块配置就没加载 所以 写的时候 带上* 比较合适 资源加载spring 提供一套加载资源的方法如下图： 通过ResourceLoader来加载Resource有一个getResource(String location) 只支持按照特殊字符自动匹配 resource类型 但是不支持Ant风格 ResourcePatternResolver 扩展ResourceLoader有一个getResources(String locationPattern) 支持按照特殊字符自动匹配、支持Ant匹配资源 PathMatchingResourcePatternResolver 是spring提供的实现类 如果有必要 可以自己实现 (我觉得自己实现的可能性很小、但是不排除坑爹的地方需要自己实现)##总结:1:特殊字符 classpath、file这样的是spring 提供的 其中classpath 最好使用的时候带上* 避免加载不到资源2:Ant风格 其实就是 ‘ ? ‘代表一个任意字符 ‘ * ‘代表匹配文件中的任意多个字符 ‘ ** ‘ 代表匹配多层路径3: Resource 系列可以单独抽出来 当作加载资源的utils来用4: Resource操作文件的时候 尽量使用getInputStream() 因为getFile()不能加载到jar中的资源]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cloud ribbon 负载均衡笔记]]></title>
    <url>%2Fming%2F878fb6fb.html</url>
    <content type="text"><![CDATA[###ribbon负载均衡必须存在12345@Bean@LoadBalanced//通过再restTemplate中添加拦截器 实现负载均衡、重写uri等功能RestTemplate restTemplate()&#123; return new RestTemplate();&#125; ServiceInstanceChooser 服务实例选择choose 根据serviceId选择一个实例 ####LoadBalancerClient extends ServiceInstanceChooser 负载均衡客户端execute 获取负载均衡后的实例、服务id之后 执行请求reconstructURI 根据实例重写uri 获取服务实例后 重写uri ####LoadBalancerAutoConfiguration 自动配置类 必须存在 restTemplate 通过http请求 添加拦截器来实现负载均衡 必须存在 LoadBalancerClient 的实现核心功能:static class LoadBalancerInterceptorConfig通过这个配置类 配置负载均衡拦截器 向restTemplate添加负载均衡功能ribbonInterceptor(LoadBalancerClient loadBalancerClient,LoadBalancerRequestFactory loadBalancerRequestFactory); 创建 负载均衡拦截器restTemplateCustomizer(LoadBalancerInterceptor loadBalancerInterceptor);为restTemplate设置负载均衡拦截器通过执行 负载均衡器的execute方法来选择实例和重写uri、执行请求 static class RetryAutoConfiguration 自动重试机制配置也是通过创建重试拦截器 添加到restTemplate中 来设置自动重试 ####ILoadBalancer获取服务实例不是采用serviceInstancerChooser获取的，而是 netflix ribbon中的ILoadBalancer查看 ribbon实现的LoadBalancerClient的getServer方法 就看得到addServers 添加实例chooseServer 根据负载均衡策略获取一个实例markServerDown 标记实例不可用getReachableServers 获取可用实例getAllServers 获取所有实例里面主要就是维护实例列表和获取列表方法、server类定义了一个服务节点的基本信息实现类： AbstractLoadBalancer implements ILoadBalancer 负载均衡器 抽象类抽象定义:serverGroup：ALL(所有)、STATUS_UP(可用)、STATUS_NOT_UP(不可用)实现的方法：chooseServer 调用接口的chooseServer(null) 选择实例的时候忽略key的条件判断抽象方法:abstract getServerList(serverGroup) 根据实例组 枚举来获取 相应实例列表abstract getLoadBalancerStats() 获取负载均衡 统计数据 NoOpLoadBalancer extends AbstractLoadBalancer BaseLoadBalancer extends AbstractLoadBalancer 实现了基本的负载均衡器定义可用实例集合 allServerList 、upServerList定义负载均衡统计信息 LoadBalancerStats定义 IPing=null 需要注入定义 IPingStrategy iping执行策略 默认使用 BaseLoadBalancer中的SerialPingStrategy 线性执行策略 通过重写IPingStrategy 来使用更高效率的 ping策略定义 IRule 负载均衡处理规则 默认使用RoundRobinRule 线性负载均衡规则启动 ping任务 默认pingIntervalSeconds=10s 使用Timer 执行定时任务 maxTotalPingTimeSeconds=5s最大执行时间实现 ILoadBalancer 基本操作 addServers 、chooseServer、markServerDown、getReachAbleServers、getAllServers定义 其他附加的的信息 例如 IClientConfig、changeListeners、serverStatusListeners等 DynamicServerListLoadBalancer extends AbstractLoadBalancer 动态实例负载均衡器定义 isSecure = false 默认不使用https定义 useTunnel =false 是否使用隧道 估计是是否使用pptp协议隧道的意思定义 ServerList serverListsImpl 实例列表 serverList 有获取初始化服务列表和获取更新的服务列表两个方法 查看实现类 org.springframework.cloud.netflix.ribbon.eureka.EurekaRibbonClientConfiguration#ribbonServerList DiscoveryEnabledNIWSServerList–》DomainExtractingServerList来构建默认的serverList 获取初始化服务方法、更新服务方法 通过#obtainServersViaDiscovery 方法实现 这个是客户端 获取服务端注册信息 转换成本地缓存 serverList方法定义 ServerListFilter filter 过滤器 根据过滤条件过滤实例定义 ServerListUpdater.UpdateAction 服务更新器具体实现定义 ServerListUpdater 服务更新器 通过updateListOfServers 先获取要更新的列表–》根据过滤条件 过滤 –》 添加到serverListServerListUpdater 接口:start 启动服务更新器stop 关闭服务更新器getLastUpdate 获取最后更新时间戳getDurationSinceLastUpdateMs 获取上一次到现在的时间间隔getNumberMissedCycles 获取错过的更新期数getCoreThreads 获取核心线程数PollingServerListUpdater实现类:默认实现 使用定时任务 定时从eureka server 拉取EurekaNotificationServerListUpdater实现类:通过eureka事件监听 来驱动 ZoneAwareLoadBalancer extends DynamicServerListLoadBalancer 区域感知负载均衡器 RibbonClientConfiguration ribbon 客户端配置ribbonClientConfig 设置ribbonClient 配置ribbonRule 设置负载均衡 处理规则 实现ribbonPing 设置负载均衡 ping 方式实现ribbonServerList 设置实例列表static RestClientRibbonConfiguration 配置ribbon的restClient相关参数 ribbonRestClient 根据ribbon相关配置 获取 restClientribbonLoadBalancer 获取负载均衡器ribbonServerListFilter 设置负载均衡服务的过滤器ribbonLoadBalancerContext 负载均衡器上下文retryHandler 重试处理serverIntrospector 实例拦截器ServiceInstance 服务实例存储实例的 serviceId 、host、port、isSecure(是否使用https)、uri、metaData(元数据map)]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring bean manager utils 笔记]]></title>
    <url>%2Fming%2Fbb781540.html</url>
    <content type="text"><![CDATA[在使用spring 中总有地方要求获取bean或者注册bean 所以找了部分资料 抄袭了几波 合并成如下工具类主要功能 :获取bean手动注册bean删除手工注册的bean123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242import com.google.common.collect.Maps;import org.springframework.beans.BeansException;import org.springframework.beans.factory.DisposableBean;import org.springframework.beans.factory.support.BeanDefinitionBuilder;import org.springframework.beans.factory.support.DefaultListableBeanFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.core.Ordered;import org.springframework.core.annotation.Order;import org.springframework.stereotype.Component;import javax.annotation.PostConstruct;import java.lang.annotation.Annotation;import java.util.Map;/** * 对操作spring applicationcontext提供基本封装 方便使用 * 使用order 最先加载 * * @author ming * @date 11:00 */@Component//预期在容器最开始加载 暂时这个无法生效 如果需要这个bean 优先加载 请调整依赖 来调整bean加载顺序@Order(Ordered.HIGHEST_PRECEDENCE)public class SpringBeanManager implements ApplicationContextAware, DisposableBean &#123; /** * spring bean上下文 * * @author ming * @date 11:00 */ private static ApplicationContext applicationContext; /** * 获取BeanFactory 进行动态注册bean 删除bean * * @author ming * @date 2017-11-10 15:51 */ private static DefaultListableBeanFactory defaultListableBeanFactory; /** * 手动注册的bean 名称列表 必须保证 每个使用它的地方 是一样的 * * @author ming * @date 2017-11-10 15:54 */ private static volatile Map&lt;String, Class&lt;?&gt;&gt; manualRegisterBeanMap = Maps.newConcurrentMap(); /** * 初始化 beanFactory * * @author ming * @date 2017-11-10 15:52 */ @PostConstruct public void init() &#123; //获取 bean factory defaultListableBeanFactory = (DefaultListableBeanFactory) applicationContext.getAutowireCapableBeanFactory(); &#125; /** * 动态注入bean * * @param beanName * @param beanClazz * @author ming * @date 2017-11-09 16:50 */ public static void registerBean(String beanName, Class&lt;?&gt; beanClazz) &#123; checkDefaultListableBeanFactory(); //创建beanBuilder BeanDefinitionBuilder beanDefinitionBuilder = BeanDefinitionBuilder.genericBeanDefinition(beanClazz); //注册bean defaultListableBeanFactory.registerBeanDefinition(beanName, beanDefinitionBuilder.getBeanDefinition()); //添加手工注册的beanName 到集合 manualRegisterBeanMap.put(beanName, beanClazz); &#125; /** * 删除bean * * @param beanName * @author ming * @date 2017-11-10 15:45 */ public static void removeBean(String beanName) &#123; //当试图删除 非手动注册的bean的时候 if (!manualRegisterBeanMap.keySet().contains(beanName)) &#123; throw new UnsupportedOperationException(&quot;不能删除非手动注册的bean&quot;); &#125; checkDefaultListableBeanFactory(); defaultListableBeanFactory.removeBeanDefinition(beanName); manualRegisterBeanMap.remove(beanName); &#125; /** * 根据名称 获取bean * * @param name 注册的bean名称 * @return T * @author ming * @date 11:19 */ @SuppressWarnings(&quot;unchecked&quot;) public static &lt;T&gt; T getBeanByName(String name) &#123; checkApplicationContext(); return (T) applicationContext.getBean(name); &#125; /** * 根据类型 获取bean * * @param clazz 注册bean的类型 * @return T * @author ming * @date 11:20 */ public static &lt;T&gt; T getBeanByType(Class&lt;T&gt; clazz) &#123; checkApplicationContext(); return applicationContext.getBean(clazz); &#125; public static &lt;T&gt; T getbeanByNameAndType(String beanName, Class&lt;T&gt; clazz) &#123; checkApplicationContext(); return applicationContext.getBean(beanName, clazz); &#125; /** * 获取application中所有注册的bean 列表 * * @return String[] * @author ming * @date 2017-08-28 16点 */ public static String[] getBeanDefinitionNames() &#123; checkApplicationContext(); return applicationContext.getBeanDefinitionNames(); &#125; /** * 统计application中所有bean的数量 * * @return Integer * @author ming * @date 2017-08-28 17点 */ public static Integer getBeanDefinitionCount() &#123; checkApplicationContext(); return applicationContext.getBeanDefinitionCount(); &#125; /** * 根据注解获取 beanNameList * * @param annotation * @return String[] * @author ming * @date 2017-08-28 16点 */ public static String[] getBeanNameListByAnnotation(Class&lt;? extends Annotation&gt; annotation) &#123; checkApplicationContext(); return applicationContext.getBeanNamesForAnnotation(annotation); &#125; /** * 根据bean类型获取所有的bean * * @param clazz * @return String[] * @author ming * @date 2017-08-28 16点 */ public static String[] getBeanNamesForType(Class clazz) &#123; checkApplicationContext(); return applicationContext.getBeanNamesForType(clazz); &#125; /** * 根据类型 获取 所有这个类型的bean map 键为bean名字 值为注册的bean * * @param clazz * @return Map * @author ming * @date 2017-08-28 16点 */ public static &lt;T&gt; Map&lt;String, T&gt; getBeansOfType(Class&lt;T&gt; clazz) &#123; checkApplicationContext(); return applicationContext.getBeansOfType(clazz); &#125; /** * 检测applicationcontext是否可用 * * @author ming * @date 2017-08-28 17点 */ private static void checkApplicationContext() &#123; if (applicationContext == null) &#123; throw new NullPointerException(&quot;spring applicationContext is null !!!&quot;); &#125; &#125; /** * 检测 defaultListableBeanFactory * * @author ming * @date 2017-11-10 15:47 */ private static void checkDefaultListableBeanFactory() &#123; if (defaultListableBeanFactory == null) &#123; throw new NullPointerException(&quot; spring defaultListableBeanFactory is null !!!&quot;); &#125; &#125; /** * 销毁方法 * * @author ming * @date 2017-08-28 17点 */ @Override public void destroy() throws Exception &#123; applicationContext = null; &#125; /** * 设置上下文 * * @author ming * @date 11:17 */ @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; SpringBeanManager.applicationContext = applicationContext; &#125;&#125; ####总结:看这个工具类的实现 就清晰的知道了 beanFactory的一些功能 和之前学习的applicationContext、beanFactory 联系起来了]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot 全局处理异常笔记]]></title>
    <url>%2Fming%2F869ed45a.html</url>
    <content type="text"><![CDATA[####全局异常处理在web中 异常也分为系统异常和业务异常 可以通过增强控制器 来对异常进行全局处理1:创建业务异常类1234567891011121314151617181920212223242526272829import lombok.Data;import java.util.Map;/** * 自定义服务异常 * * @author ming * @date 2017-06-24 */@Datapublic class ServiceException extends RuntimeException &#123; /** * 异常编码 */ private int code; /** * 消息 */ private String msg; /** * 扩展参数 */ private Map&lt;String, Object&gt; extParams;&#125; 2:创建业务异常枚举类12345678910111213141516171819202122import lombok.Getter;/** * 错误码表 * * @author ming * @date 2017-07-16 */@Getterpublic enum ExceptionConstants &#123; ERROR(1,&quot;业务异常&quot;); private Integer num; private String content; ExceptionConstants(Integer num, String content) &#123; this.num = num; this.content = content; &#125;&#125; 3:如何抛出异常这里粗糙的直接抛出枚举值如果有需要 可以建立业务异常服务 统一管理错误码和错误信息 动态的变更业务异常提示也可以继承 细分异常 例如 有的是参数错误 、有的是请求未授权之类的1throw new ServiceException(ExceptionConstants.ERROR.getNum(),ExceptionConstants.ERROR.getContent()); 4:建立增强controller 全局异常捕捉这里通过@ControllerAdvice增强通过@ExceptionHandler 捕捉异常1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import com.ming.base.exception.ServiceException;import lombok.extern.slf4j.Slf4j;import org.apache.commons.lang3.exception.ExceptionUtils;import org.springframework.web.bind.annotation.ControllerAdvice;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.ResponseBody;import javax.servlet.http.HttpServletRequest;/** * 全局异常处理 * * @author ming * @date 2017-11-10 13:58 */@ControllerAdvice@Slf4jpublic class BaseGlobalExceptionHandler &#123; @ExceptionHandler(value = Exception.class) @ResponseBody public ReturnJsonBody defaultErrorHandler(HttpServletRequest req, Exception e) throws Exception &#123; ReturnJsonBody rb = new ReturnJsonBody(); if (e instanceof ServiceException) &#123; ServiceException se = (ServiceException) e; rb.setCode(se.getCode()); rb.setMsg(se.getMsg()); &#125; else &#123; rb.setCode(1); rb.setMsg(&quot;系统异常&quot;); e.printStackTrace(); rb.setStack(ExceptionUtils.getStackTrace(e)); /*try &#123; addServerExceptionLog(req, e); &#125; catch (Exception ex) &#123; LOGGER.error(&quot;add server exception error &#123;&#125;&quot;, ExceptionUtils.getStackTrace(ex)); &#125;*/ &#125; return rb; &#125; // public abstract void addServerExceptionLog(HttpServletRequest request, Throwable throwable);&#125; ####总结:通过增强controller 来捕捉全局mvc异常 这样第一可以返回指定格式错误信息 第二 可以捕捉业务异常]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot 全局处理返回数据格式笔记]]></title>
    <url>%2Fming%2Fba648708.html</url>
    <content type="text"><![CDATA[####全局处理json数据返回格式在前后端分离中 前后端为了更好的交互 应该指定一个较为通用的数据返回格式基本上都是code+data 方式返回在spring mvc 中通过对controller全局增强 来进行处理1:制定 返回json数据返回大致格式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 返回json 字符串格式 * json接口 返回的字符串格式 * * @author ming * @date 2017-11-10 12:56 */@Data@NoArgsConstructorpublic class ReturnJsonBody implements Serializable &#123; /** * 状态码 */ private long code; /** * 数据 */ private Object data; /** * 附加信息 */ private String msg; /** * 异常信息 */ private String stack; /** * 返回成功的消息使用的构造函数 * * @author ming * @date 2017-11-10 17:26 */ public ReturnJsonBody(long code, Object data) &#123; this.code = code; this.data = data; &#125; /** * 返回异常的消息使用的构造函数 * * @author ming * @date 2017-11-10 17:26 */ public ReturnJsonBody(long code, String msg, String stack) &#123; this.code = code; this.msg = msg; this.stack = stack; &#125;&#125; 2:通过增强控制器来实现对返回数据包装123456789101112131415161718192021222324252627282930313233343536373839404142/** * 全局json 数据返回处理 * * @author ming * @date 2017-11-10 14:02 */@ControllerAdvicepublic class BaseGlobalResponseBodyAdvice implements ResponseBodyAdvice&lt;Object&gt; &#123; /** * 需要处理的类型 * * @author ming * @date 2017-11-10 14:05 */ private final Set&lt;MediaType&gt; jsonMediaType = new ImmutableSet.Builder&lt;MediaType&gt;() .add(MediaType.APPLICATION_JSON) .add(MediaType.APPLICATION_JSON_UTF8) .build(); @Override public boolean supports(MethodParameter methodParameter, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; converterType) &#123; return true; &#125; @Override public Object beforeBodyWrite( Object obj, MethodParameter methodParameter, MediaType mediaType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; converterType, ServerHttpRequest serverHttpRequest, ServerHttpResponse serverHttpResponse) &#123; //当类型 不属于 需要处理的包头的时候 直接返回obj if (!jsonMediaType.contains(mediaType)) &#123; return obj; &#125; //当类型 是属于需要处理的时候 并且 obj不是ReturnJsonBody的时候 进行格式化处理 if (obj == null || !(obj instanceof ReturnJsonBody)) &#123; obj = new ReturnJsonBody(0L, obj); &#125; return obj; &#125;&#125; ####总结: 使用增强控制器返回格式方式 来对json接口进行返回数据格式统一处理 也是必须的 方便和前端交互]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot mvc配置笔记]]></title>
    <url>%2Fming%2Fcdea8691.html</url>
    <content type="text"><![CDATA[配置mvc相关参数的类常用的 也就是如下三种方法 如果需要使用spring boot 中默认实现 请选则第三种方式 避免覆盖spring boot 实现@EnableWebMvc+extends WebMvcConfigurationAdapter，在扩展的类中重写父类的方法即可，这种方式会屏蔽springboot的@EnableAutoConfiguration中的设置extends WebMvcConfigurationSupport，在扩展的类中重写父类的方法即可，这种方式会屏蔽springboot的@EnableAutoConfiguration中的设置extends WebMvcConfigurationAdapter，在扩展的类中重写父类的方法即可，这种方式依旧使用springboot的@EnableAutoConfiguration中的设置以上资料参考博客:http://www.voidcn.com/article/p-fpvxvkbi-bpb.html####常用方式实现1:拦截器实现1234567891011121314151617181920import org.springframework.web.servlet.handler.HandlerInterceptorAdapter;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * 统一设定返回包头 * * @author ming * @date 2017-11-06 18:15 */public class ResponseHandlerInterceptot extends HandlerInterceptorAdapter &#123; @Override public void afterConcurrentHandlingStarted(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //统一设定 返回编码集 response.setCharacterEncoding(&quot;UTF-8&quot;); &#125;&#125; 2:注册到拦截器链中1234567891011121314151617181920212223242526272829303132333435363738394041/** * 拦截器配置 * * @author ming * @date 2017-08-28 11点 */@Configurationpublic class WebInterceptors extends WebMvcConfigurerAdapter &#123; public WebInterceptors() &#123; super(); &#125; /** * 添加拦截器 * * @author ming * @date 2017-11-07 10:08 */ @Override public void addInterceptors(InterceptorRegistry registry) &#123; //注册统一处理响应包头拦截器 registry.addInterceptor(new ResponseHandlerInterceptot()); super.addInterceptors(registry); &#125; /** * 添加允许跨域的请求 * * @author ming * @date 2017-11-10 17:07 */ @Override public void addCorsMappings(CorsRegistry registry) &#123; //允许所有请求跨域 registry.addMapping(&quot;/**&quot;); super.addCorsMappings(registry); &#125; &#125; ####总结:追求高度自定义 继承 WebMvcConfigurationSupport 如果想偷懒 那就继承 WebMvcConfigurationAdapter 可以拥有spring boot 默认的配置]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[guava-basic笔记]]></title>
    <url>%2Fming%2Fd9ddd520.html</url>
    <content type="text"><![CDATA[##guava basic 基本工具避免null optional如果是jdk1.8以上直接使用optional 1.8以下需要使用guava basic工具包前置检查 Preconditions方法声明（不包括额外参数）描述检查失败时抛出的异常checkArgument(boolean)检查boolean是否为true，用来检查传递给方法的参数。IllegalArgumentExceptioncheckNotNull(T)检查value是否为null，该方法直接返回value，因此可以内嵌使用checkNotNull。NullPointerExceptioncheckState(boolean)用来检查对象的某些状态。IllegalStateExceptioncheckElementIndex(int index, int size)检查index作为索引值对某个列表、字符串或数组是否有效。index&gt;=0 &amp;&amp; index&lt;size *IndexOutOfBoundsExceptioncheckPositionIndex(int index, int size)检查index作为位置值对某个列表、字符串或数组是否有效。index&gt;=0 &amp;&amp; index&lt;=size *IndexOutOfBoundsExceptioncheckPositionIndexes(int start, int end, int size)检查[start, end]表示的位置范围对某个列表、字符串或数组是否有效*IndexOutOfBoundsExceptionobject方法 Objectsjdk1.7 后提供了相应的方法 可以不用guava提供比较链 ComparisonChain排序 Ordering排序器方法描述natural()对可排序类型做自然排序，如数字按大小，日期按先后排序usingToString()按对象的字符串形式做字典排序[lexicographical ordering]from(Comparator)把给定的Comparator转化为排序器链式调用方法描述reverse()|获取语义相反的排序器nullsFirst()|使用当前排序器，但额外把null值排到最前面。nullsLast()|使用当前排序器，但额外把null值排到最后面。compound(Comparator)|合成另一个比较器，以处理当前排序器中的相等情况。lexicographical()|基于处理类型T的排序器，返回该类型的可迭代对象Iterable的排序器。onResultOf(Function)|对集合中元素调用Function，再按返回值用当前排序器排序。排序器方法描述greatestOf(Iterable iterable, int k)|获取可迭代对象中最大的k个元素。|leastOfisOrdered(Iterable)|判断可迭代对象是否已按排序器排序：允许有排序值相等的元素。|isStrictlyOrderedsortedCopy(Iterable)|判断可迭代对象是否已严格按排序器排序：不允许排序值相等的元素。|immutableSortedCopymin(E, E)|返回两个参数中最小的那个。如果相等，则返回第一个参数。|max(E, E)min(E, E, E, E…)|返回多个参数中最小的那个。如果有超过一个参数都最小，则返回第一个最小的参数。|max(E, E, E, E…)min(Iterable)|返回迭代器中最小的元素。如果可迭代对象中没有元素，则抛出NoSuchElementException。|max(Iterable), min(Iterator), max(Iterator)总结: guava的基本工具类用的多的可能就是 Preconditions 来检查参数了 optional jdk8 已经包含了 比较的方法 也有 或者 jdk8中stream集合提供更加强大的 宝马都有了 还用个毛的guava的自行车]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>guava</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[guava-collections笔记]]></title>
    <url>%2Fming%2F54bd928f.html</url>
    <content type="text"><![CDATA[guava 集合工具不可变集合当对象被不可信的库调用时，不可变形式是安全的；不可变对象被多个线程调用时，不存在竞态条件问题不可变集合不需要考虑变化，因此可以节省时间和空间。所有不可变的集合都比它们的可变形式有更好的内存利用率（分析和测试细节）；不可变对象因为有固定不变，可以作为常量来安全使用1guava 不可变集合不接受null 如果需要可使用null使用jdk中的Collections.unmonifiableXXX（） 创建不可变集合 copyOf ImmutableSet.copyOf(set); of ImmutableSet.of(“1”,”2”); Builder 1234ImmutableSet.&lt;Color&gt;builder() .addAll(WEBSAFE_COLORS) .add(new Color(0, 191, 255)) .build(); 有序的不可变集合 在构建的时候 就排序 asList() 视图所有不可变集合提供 asList() 视图 方便的获取指定值 sortedSet.asList().get(k)从ImmutableSortedSet中读取第k个最小元素。 可变集合和不可变集合对照表 可变集合接口 属于JDK还是Guava 不可变版本 Collection|JDK|ImmutableCollectionList|JDK|ImmutableListSet|JDK|ImmutableSetSortedSet/NavigableSet|JDK|ImmutableSortedSetMap|JDK|ImmutableMapSortedMap|JDK|ImmutableSortedMapMultiset|Guava|ImmutableMultisetSortedMultiset|Guava|ImmutableSortedMultisetMultimap|Guava|ImmutableMultimapListMultimap|Guava|ImmutableListMultimapSetMultimap|Guava|ImmutableSetMultimapBiMap|Guava|ImmutableBiMapClassToInstanceMap|Guava|ImmutableClassToInstanceMapTable|Guava|ImmutableTable guava 新集合1: Multiset 方法|描述|—-|—-|count(E)|给定元素在Multiset中的计数elementSet()|Multiset中不重复元素的集合，类型为SetentrySet()|和Map的entrySet类似，返回Set&lt;Multiset.Entry&gt;，其中包含的Entry支持getElement()和getCount()方法add(E, int)|增加给定元素在Multiset中的计数remove(E, int)|减少给定元素在Multiset中的计数setCount(E, int)|设置给定元素在Multiset中的计数，不可以为负数size()|返回集合元素的总个数（包括重复的元素） 2:Multimap 单键多值map 方法签名|描述|等价于|—-|—-|—|put(K, V)|添加键到单个值的映射|multimap.get(key).add(value)putAll(K, Iterable)|依次添加键到多个值的映射|Iterables.addAll(multimap.get(key), values)remove(K, V)|移除键到值的映射；如果有这样的键值并成功移除，返回true。|multimap.get(key).remove(value)removeAll(K)|清除键对应的所有值，返回的集合包含所有之前映射到K的值，但修改这个集合就不会影响Multimap了。|multimap.get(key).clear()replaceValues(K, Iterable)|清除键对应的所有值，并重新把key关联到Iterable中的每个元素。返回的集合包含所有之前映射到K的值。|multimap.get(key).clear(); Iterables.addAll(multimap.get(key), values) 3: BiMap 双向映射map 通过inverse() 反转键值对 保证值是唯一的 values()返回是set 键映射到已经存在的值 需要使用 forcePut 4: Table =&gt; Map&lt;R,Map&gt; ==》表格 Table rowMap()：用Map&lt;R, Map&gt;表现Table。同样的， rowKeySet()返回”行”的集合Set。 row(r) ：用Map返回给定”行”的所有列，对这个map进行的写操作也将写入Table中。 类似的列访问方法：columnMap()、columnKeySet()、column(c)。（基于列的访问会比基于的行访问稍微低效点） cellSet()：用元素类型为Table.Cell的Set表现Table。Cell类似于Map.Entry，但它是用行和列两个键区分的。 5: CLassToInstanceMap 它的键是类型，而值是符合键所指类型的对象。Map&lt;Class&lt;? extends B&gt;, B&gt; ==》 ClassToInstanceMap 集合扩展工具类1: Forwarding(装饰器)自定义集合的时候可以前后加一些操作 例如日志2: PeekingIterator(将jdk中的Iterator增强提供一个peek()方法)注意：Iterators.peekingIterator返回的PeekingIterator不支持在peek()操作之后调用remove()方法。12345678910List&lt;E&gt; result = Lists.newArrayList();PeekingIterator&lt;E&gt; iter = Iterators.peekingIterator(source.iterator());while (iter.hasNext()) &#123; E current = iter.next(); while (iter.hasNext() &amp;&amp; iter.peek().equals(current)) &#123; //跳过重复的元素 iter.next(); &#125; result.add(current);&#125; 3:AbstractIterator AbstractSequentialIterator jdk8有更加强大的迭代器http://ifeve.com/google-guava-newcollectiontypes/ 总结: guava工具包最出名应该就是集合的相关操作了1：提供不可变集合 来提升性能 但是这个用起来要注意 要确定后续肯定不会在向集合添加更新删除操作了，之前在项目中 调用dubbo服务的时候 用不可变集合 直接gg、####2：第二大的功能 应该就是他的一些变种集合类了 不过用的比较多的话 也就是table、Multimap 其他有用到 很少]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>guava</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot-thymeleaf模版实现类似jsp的sitemesh]]></title>
    <url>%2Fming%2F12183fd8.html</url>
    <content type="text"><![CDATA[####thymeleaf虽然现在大部分项目 更加倾向于前后端分离 但是有时候身为后端工程师 总想手贱写点小东西但是jsp 又比较老 而且需要web容器支撑 spring boot 支持性太差所以还是用spring boot 推荐的thymeleaf可是 jsp中的siteMesh装饰器真的好用 苦于thymeleaf没有这个东西在国外博客看到别人实现了类似功能 特此写这篇笔记 方便后续查阅1:建立layout注解用这个注解标识 那些接口需要被装饰123456789101112131415161718192021222324import java.lang.annotation.*;/** * 样式装饰器 注解 在controller中注解 * * @author ming * @date 2017-08-28 11点 */@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Layout &#123; /** * no layout will be used */ String none = &quot;none&quot;; /** * default layout will be used */ String defaultLayOut = &quot;default&quot;; String value() default defaultLayOut;&#125; 2:建立 thymeleaf 处理拦截器这个拦截器 就是用来根据layout注解处理相关组装页面的123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * thymeleaf样式拦截器 实现类似 jsp的sitemesh 装饰器功能 * * @author ming * @date 2017-08-28 11点 */public class ThymeleafLayoutInterceptor extends HandlerInterceptorAdapter &#123; private static final String DEFAULT_LAYOUT = &quot;layouts/default&quot;; private static final String DEFAULT_VIEW_ATTRIBUTE_NAME = &quot;view&quot;; private String defaultLayout = DEFAULT_LAYOUT; private String viewAttributeName = DEFAULT_VIEW_ATTRIBUTE_NAME; public void setDefaultLayout(String defaultLayout) &#123; Assert.hasLength(defaultLayout, &quot;默认样式不存在!&quot;); this.defaultLayout = defaultLayout; &#125; public void setViewAttributeName(String viewAttributeName) &#123; Assert.hasLength(defaultLayout, &quot;默认样式不存在!&quot;); this.viewAttributeName = viewAttributeName; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; if (modelAndView == null || !modelAndView.hasView()) &#123; return; &#125; String originalViewName = modelAndView.getViewName(); if (isRedirectOrForward(originalViewName)) &#123; return; &#125; String layoutName = getLayoutName(handler); if (Layout.none.equals(layoutName)) &#123; return; &#125; modelAndView.setViewName(layoutName); modelAndView.addObject(this.viewAttributeName, originalViewName); &#125; private boolean isRedirectOrForward(String viewName) &#123; return viewName.startsWith(&quot;redirect:&quot;) || viewName.startsWith(&quot;forward:&quot;); &#125; private String getLayoutName(Object handler) &#123; if (handler instanceof HandlerMethod) &#123; HandlerMethod handlerMethod = (HandlerMethod) handler; Layout layout = getMethodOrTypeAnnotation(handlerMethod); if (layout != null) &#123; return layout.value(); &#125; &#125; return this.defaultLayout; &#125; private Layout getMethodOrTypeAnnotation(HandlerMethod handlerMethod) &#123; Layout layout = handlerMethod.getMethodAnnotation(Layout.class); if (layout == null) &#123; return handlerMethod.getBeanType().getAnnotation(Layout.class); &#125; return layout; &#125;&#125; 3:建立样式装饰页面在项目静态页面路径下 创建 layouts文件夹在文件夹目录下建立 装饰配置html 例如default.html12345678910111213&lt;!DOCTYPE html&gt;&lt;html xmlns:th=&quot;http://www.thymeleaf.org&quot; lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot;/&gt; &lt;title&gt;ming thymeleaf site mesh&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=&quot;menu-container&quot;&gt; &lt;div class=&quot;container&quot; th:replace=&quot;$&#123;view&#125; :: content&quot;&gt;加载中。。。。。&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 4:在controller中应用layout默认是使用default的 这个看layout实现即可这样 index.html就会嵌入到default.html中 那个th:replace=“{view}”那个位置1234567891011121314151617181920import com.ming.base.annotations.Layout;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.GetMapping;/** * 首页 控制器 * * @author ming * @date 2017-11-08 10:33 */@Controller@Layoutpublic class IndexController &#123; @GetMapping(value = &#123;&quot;&quot;, &quot;/&quot;, &quot;/index&quot;&#125;) public String index() &#123; return &quot;index&quot;; &#125;&#125; ####总结：thymeleaf 总的来说 还行 毕竟简单粗暴 但是有几个比较坑的地方 1:必须是标在的xml结构的html 也就是必须符合xml规范 2：由于技术用的人可能不太多 编辑器支持不是很好 不能做到 jsp 那样可以直接追踪到controller中]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-compose配置笔记]]></title>
    <url>%2Fming%2F5f628b10.html</url>
    <content type="text"><![CDATA[####docker-compose 是docker的一个工具 是用来根据配置联合启动多个docker的工具 特别是在启动一些复杂应用的时候 适合用docker-compose来启动 当然 也可以自己写shell脚本启动####docker-compose配置文件 部分字段解释#####实例 yaml格式1234567891011121314151617181920212223version: &apos;3&apos;services: mysql: image: mysql ports: - &apos;3306:3306&apos; networks: - network1 redis: image: redis ports: - &apos;6379:6379&apos; networks: - network1 nginx: image: nginx prots: - &apos;80:80&apos; networks: - network1networks: network1: driver: bridge 标准的docker-compose配置需要version、service、networks三部分 version 配置文件版本 1不能填写1 service 容器相关启动配置 12可以指定 image相关的启动参数 例如 -v --name -p 等启动信息在挂在数据卷的时候 也就是 指定-v参数的时候 windows指定的目录无权限 坑的一匹 networks 容器使用的网卡模式 1主要是设定容器使用的网卡模式 ####docker-compose 用法用法和docker 的用法差不多例如 up 根据这个yaml启动相应的容器 加上 -f 指定yaml文件 不指定 默认是当前目录的./docker-compose.yaml -d是后台运行 不指定-d前台运行 build 可以根据dockerfile 去构建生成启动容器1sudo docker-compose -f ./xxx.yaml up 其他用法 参考man docker-compose #####学习博客地址:http://www.jianshu.com/p/2217cfed29d7]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java注解笔记]]></title>
    <url>%2Fming%2F478f654a.html</url>
    <content type="text"><![CDATA[##java定义的4个标准元数据注解:1 @Target2 @Retention3 @Documented4 @Inherited|名称 | 作用 | 取值 | 备注||———|:——|:——-|——||@target | 用来说明annotation修饰对象范围 描述注解使用范围| 1.CONSTRUCTOR:用于描述构造器2.FIELD:用于描述域3.LOCAL_VARIABLE:用于描述局部变量4.METHOD:用于描述方法5.PACKAGE:用于描述包6.PARAMETER:用于描述参数7.TYPE:用于描述类、接口(包括注解类型) 或enum声明|在自定义注解时候 定义注解使用范围@Retention定义annotation保留时间长短 也就是生命周期1.SOURCE:在源文件中有效（即源文件保留） 2.CLASS:在class文件中有效（即class保留） 3.RUNTIME:在运行时有效（即运行时保留）用来定义注解生命周期@Documented标记注解 描述这个类型的注解是作为被标注的程序成员变量的公共api就是一个标记 例如javadoc的注解 可用被javadoc这样的工具进行操作生成文档@Inherited标记注解 描述某个被标注的类型是被继承的 如果使用此注解标记一个类 啦么这个注解将用于该类的子类当@Inherited annotation类型标注的annotation的Retention是RetentionPolicy.RUNTIME，则反射API增强了这种继承性。如果我们使用java.lang.reflect去查询一个@Inherited annotation类型的annotation时，反射代码检查将展开工作：检查class和其父类，直到发现指定的annotation类型被发现，或者到达类继承结构的顶层。定义注解格式 public @interface 注解名{定义内容}注解参数可支持类型：1.所有基本数据类型（int,float,boolean,byte,double,char,long,short) 2.String类型 3.Class类型 4.enum类型 5.Annotation类型 6.以上所有类型的数组annotation类型的参数设定要求：第一,只能用public或默认(default)这两个访问权修饰.例如,String value();这里把方法设为defaul默认类型； 第二,参数成员只能用基本类型byte,short,char,int,long,float,double,boolean八种基本数据类型和 String,Enum,Class,annotations等数据类型,以及这一些类型的数组.例如,String value();这里的参数成员就为String; 第三,如果只有一个参数成员,最好把参数名称设为”value”,后加小括号.例:下面的例子FruitName注解就只有一个参数成员。注解元素必须有默认值 要么默认指定 要么注解时候指定。非基本类型的注解元素不能为null注解如果不处理 几乎和注释一样 所以需要注解处理器主要是通过反射来构建自定义注解处理器]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java1.8笔记]]></title>
    <url>%2Fming%2F3e07ee0e.html</url>
    <content type="text"><![CDATA[####最近一直在看 jdk8的书 觉得jdk8和之前的jdk变化还是挺大####主要多了如下一些东西####1:lambda表达式支持(方法引用 )jdk8增加lambda表达式的支持 可以通过‘-&gt;’ 来传递代码片段和匿名方法很像 但是有一点细微区别java.util.function包下 提供很多常用的function接口方法引用其实也是lambda表达式的一种语法糖####2:stream集合这种集合 主要是为了计算 一个是有多种操作符可以很轻松的实现一些数据操作、过滤、扁平化、收集等任务如果条件合适 很方便的实现并行计算 转换成并行stream集合####3:新的future实现(completableFuture)新增了一中新的future实现 相应的工具类中 提供很工厂方法去方便将普通任务包装成异步执行的 future任务 可以自定义线程池之类的 来根据不同的环境优化####4:新的time包jdk8之前的时间包比较混乱 例如 java.util.Date java.sql.Date 各有各的地方 看起来贼混乱 jdk8 从新整理的time相关的类、包 提供对之前的java.util.Date这样的互相转换方法####5:interface default方法java的提供的方法是一直演进的 一般像之前的方法提供兼容性都是从代码上进行兼容 一个是比较麻烦 二个是有点混乱 现在jdk8提供接口中default方法 可以很方便的去兼容之前的代码 但是这个dufault方法 是很麻烦的 各种实现、继承之间的规则变的比较复杂了 相当于换了一种方式实现了多继承 也会遇到其它支持多继承语言中的坑 例如 菱形继承####6: Optional这个是学习scala中的optional 可以通过它来实现优雅的防御性编程从设计上来说 是否用optional包装 可以用来表明这个值是否可以为nulloptional也提供map、flatmap、filter几种操作符 功能类似stream中的用法 其中flatmap用的比较多####7:优化自定义注解主要是可重复注解#####总结:工作中使用上jdk8的代码 看起来还是蛮骚的 就是出问题 排查难度会上升一点 特别是lambda中出现问题 stream在做一些对集合中数据进行处理的时候 非常方便 性能也强 如果条件允许还可以很方便的使用并行stream集合、但是直接用并行流的话 效率比不上自己优化过线程池的多线程解决方案]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git glow 笔记]]></title>
    <url>%2Fming%2Fc67df015.html</url>
    <content type="text"><![CDATA[###gitflow 代码提交规范如下图：master:线上分支 这个分支 就是线上代码所在的分支 每个点就是软件的一个版本 打上tagdevelop:当代码在开发分支上开发完毕经过基本测试 即可推送合并到develop上 这个是一个比较稳定的一个版本了 合并到develop分支上的功能 代表这个是必须上线的一个功能feature:开发分支 这个可以开多个 多个项目组 并行开发 在合适的时机 合并到develop 或者 新的feature分支 进行功能合并release:测试分支 develop上的代码 分开一个release分支进行测试 当测试阶段性完成 就合并到develop分支 当整个测试完成 就将测试完成的代码合并到develop 和master分支上hotfixes:线上bug修复分支 主要处理 master 也就是线上的bug 开的临时分支 当bug处理完成 则将代码推送到develop和master分支这几种分支中 develop占用主要地位 几乎所有的分支度基于这个分支 不管是 feature、release、hotfixes、master 度与develop分支有关]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot (一)笔记]]></title>
    <url>%2Fming%2F1d0e6366.html</url>
    <content type="text"><![CDATA[##步骤1:安装spring boot cli2:利用spring boot cli初始化项目3:写一个helloworld控制器##1:安装spring boot clispring boot cli是spring boot的一个操作工具 可以直接利用这个工具去生成 管理spribg boot项目在这里去寻找合适的版本下载解压 添加到系统路径http://repo.spring.io/release/org/springframework/boot/spring-boot-cli/安装方式有两种1:类似jdk安装方法 下载spring boot cli 解压包 将目录下的bin添加到系统路径中2:利用gvm(Groovy的工具去管理):安装gvm 之后12gvm install springbootspring --version ##2:利用spring boot cli 初始化项目spring boot cli 初始化项目 是从网络上下载一个基本demo来初始化的1spring init -dweb,data-jpa,h2,thymeleaf 会初始化spring mvc jpa h2 等 组成一个基本的spring +mvc+jpa+h2数据库的一个基本项目 默认是maven 如果需要gradle来进行项目管理 在语句后加上 –build gradle即可 ##3:hellwworld控制器就是写个spring mvc的控制器12345678@RestControllerpublic class TestController &#123; @RequestMapping(&quot;/test&quot;) public String test()&#123; return &quot;test springboot&quot;; &#125;&#125; 控制器访问地址为:http://localhost:8080/test ###总结:spring boot 就是spring 等相关框架一个快速版 默认设置已经够用 自定义配置覆盖默认配置]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot (二)笔记]]></title>
    <url>%2Fming%2F64575eaf.html</url>
    <content type="text"><![CDATA[###步骤1:使用spring boot cli 生成基本项目2:写dao、controller层代码3:写thymeleaf 模板###1:初始化项目spring init -dweb,data-jpa,h2,thymeleaf下载demo.zip解压 改名springboot (任意名称)刷新maven 下载jar包构建项目###2:dao、controller层代码entity123456789101112@Entitypublic class Book &#123; @Id @GeneratedValue(strategy = GenerationType.AUTO) private Long id; private String reader; private String isbn; private String title; private String author; private String description;.....省略setter gettter等方法&#125; 定义jpa book实体的 repository1234@Repositorypublic interface BookRepository extends JpaRepository&lt;Book,Long&gt; &#123; List&lt;Book&gt; findByReader(String reader);&#125; 正式项目中会设立service层 这里就不写了 就是跟平常写spring 项目一样的玩法定义 controller层 新增和查看控制器1234567891011121314151617181920212223@Controllerpublic class ReadingListController &#123; @Resource BookRepository bookRepository; @RequestMapping(value = &quot;/&#123;reader&#125;&quot;,method = RequestMethod.GET) public String readersBook(Model model, @PathVariable(value = &quot;reader&quot;,required = false)String reader)&#123; List&lt;Book&gt; books= bookRepository.findByReader(reader); if (books!=null)&#123; model.addAttribute(&quot;books&quot;,books); &#125; return &quot;readingList&quot;; &#125; @RequestMapping(value = &quot;/&#123;reader&#125;&quot;,method = RequestMethod.POST) public String addToReadingList(@PathVariable(value = &quot;reader&quot;,required = false) String reader,Book book)&#123; book.setReader(reader); bookRepository.save(book); return &quot;redirect:/&#123;reader&#125;&quot;; &#125;&#125; ###thymeleaf 模板引擎代码1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot; xmlns:th=&quot;http://www.w3.org/1999/xhtml&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;/&gt; &lt;title&gt;阅读列表&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;你的阅读列表&lt;/h2&gt;&lt;div th:unless=&quot;$&#123;#lists.isEmpty(books)&#125;&quot;&gt; &lt;dl th:each=&quot;book : $&#123;books&#125;&quot;&gt; &lt;dt class=&quot;bookHeadline&quot;&gt; &lt;span th:text=&quot;$&#123;book.title&#125;&quot;&gt;标题&lt;/span&gt; &lt;span th:text=&quot;$&#123;book.author&#125;&quot;&gt;作者&lt;/span&gt; (ISBN: &lt;span th:text=&quot;$&#123;book.isbn&#125;&quot;&gt;ISBN&lt;/span&gt;) &lt;/dt&gt; &lt;dd class=&quot;bookDescription&quot;&gt;&lt;span th:if=&quot;$&#123;book.description&#125;&quot; th:text=&quot;$&#123;book.description&#125;&quot;&gt;Description&lt;/span&gt; &lt;span th:if=&quot;$&#123;book.description eq null&#125;&quot;&gt;description为空&lt;/span&gt; &lt;/dd&gt; &lt;/dl&gt;&lt;/div&gt;&lt;div th:if=&quot;$&#123;#lists.isEmpty(books)&#125;&quot;&gt; &lt;p&gt;当前没有阅读&lt;/p&gt;&lt;/div&gt;&lt;hr/&gt;&lt;h3&gt;添加书&lt;/h3&gt;&lt;!--只需要进控制器即可 直接post当前路径--&gt;&lt;form method=&quot;POST&quot;&gt; &lt;label&gt;标题:&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;title&quot; size=&quot;50&quot;&gt;&lt;/input&gt;&lt;br/&gt; &lt;label&gt;作者:&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;author&quot; size=&quot;50&quot;&gt;&lt;/input&gt;&lt;br/&gt; &lt;label&gt;ISBN:&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;isbn&quot; size=&quot;15&quot;&gt;&lt;/input&gt;&lt;br/&gt; &lt;label&gt;Description:&lt;/label&gt;&lt;br/&gt; &lt;textarea name=&quot;description&quot; cols=&quot;80&quot; rows=&quot;5&quot;&gt;&lt;/textarea&gt;&lt;br/&gt; &lt;input type=&quot;submit&quot;&gt;&lt;/input&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; ##浏览器打开http://localhost:8080/sss(任意字符串 进 get /{reader}控制器即可) ###代码地址:https://github.com/xuxianyu/myGitHub/tree/master/springboot]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven 远程部署tomcat 上的java web 项目]]></title>
    <url>%2Fming%2Fd7957e83.html</url>
    <content type="text"><![CDATA[####由于有朋友不会这个远程部署又懒的百度、google 于是我写这个maven+tomcat远程部署javaweb项目的教程。以后心情好说不定会继续更新项目管理的一些环境搭建:如jenkins+gitlab+项目管理工具(如禅道)这样自动化部署测试环境##工具和环境准备1:工具 maven tomcat2:环境maven能下jar即可、tomcat管理员账户和一些安全设置设定(8.5以上需要设定远程管理员访问的配置)3:能访问远程tomcat管理页面##maven远程部署配置####1: maven工具配置需要在maven的setting.xml中添加如下配置settins.xml 一般在maven安装目录的conf文件夹下 不排除有人更改默认地址了12345678&lt;servers&gt; &lt;!--maven tomcat远程部署密码帐号密码设置--&gt; &lt;server&gt; &lt;id&gt;名称 例如“laji” (任意取 pom.xml中需要使用)&lt;/id&gt; &lt;username&gt;tomcat管理员用户名&lt;/username&gt; &lt;password&gt;tomcat管理员密码&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt; ####2:maven项目中的pom设置 在build的插件中添加下面这个插件并且配置亲测可以支持8.5tomcat 和7.x的 , tomcat 9.x的没测试1234567891011121314&lt;!--tomcat远程部署插件--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;configuration&gt; &lt;!-- 此处的名字必须和setting.xml中配置的ID一致--&gt; &lt;server&gt;laji&lt;/server&gt; &lt;!-- tomcat远程部署访问页面--&gt; &lt;url&gt;http://服务器ip:8080/manager/text&lt;/url&gt; &lt;!-- 此处的名字是项目发布的工程名 可以任意取 访问部署好的项目旧是这个名称--&gt; &lt;path&gt;/lajiproject&lt;/path&gt; &lt;/configuration&gt; &lt;/plugin&gt; ##tomcat远程部署配置 ####1:需要配置tomcat管理员账户 并且能访问远程tomcat管理员地址例如：localhost:8080/manager/text在tomcat安装目录的conf下面的tomcat-users.xml中修改12345678910111213&lt;tomcat-users xmlns=&quot;http://tomcat.apache.org/xml&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://tomcat.apache.org/xml tomcat-users.xsd&quot; version=&quot;1.0&quot;&gt;&lt;role rolename=&quot;admin-gui&quot;/&gt;&lt;role rolename=&quot;admin-script&quot;/&gt;&lt;role rolename=&quot;manager-gui&quot;/&gt;&lt;role rolename=&quot;manager-script&quot;/&gt;&lt;role rolename=&quot;manager-jmx&quot;/&gt;&lt;role rolename=&quot;manager-status&quot;/&gt;&lt;user username=&quot;admin&quot; password=&quot;ideal123&quot; roles=&quot;manager-gui,manager-script,manager-jmx,manager-status,admin-script,admin-gui&quot;/&gt;&lt;/tomcat-users&gt; ####2:tomcat8.5远程需要添加远程管理员用户访问配置步骤 ####tomcat 8.5之后呢对安全访问增强了 不仅仅需要配置管理帐号还需要配置允许远程访问管理员账户1234567891011在conf/Catalina/localhost/manager.xml 没有就创建这个xml ，然后在manager.xml中添加&lt;Context privileged=&quot;true&quot; antiResourceLocking=&quot;false&quot; docBase=&quot;$&#123;catalina.home&#125;/webapps/manager&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.RemoteAddrValve&quot; allow=&quot;^.*$&quot; /&gt;&lt;/Context&gt;直接生效无须重启在官方文档中提到：每个web应用应该有自己的安全管理文件（manager.xml）如果没有使用默认值 也就是不能远程访问所以如果需要远程访问就需要创建manager.xml来指定允许远程访问规则 ##执行远程部署 ####例如idea 在你项目的maven配置的地方找到Plugins&gt;tomcat7&gt;tomcat7:redeploy ####尽量使用redeploy 因为你不从新部署有时候会产生乱七八糟的错误 ####这个插件具体玩法 向具体了解就需要自行找官方文档 我也没看官方文档 ###总结:部署过程： maven编译jar或者war》maven通过远程服务器的支持上传jar或者war ###这个时候需要保证本地编译的jar和war能符合服务器上的tomcat的jre版本]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot (三)笔记]]></title>
    <url>%2Fming%2F241784d.html</url>
    <content type="text"><![CDATA[###spring boot中 在某些配置的时候肯定是需要自定义配置的 spring boot 默认显示配置覆盖默认配置 所以只需要符合spring boot的配置环境###能够覆盖默认配置的配置位置1:命令行参数(如直接命令行启动某个jar 后面附带的命令)2:jndi配置3:jvm配置4:操作系统环境变量5:随机生成带random.*的属性(并不是很明白 以后看懂了 在更新)6:应用程序的application.properties 或者 application.yml7:通过@PropertySource注解标注的bean######按照顺序覆盖 优先级从1-7 依次降低 就是说 当命令行指定了某个配置 后面在怎么写 也无法改变 因为 命令行的参数优先级最高######如果 有的配置上述几个位置没有配置则采用spring boot 的默认配置###application文件位置1:外置 应用程序的运行目录的/config目录2:外置 应用程序运行目录3:内置 jar或者war的/config目录内4:内置 jar或者war的根目录######也是从1-4 优先级依次降低、yml配置 覆盖 properties中的配置###在程序中使用配置中的参数@ConfigurationProperties这个注解可以去配置中寻找某些前缀的参数如 配置中有12my.name=xianyumy.sex=boy 那么可以在某个bean中注入 通过setter注入···@ConfigurationProperties(prefix=”my”)public class myProperties{ private String name;private String sex;setter.getter 。。。。}···]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot (四)笔记]]></title>
    <url>%2Fming%2F68619b43.html</url>
    <content type="text"><![CDATA[###在使用spring boot的时候 spring本身会根据springboot的版本引入依赖包 跟maven一样有隐藏依赖会自动引入这个时候如果不需要其中一些工具包 或者需要指定某些包的版本 可以通过maven的功能去排除依赖和覆盖依赖##排除依赖 通过maven的语法排除依赖包 exclusions例如 为项目大小瘦身的时候 排除不需要的jar 例如jackson12345678910111213&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;``` ##覆盖依赖 通过maven的最短路径寻包的特性 去覆盖已有依赖例如 需要指定某个包的版本 直接在spring boot所在的pom中添加这个包的依赖即可 例如 spring boot 的版本依赖的jackson是2.3.3 但是我们需要2.4.3版本 直接在spring boot 的pom下面添加2.4.3 的jackson即可 com.fasterxml.jackson.core jackson-databind 2.4.3```]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows 安装虚拟化工具蓝屏]]></title>
    <url>%2Fming%2F5dd0b5a6.html</url>
    <content type="text"><![CDATA[win10 安装vbox的时候蓝屏 经过google 发现是 Hyper-V 和 vbox 冲突 坑爹的微软关闭Hyper-V搜索 windows功能 找到Hyper-v 关闭 重启 即可]]></content>
      <categories>
        <category>坑</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>vbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web service笔记]]></title>
    <url>%2Fming%2Fa451f549.html</url>
    <content type="text"><![CDATA[##web service 三要素 soap、wsdl、uddi###soap(Simple Object Access Protocol) 简单对象访问协议soap是一种对象访问通信协议 基于xml的协议 用来访问结构化和固化的信息主要特点 制定程序之间的通信、消息格式; 独立平台、语言;基于xml;允许绕过防火墙;w3c标准######soap消息是一个xml文档:必须包含Envelope元素 (标识此xml文档为soap消息)必须包含Body元素(包含所有调用和响应的信息)可选Header元素(头部信息)、Fault(处理此消息发生的错误信息)语法规则:soap消息必须是xmlsoap消息必须使用soap Envelope、soap Encoding 命名空间来保证规范soap消息不能包含DTDsoap不能包含xml处理指令123456789&lt;?xml version=&quot;1.0&quot;&gt;&lt;soap:Envelopexmlns:soap=&quot;http://www.w3.org/2001/12/soap-envelope&quot;soap:encodingStyle=&quot;http://www.w3.org/2001/12/soap-encoding&quot;&gt;&lt;soap:Body&gt;&lt;/soap:Body&gt;&lt;/soap:Envelope&gt; soap消息的xml文档 一般包含Header、Body、Fault等三个元素 具体直接查询w3c文档 ###wsdl(Web Services Description Language )网络服务描述语言wsdl也是xml文档 用来描述网络服务 不是w3c标准主要元素:portType：web service 执行的操作message：web service 使用消息types：web service使用数据类型binding：web service 使用的通信协议 ######portType端口提供四种类型客户端主动One-way:接受消息 不返回Request-response：此服务接受请求返回响应服务端主动Solicit-response:此服务发送请求等待响应Notiication：此服务发送一个请求 不等待响应 ######Request-response类型1234567891011121314&lt;message name=&quot;myRequest“&gt; &lt;part name=&quot;param&quot; type=”xs:string&quot;/&gt;&lt;/message&gt;&lt;message name=&quot;myResponse&quot;&gt; &lt;part name=&quot;value&quot; type=&quot;xs:string&quot;/&gt;&lt;/message&gt;&lt;portType name=&quot;myService&quot;&gt; &lt;operation name=&quot;myRequestResponse&gt; &lt;input message=&quot;myRequest&quot;/&gt; &lt;output message=&quot;myResponse&quot;/&gt; &lt;/operation&gt;&lt;/portType&gt; 上述例子 一个服务myService 定义了一个名字是myRequestResponse的操作myRequestResponse接受一个myRequest的输入消息，返回一个myResponse消息 ######binding（并不是特别明白 只知道是seb service 具体细节的 以后明白了在补上) ###uddi(Universal Description, Discovery and Integration) 描述、发现、集成服务看的不是特别明白 感觉就是一个列表 这个列表 里面存在大量的wsdl等相关信息 用来提供给其他调用方看的 ##总结:web service 三要素 soap消息、wsdl、uddi soap定义了消息的格式xml文档、wsdl定义了服务调用的xml文档、uddi整理归纳wsdl等相关文档]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>web service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yml格式笔记]]></title>
    <url>%2Fming%2F958a34fe.html</url>
    <content type="text"><![CDATA[####yaml 在学习docker-compose工具中需要用到yaml来做配置####yaml语法清晰简洁 适合写配置 但是不适合做数据传输####在比较新的技术中 大量应用了yaml去配置 如spring cloud docker-compose等######语法规则大小写敏感缩进表示层级关系缩进不允许tab 只允许空格空格数量不重要。相同层级左边对齐即可#表示注释######支持的数据结构对象1name: xu 数组 123name: - xu - xu1 纯量 123456789101112131415161718数字number: 123boolean flag: true or falsenull值parent:~ !!强转类型 字符串1:默认不使用引号 str: xu2:包含特殊字符串需要引号 str: &apos;xu&apos;3:双引号不对特殊字符转义 s1: &apos;xu&apos; s2: &quot;xu&quot;4:字符串可以写成多行 必须缩进一个空格 换行符转为空格 str: 多行 字符 串5:多行字符串 可以用| 保留换行符 或者&gt; 折叠6: + 保留文字末尾换行 -删除文字末尾换行 ######引用允许用&amp;设定锚点 用*引用 用&lt;&lt;合并到当前数据 ######学习博客地址:http://www.ruanyifeng.com/blog/2016/07/yaml.html?f=tt]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>yml、yaml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跨域笔记]]></title>
    <url>%2Fming%2F38475811.html</url>
    <content type="text"><![CDATA[##在将项目前后端分离的时候，首当其冲的就是跨域问题;此篇笔记 用来记录什么是跨域、如何解决跨域、以及一个实例;免得自己以后忘记了还需要去搜索###什么是跨域http为了提高安全，禁止非同域访问什么是同域:满足下三条才是同域 1:同端口 ip，2:同样的协议,3:如果是子域名 也要一样 否则就是非同域 不能直接互相访问，必须通过一些安全设置或者技巧去访问如jsonp、cors等方案###解决跨域####1:jsonp 方式首先jsonp和json是没有任何关系的 ;由于浏览器对js、图片不会做跨域限制jsonp就是相当于把数据下载下来解析，利用script标签去下载数据 然后解析就是用javascript动态加载一个script文件，如何去解析这个文件 例如json字符串######局限性:只能get请求 如果需要post、put等其他请求 无法满足###2:cors跨域(重点)cors是w3c定义的一种新的标准 用来适应跨域数据请求的当浏览器发现是跨域请求 会自动在报头添加一些跨域信息 如option等cors跨域分为简单请求和负责请求 但是只要在服务端设定合适 区别不是特别大当满足如下条件就是简单的cors跨域请求 不满足则是复杂cors请求1:请求方式:get、post、head2:报头限制:只能包含如下报头信息 超过则是复杂请求Accept、Accept-Language、Content-Language、Last-Event-ID、Content-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain|也就是意味者如果要自定义报头、发送cookie等功能 都是复杂请求不管是复杂请求还是简单请求 在服务端设置的时候 复杂请求设置是涵盖了简单请求需要的设置的######简单cors跨域1发送简单请求--&gt;服务端检验请求合法性--&gt;请求合法就和正常请求一样、不合法返回跨域错误提示 ######复杂cors跨域1发送预检请求--&gt;服务端检验请求是否合法--&gt;请求合法 发送正式请求、不合法 结束 提示请求不符合服务端检验要求 学习地址:http://www.ruanyifeng.com/blog/2016/04/cors.html]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乱码处理笔记]]></title>
    <url>%2Fming%2F54c825bb.html</url>
    <content type="text"><![CDATA[#编码问题##1:各种编码介绍###1.1:ascll码123共128个,用一个字节的低七位表示，0～31是控制字符换行、回车、删除相关的字符32～126是输出字符,就是可以同过键盘输入并且输出的 ###1.2:iso-8859-112共256个字符.是基于ascll来扩展的的。还是单字节编码 ###1.3:gb2312(信息技术中文编码集)1234共682个符号、6763个汉字,编码范围是A1～F7,A1~A9 共682个，是符号区,B0~F7 共6763个，是汉字区。 ###1.4:gbk(汉字内码扩展规范)1234扩展gb2312,编码范围是8140～FEFE(去除XX7F)，共23940个码位，表示21003个汉字,完全兼容gb2312.在系统中应用较为广泛 ###1.5:gb18030123是中国的强制标准,可能是单字节、双字节、四字节.完美兼容gb2312 ###1.6:utf-16(统一码)123456iso创建的超语言字典,世界上所有语言可以通过字典来进行翻译。utf-16 采用定长表示方法,无论什么字符读用两个字节表示一个字节8bit,所以叫utf-16 java内存就是用utf-16来作为内存的字符存储格式缺点：任何字符都是两个字节，增大存储成本和传输成本 ###1.7:utf-8(最常用编码)123456 utf-8采用的是变长技术,避免了utf-16缺点,每个编码区域有不同的字码长度。不同的字符可以由1～6字节组成。 编码规则: 1):如果是一个字节,最高位(也就是第8个bit)为0,表示这个字符就是ascll字符 2):如果是一个字节,开头是11连续的1的个数表示这个字符的字节数,例如1110xxxx就是三个字节的utf-8的首字节 3):如果是一个字节,以10开始，这个就不是首字节,需要向前查找首字节 ###1.8总结1234平常使用也就是gb2312、gbk、utf-8常见为了尽量避免乱码。优先选择utf-8如果不在乎磁盘可以选择utf-16毕竟解析比utf-8简单如果是网络IO的话 还是选择utf-8比较好 网络IO 字节流完整性容易遭到破坏 导致乱码 ##2:javaweb常见编码问题 ###2.1: http请求前后的乱码12345678 一般一次http请求中涉及到的编解码 存在于 request编码、request解码、response编码、response解码。这样的可以通过设定http请求头、响应头、服务器编解码设置、客户端编解码设置来处理例如：tomcat配置文件server.xml &lt;Connector port=&quot;8090&quot; protocol=&quot;HTTP/1.1&quot; maxThreads=&quot;150&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; URIEncoding=&quot;utf-8&quot; /&gt; http中请求报头或者响应报头设置charset=utf-8 客户端也就是浏览器一般是默认utf-8编码 也可以自己去指定编码 ###2.2: 数据库和项目之间出现乱码123主要就是项目中编解码和数据库的编解码、编码设置一般直接设置链接参数 ：jdbc:mysql://localhost:3306/mydb?characterEncoding=utf8一般项目直接设置utf-8 数据库也设定utf-8 ###2.3: 总结12345678910一般出现乱码肯定是有io的地方要么是各种链接之间 要么是系统内部出现来不同的编码例如http请求 先确定乱码产生地点是在客户端还是服务端 是在那个环节产生的 一般进行一些简单的抓包分析看看旧大概知道是那个地发出现乱码了 检查报头 和客户端 服务端的解析编码集 出现乱码先一步步的缩小范围找到出现乱码的节点 看是那个地发设置出了问题然后找到是什么导致这个节点这个设置出现问题如果是有网络IO的话 可以尝试抓包分析如果是本地IO的话 就看看系统编码、项目编码、等设置尽量避免使用框架、各种软件、系统的默认设置 ###2.4:form表单提交数据乱码12345有时候组合页面的时候和遇到类似ie这种变态浏览器的时候 会遭遇form表单乱码问题 其他地方都设置合适编码了这个时候在form中制定form表单的编码即可 &lt;form accept-charset=&quot;utf-8&quot; onsubmit=&quot;document.charset=&apos;utf-8&apos;&quot; &gt;后面那个onsubmit是遇到ie这种变态浏览器需要加的 最后 可能是服务器uri编码集未设定 例如tomcat的server.xml中的设置 ###笔记参考书籍：深入javaweb技术内幕]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>乱码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[接口签名笔记]]></title>
    <url>%2Fming%2F5e68a67b.html</url>
    <content type="text"><![CDATA[####由于开放型的短信接口受到不明来源的恶意访问 大佬们紧急对整个项目的接口进行加密原理:密钥+参数生成 md5 签名 客户端保存好密钥即可 之前对接苏宁易购的那个支付平台的时候 也是选择这种方式进行访问加密1:生成密钥这个随机定义 例如我选择使用 appId + salt 生成md5 截取前12位作为 指定app应用的密钥 如果发生泄漏 可以通过改变salt 来生成新的密钥2:客户端密钥 存储客户端 拿到密钥不能明文存储 例如 12位 可以拆分三段 然后分别进行偏移 这样如果别人要识别 必须反编译源码 并且读懂相关规则3:签名规则除开签名以外所有参数 按照排序规则排序 然后拼接上密钥 通过md5 或者类似的算法生成md5签名4：服务端验证规则除开签名 也按照客户端同样的排序规则排序 拼接密钥 通过相同的算法生成服务端签名 通过比较客户端签名 和服务端签名 来验证服务是否可靠、生成签名 方法示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100#!/usr/bin/env groovy/** groovy 生成md5 签名的算法 * * @author ming * @date 2017-11-15 12:45 */import java.nio.charset.Charsetimport java.security.MessageDigestimport java.security.NoSuchAlgorithmExceptionimport org.apache.commons.codec.binary.Hex;static void main(String[] args) &#123; Map&lt;String, String[]&gt; map = new HashMap&lt;&gt;() map.put(&quot;sign&quot;, [&quot;mkasfasfds&quot;] as String[]) map.put(&quot;param&quot;, [&quot;ming&quot;] as String[]) map.put(&quot;b&quot;, [&quot;b&quot;] as String[]) map.put(&quot;a&quot;, [&quot;a&quot;] as String[]) print(getSign(&quot;ming&quot;, map))&#125;/** * 生成签名 * @param accessSecretKey 密钥 * @param parameterMap 参数map 集合 * @author ming * @date 2017-11-15 11:42 */String getSign(String accessSecretKey, Map&lt;String, String[]&gt; parameterMap) &#123; //拼接参数 StringBuffer allNotEncryptString = new StringBuffer(); String signature = parameterMap.get(&quot;sign&quot;)[0]; // 获取未加密的请求参数 String notEncryptString = getRequestParameterString(parameterMap); if (notEncryptString == null || notEncryptString.length() == 0) &#123; throw new NullPointerException(&quot; 请求参数拼接为空&quot;) &#125; // 组合所有加密的字符穿 allNotEncryptString.append(notEncryptString); allNotEncryptString.append(&quot;secret&quot; + accessSecretKey); // 本地加密 String localSignature = md5(allNotEncryptString.toString(), Charset.forName(&quot;UTF-8&quot;)).toLowerCase(); return localSignature;&#125;/** * 取得未加密的请求参数字符串&lt;br/&gt; * 注：1.该字符串的组成规则为： * 1.1 请求参数 &apos;key&apos;+&apos;value&apos;成对 * 1.2 依据字母顺序表：a--&gt;b--&gt;c--&gt;...--&gt;y--&gt;z 对‘请求参数key’排序 * 2.该字符串中不包括signature * */static String getRequestParameterString(Map&lt;String, String[]&gt; parameterMap) &#123; if (parameterMap == null || parameterMap.size() == 0) &#123; return null; &#125; List&lt;String&gt; parameterNameList = new ArrayList&lt;&gt;(parameterMap.keySet()); // 对请求的key 排序 parameterNameList.sort &#123; a, b -&gt; (a &lt;=&gt; b) &#125;; StringBuffer strBuffer = new StringBuffer(); for (String parameterName : parameterNameList) &#123; //排除签名 if (parameterName == &quot;sign&quot;) &#123; continue; &#125; String[] values = parameterMap.get(parameterName); if (values != null) &#123; if (values.length == 1) &#123; strBuffer.append(parameterName + values[0]); &#125; else &#123; //此处规则 省略。。。。 &#125; &#125; &#125; return strBuffer.toString();&#125;/*** * MD5加密 生成32位md5码 * * @param inStr 待加密字符串 * @return 返回32位md5码 */ static String md5(String inStr, Charset charset) &#123; MessageDigest messageDigest = null; try &#123; messageDigest = MessageDigest.getInstance(&quot;MD5&quot;); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; if (messageDigest == null) &#123; throw new NullPointerException(); &#125; messageDigest.update(inStr.getBytes(charset)); byte[] digestBytes = messageDigest.digest(); return Hex.encodeHexString(digestBytes);&#125;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java操控excel相关(poi,jxl)笔记]]></title>
    <url>%2Fming%2Fd3259856.html</url>
    <content type="text"><![CDATA[poi和jxl介绍poi和jxl操作excel不同点poi读写excel实例jxl读写excel实例poi读写word实例poi和jxl选择1:poi和jxl介绍1.1:poipoi是对所有office资源进行读写的一套工具包、属于apache开源组织。 1.2:jxljxl只能对excel进行操作的一套工具包。 2:两者操作excel不同点poi和jxl都是封装了对excel操作方法; poi是把整个文件的属性都封装在HSSFWorkbook 中; 通过HSSFWorkbook来操作单个工作薄。然后通过工作薄来操作行; 在通过行来操控单元格。这样一级一级的分拆下来; HSSFWorkbook----&gt;HSSFSheet-----&gt;HSSFRow----&gt;HSSFCell; 由于是基于HSSFWorkbook对象一步步创建起来的。所以不用把创建好的单元格添加进这个对象中、 如果需要对部分表格进行设置样式什么的。就可以创立HSSFCellStyle对象来进行设定样式; jxl是把整个文件封装在Workbook相关对象中; 通过Workbook去创建sheet工作薄;但是和poi不一样的地方是 jxl是通过向sheet中使用label(单元格)来进行读取写入; Workbook-----&gt;sheet------&gt;label ; jxl是先创建一个工作区域、然后区创立单元格、单元格包含这个单元格的位置、内容等信息;然后把这个单元格加入工作区; ###3：poi读写excel文件的实例(代码中fileURL是你存放路径)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//写入public void poiWriteExcel() &#123; //创建excel工作薄 HSSFWorkbook hssfWorkbook = new HSSFWorkbook(); //在里面创建一个sheet 名字为工作薄1 HSSFSheet hssfSheet = hssfWorkbook.createSheet(&quot;工作薄1&quot;); //在索引为o的位置创建行 也就是第一行 HSSFRow oneRow = hssfSheet.createRow(0); //创建红色字体 HSSFFont font = hssfWorkbook.createFont(); font.setColor(HSSFFont.COLOR_RED); //创建格式、 HSSFCellStyle cellStyle = hssfWorkbook.createCellStyle(); cellStyle.setFont(font); //在第o行创建第一个单元格 HSSFCell cell = oneRow.createCell(0); //使用单元格格式 cell.setCellStyle(cellStyle); //在第一个单元格输入内容 cell.setCellValue(&quot;xu&quot;); //创建一个第十行 HSSFRow tenRow = hssfSheet.createRow(9); //创建输出流 try &#123; FileOutputStream fileOutputStream = new FileOutputStream(fileURL + &quot;xianyu.xls&quot;); //存储工作博 hssfWorkbook.write(fileOutputStream); fileOutputStream.flush(); fileOutputStream.close(); &#125; catch (IOException e) &#123; System.out.println(&quot;无法写入&quot;); e.printStackTrace(); &#125; &#125;//读取public void poiReadExcel() &#123; HSSFWorkbook hssfWorkBook = null; try &#123; hssfWorkBook = new HSSFWorkbook(new FileInputStream(fileURL + &quot;xianyu.xls&quot;)); //获取第一个工作薄 HSSFSheet hssfSheet = hssfWorkBook.getSheetAt(0); //获取第一行 HSSFRow row = hssfSheet.getRow(0); System.out.println(row.getCell(0)); &#125; catch (IOException e) &#123; System.out.println(&quot;无法读取&quot;); e.printStackTrace(); &#125; &#125; ###4:jxl读写excel123456789101112131415161718192021222324252627282930313233343536//写入public void jxlWriteExcel() &#123; try &#123; //创建xls WritableWorkbook wwb = Workbook.createWorkbook( new FileOutputStream(fileURL + &quot;xianyujxl.xls&quot;)); //添加工作薄 WritableSheet sheet = wwb.createSheet(&quot;工作薄1&quot;, 0); //添加单元格 Label(x,y,z) x=列 y=行 z=内容 Label label = new Label(0, 0, &quot;xu&quot;); //添加进工作薄 sheet.addCell(label); // 写数据 wwb.write(); wwb.close(); &#125; catch (IOException e) &#123; System.out.println(&quot;写入失败&quot;); e.printStackTrace(); &#125; catch (WriteException e) &#123; e.printStackTrace(); &#125; &#125;//读取public void jxlReadExcel() &#123; try &#123; //获取excel Workbook wb = Workbook.getWorkbook( new FileInputStream(fileURL + &quot;xianyujxl.xls&quot;)); //获取sheet工作薄 Sheet sheet = wb.getSheet(0); System.out.println(sheet.getCell(0, 0).getContents()); &#125; catch (IOException | BiffException e) &#123; e.printStackTrace(); &#125; &#125; ###5:poi读写word12345678910111213141516171819202122232425262728293031//写入public void poiWriteWord() &#123; try &#123; //创建word文件 XWPFDocument xwpfDocument = new XWPFDocument(); //新建段落 XWPFParagraph xwpfP = xwpfDocument.createParagraph(); //创建文本 XWPFRun xwpfR = xwpfP.createRun(); xwpfR.setText(&quot;xu&quot;); xwpfDocument.write(new FileOutputStream(fileURL + &quot;xianyu.doc&quot;)); &#125; catch (IOException e) &#123; System.out.println(&quot;无法写入&quot;); e.printStackTrace(); &#125; &#125;//读取public void poiReadWord() &#123; //获取doc对象 XWPFDocument xwpfDocument; try &#123; xwpfDocument = new XWPFDocument(new FileInputStream(fileURL + &quot;xianyu.doc&quot;)); //获取段落并且遍历 xwpfDocument.getParagraphs().forEach(xwpfParagraph -&gt; System.out.println(xwpfParagraph.getText())); &#125; catch (IOException e) &#123; System.out.println(&quot;无法读取&quot;); e.printStackTrace(); &#125; &#125; 6：poi和jxl选择不用想了、肯定poi 因为jxl很久不更新了。poi现在是apache的项目、前景好、文档全]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea 常用插件]]></title>
    <url>%2Fming%2Fa365393a.html</url>
    <content type="text"><![CDATA[名称功能快捷键备注ace jump文件中匹配字符串跳转ctrl+;常用在代码中匹配跳转vim使用类似vim方式操作文件内容vim控使用find bugs查找代码中不符合他的规范的代码略坑 但是有点用.ignoregit 配置忽略文件的插件可以通过查看是否变灰 来确定配置是否生效bashsupport写bashshell脚本的插件一般用途 shell脚本 不是很需要这个lombok配合lombok.jar使用lombok 很不错 能让代码看起来 更加干净整洁markdown support书写markdown 文件的插件还不错 用起来 和简书上差不多code glance代码试图pgup pgon 上下翻屏]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中文写java]]></title>
    <url>%2Fming%2Fe8ebc393.html</url>
    <content type="text"><![CDATA[###偶然间发现java底层是采用utf16做编码集的 突发奇想 既然是utf16做底层编码 拿起不是可以拿非英文开发 毕竟编译器可以识别中文那么肯定也可以编译中文###代码尝试：12345678910111213class 垃圾&#123; public void 一个垃圾方法()&#123; System.out.println(&quot;真的垃圾&quot;); &#125; public void 两个垃圾方法(String 垃圾参数)&#123; System.out.println(&quot;第二个垃圾方法的垃圾参数:&quot;+垃圾参数); &#125; public static void main(String[] args) &#123; 垃圾 垃圾的实例=new 垃圾(); 垃圾的实例.一个垃圾方法(); 垃圾的实例.两个垃圾方法(&quot;啦等等单打独斗&quot;); &#125;&#125; ####总结:java真的贼几把神奇、这样看来几乎可以用任何utf16包含的语言去编写java了]]></content>
      <categories>
        <category>骚想法</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jsp 自定义标签]]></title>
    <url>%2Fming%2Fdd01bc67.html</url>
    <content type="text"><![CDATA[###在做jsp项目中除了一些框架的标签如spring、jstl、shiro等标签 可能还需要自定义一些常用标签 如page等###自定义jsp标签有两种方式1:java bean+ tld1通过tld来调用java中的代码 这种写法 参考http://www.runoob.com/jsp/jsp-custom-tags.html 2:tag文件123456789101112131415161718直接定义一个后缀为tag的文件 这种方式比 java bean+tld 简单方便 容易使用和定义tag文件头 如下设置 其他按照jsp使用即可 可以导入其他标签库、java代码、等//定义tag的编码集合&lt;%@tag pageEncoding=&quot;UTF-8&quot; %&gt;//定义一个名字为str 类型为string的必须元素&lt;%@attribute name=&quot;str&quot; required=&quot;true&quot; type=&quot;java.lang.String&quot; %&gt;//定义一个名字为flag 类型为boolean 的非必须元素&lt;%@attribute name=&quot;flag&quot; required=&quot;false&quot; type=&quot;java.lang.Boolean&quot; %&gt;。。。。。省略业务代码 这里就跟写jsp一样调用:在jsp头部加上这个标签所在的文件夹 是文件夹不是单个标签 &lt;%--自定义的标签位置--%&gt;&lt;%@taglib prefix=&quot;tags&quot; tagdir=&quot;/WEB-INF/tags&quot; %&gt;然后使用即可 例如实例代码文件名为 test.tag &lt;tags:test str=&quot;test&quot;&gt;&lt;/tags:test&gt;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java基础</tag>
        <tag>jsp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式(一)-六大基本原则]]></title>
    <url>%2Fming%2Fae7599d.html</url>
    <content type="text"><![CDATA[开闭原则(open close princlple)“对扩展开发,对修改关闭”,当程序需要扩展的时候不能去修改源代码，要实现一个热插拔效果。通过使用接口和抽象类去设计。这样在以后替换方法实现算法的时候只需要实现接口使用这个类就可以了开闭原则关键步骤是抽象例如:sf4j 和log4j之间 sf4j定义了日志框架的大部分接口。log4j只是实现sf4j其中一种。里氏替换原则(liskov substitution princlple)任何基础类可以出现的地方.他的子类一定可以出现。只有当派生类可以替换基本类。并且软件不受到影响，基础类才能被真正的复用。里氏替换原则 对抽象化的具体步骤实现的规范 。补充了开闭原则例如hinernate中orm名称映射规则。如果需要自己制定规则 只需要继承或者实现已有的基础类 就可以把这个类设置成hibernate的orm替换规则例如:数据库表要求全部是以T开头 后面采用下划线方式命名 但是entity采用去除T 并且采用驼峰式命名这个时候就实现hibernate的转换接口然后设置成自定义的类就行了##依赖倒转原则(dependence lnversion princlple)针对抽象出来的结构编程。依赖抽象出来的类或者接口编程。不依赖具体实现就是面向接口编程 例子： list 我可以用arraylist 也可以用linkedlist 但是他们都是list接口的方法接口隔离原则(interface segregation prinalple)使用多个隔离的接口比使用单个接口好,降低接口和实现类之间的耦合迪米特法则(demeter princlple) 最少知道法则一个类尽量少知道和其它实体之间的相互作用 让系统模块相对独立合成复用原则(composite reuse princlple)尽量使用合成和聚合 尽量少使用继承就是一个复杂类应当由很多小类合成聚合而来 不是继承一个类去做增加##总结####设计模式就是依赖这些基本法则的最佳实现#设计模式笔记参考:http://www.runoob.com/design-pattern/design-pattern-tutorial.html]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xml和json的区别及其使用范围笔记]]></title>
    <url>%2Fming%2Fd61f2d28.html</url>
    <content type="text"><![CDATA[###老是有人问我xml和json区别、 特写此篇记录来列出xml和json区别，懒得每次都解释、网络中很多博客都没提到关键的区别点 自述性、规范性;其他什么解析方法、啥啥的都不是最重要的最主要的就是xml能够由很强的自述性、规范性###相同点:1231:都是一种数据传输格式2:都和平台没有关系 xml和json都是对平台没有限制 只需要按照他们的规则进行解析即可3:只要是能序列化和反序列化的数据都能传输 例如图片完全可以转成二进制或者16进制字符串传输然后反序列化成图片 （不推荐这样玩 容易损坏） ###不同点:123451:xml具有自述性 就是可以包含自我描述的元数据 例如&lt;name type=&quot;string&quot;&gt;xianyu&lt;/name&gt;这个就描述了name的值是xianyu类型是stringjson就无法这样直观的表述 这样就用来写配置及其方便、准确 用json也能写配置只要你不怕看的头疼2:xml具有很强的规范性 你可以自己制定xml schema 来制定规范 json则没有这样的规范 只能间接的通过额外的json来为json定义格式 不方便而且麻烦 ##如何选择121:当需要传输具有元数据的数据的时候就肯定要用xml，2:当需要节省流量、简化数据解析的时候要用json ##解析难度12345xml有sax和dom两种解析方式 都差不多 sax是把xml模拟成一个流然后对其中需要的字段进行解析 这种方法不能修改dom是按照xml的元素结构进行解析 一般都是直接把xml加载到内存进行分析 可以修改 json就是把它当作字符串进行基于json格式的解析 ##总结: ###xml和json都由各自适用的范围不能说那个替代那个 json在做数据传输方面比xml好一点 毕竟没xml冗杂，但是在传输那种能需要自述性、和严格规范的数据的时候xml是无可替代的 在做webservice的时候 两种都会用]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>xml</tag>
        <tag>json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式笔记(七)：创建型-原型模式]]></title>
    <url>%2Fming%2F5a9f0461.html</url>
    <content type="text"><![CDATA[##原型模式：（Prototype Pattern）####意图用原型实例来指定创建对象的种类，并且通过拷贝这些原型创建新的对象####主要解决在运行期建立和删除原型####何时使用1：当一个系统应该独立于它产品创建构成和表示的时候。2：当要实例化的类是在运行时刻指定的时候 ，例如动态装载3：为了避免创建一个与产品类层次平行的工厂类层次4：当一个类的实例智能有几个不同状态组合中的一种时候，建立相应数目的原型并克隆他们 比每次用合适的状态的手工实例化该 类更方便一些####如何解决利用已有的一个原型对象，快速生成和原型对象一样的实例####关键代码1：实现克隆操作 利用Cloneable 重写clone(),2:原型模式同样用于隔离类对象使用者和具体类型（易变类）之间耦合关系，要求易变类拥有稳定的接口####实例1：细胞分裂2：java object clone() 方法####优点1：提高性能2：避免构造函数约束####缺点1：配备克隆方法需要对类的功能进行通盘考虑，对于全新的类不麻烦，但是对于已经有的类不容易实现，特别是一个类引用不支持串行化的间接对象或者引用含有循环结构的适合2：必须实现Cloneable接口3：逃避构造函数约束####使用场景1：资源优化2：类初始化需要很多资源，3：性能和安全要求场景4：通过new产生对象需要非常繁琐的数据准备或者访问权限5：一个对象多个修改者6：一个对象需要提供给其他对象访问，并且多个调用者都需要修改其值，7：实际项目中原型模式常根工厂模式一起，通过clone创建一个对象，如何由工厂方法提供给调用者，####注意和对一个类来实例化创建对象不同的是，原型模式是通过一个现有的对象生成一个新的对象，浅拷贝通过Cloneable ，深拷贝通过Serializable读取二进制流####总结：通过实现cloneable的clone（） 方法来实现浅克隆 通过序列化获取二进制流 来进行深度克隆 就是自行创建一个可靠安全的原型 通过克隆方式获得该对象####代码地址：https://github.com/xuxianyu/myGitHub/tree/master/DisignPattern/src/main/java/com/xxx/create/Prototype]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式(二)-23种设计模式分类和基本概述]]></title>
    <url>%2Fming%2F18dacc63.html</url>
    <content type="text"><![CDATA[##创建型模式：提供在创建对象的时候的逻辑，不是直接使用运算符如new这样的形式来实例化对象，模式名称 | 模式概述 | 备注—–|:————|:—–工厂模式(Factory Pattern) | 就是一个产品加工共厂的套路 负责产生一些大致相似的产品 | 例如生产娃娃的加工厂 生产娃娃 有的是充气的 有的是硅胶的 但是你只需要指定是使用什么材料 就可以通过工厂产生出来抽象工厂模式(Abstract Factory Pattern)| 工厂的工厂 用来生产工厂的工厂| 例如我有建造硅胶产品工厂的能力 我可以拿来建立娃娃工厂、我也可以拿来建立其他硅胶产品工厂单例模式(Singleton Pattern)| 一个类只能有一个对象，并且是需要线程安全的创建 | 在国内一个人名义上是只能有一个老婆的，如果你想两个合法老婆 那就违法了 也就是线程不安全了建造者模式(Builder Pattern)| 在将类组合成复杂对象的时候 被组合的类是变化的 但是组合的方式是固定的 | 例如娃娃工厂 里面需要很多基本的设备 什么融合材料的设备、将材料做成模型的设备、模型组合设备等等。他们大致组合顺序是固定的但是设备选择不一定，可以买国产货也可以使用其他国家的机器。原型模式(Prototype Pattern)| 先创建一个原型 以后在需要这个对象 直接克隆 | 例如生产娃娃 你有一个波多XXX 啥的娃娃 但是她的制作工艺比较复杂 那这个时候可以通过这个娃娃去做一套模具来进行克隆 这样就能保证快速 完整的作出波多XXX样式的娃娃##结构型模式：关注类和对象的组合，用继承来组合接口和定义组合对象获取新功能的方式模式名称 | 模式概述 | 备注——–|:———|:—–适配器模式(Adapter Pattern)|就是一个类似转接头的东西 主要是针对类的兼容性做改变 让旧类和新类进行兼容|例如苹果7手机 它本身是不能直接使用ust数据线链接电脑的必须找个type-c转换成usb接口的设备来做个适配桥接模式(Bridge Pattern)||过滤器模式(Filter\Criteria Pattern)||组合模式(Composite Pattern)||装饰器模式(Decorator Pattern)||外观模式(Facade Pattern)||享元模式(Flyweight Pattern)||代理模式(Proxy Pattern)||##行为型模式:关注对象之间的通信模式名称 | 模式概述 | 备注——–|:———|:—–责任链模式(Chain of Responsibllity Pattern)||命令模式(Command Pattern)||解释器模式(InterPreTer Pattern)||迭代器模式(Iterator Pattern)||中介者模式(Mediator Pattern)||备忘录模式(Memento Pattern)||观察者模式(Observer Pattern)||状态模式(State Pattern)||空对象模式(null object Pattern)||策略模式(strategy Pattern)||模板模式(Template Pattern)||访问者模式(Visitor Pattern)||]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式笔记(三)：创建型-工厂模式]]></title>
    <url>%2Fming%2F80d0f7f9.html</url>
    <content type="text"><![CDATA[##工厂模式(factory pattern):####意图定义一个创建对象的接口。让其子类决定实例化那一个工程类，工厂模式将其创建过程延迟到子类中####主要解决主要解决接口选择问题。####何时使用在不同条件下创建不同实例。####如何解决让其子类实现工厂接口，返回的也是一个抽象的产品。关键代码创建过程在其子类中执行。####优点1,一个调用者创建一个对象。只要知道对象名旧可以 。2,扩展性高，想增加一个产品，扩展一个工厂类就可以。3,屏蔽产品实现。调用者只需要知道产品接口。####缺点每次增加产品，都需要增减一个实现类和对象实现工厂，增加系统复杂度。增加系统具体类依赖####使用场景1，日志记录，记录可能记录到硬盘，数据库，用户可以选择记录到哪里2,数据库访问，当用户不知道访问什么类型数据库的时候，hibernate方言就是这3,设计链接服务器的框架，需要三个协议“pop3”，“imap”，“http” 设计成产品类，共同实现一个接口。####注意事项当需要生成一个复杂对象的时候使用。如果是简单对象。不要使用工厂模式。会增加系统复杂度####个人总结：工厂模式适合在那些大体相同。但是细节不同的相似对象。例如hibernate方言。为了能自动选择方言编写的自动方言工厂类，但是工厂模式不适用于简单对象。####代码地址：https://github.com/xuxianyu/myGitHub/tree/master/DisignPattern/src/main/java/com/xxx/create/factory]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式笔记(九)：结构型-桥接模式]]></title>
    <url>%2Fming%2Fca9f8bd1.html</url>
    <content type="text"><![CDATA[##桥接模式(Bridge Pattern)####意图将抽象部分和实现部分分离，使他们可以独立变化####主要解决在多种可能变化的情况下，用继承会造成类爆炸的问题，不好扩展####何时使用实现系统可以有多个角度分类，每一个角度都可能变化####如何解决把这种多角度分类分离出来，让他们独立变化，减少之间的耦合####关键代码抽象类依赖实现类####应用实例1：猪八戒从天蓬元帅投胎到猪转世投胎机制将尘世划分为肉体和灵魂 ，前者相当于实现化，后者相当于抽象化，生灵通过功能委派，调用肉体对象，2：开关####优点1：抽象和实现分离2：优秀扩展能力3：实现细节对客户透明####缺点桥接模式会增加系统理解和设计难度，由于聚合关联关系在抽象层，需要开发者对抽象进行设计和编程####使用场景1：如果一个系统需要在组件抽象化角色和具体化角色之间有更多的灵活性，避免在两个层次之间建立静态继承关系，通过桥接模式可以使他们在抽象层建立一个关联关系2：对于不希望因为使用继承或者因为多层次继承导致类中个数急剧增加的系统3：一个类存在两个独立变化的维度 ，并且两个维度都需要进行扩展####注意对于两个独立变化的维度 使用桥接模式最合适####总结：利用一个中间接口来把多种不同状态的类进行分离####代码地址：https://github.com/xuxianyu/myGitHub/tree/master/DisignPattern/src/main/java/com/xxx/structural/bridge]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式笔记(八)：结构型-适配器模式]]></title>
    <url>%2Fming%2F6cd7a67e.html</url>
    <content type="text"><![CDATA[##适配器模式(Adapter Pattern)####意图当一个类的接口转换成客户希望的另外一个接口的适合，适配器模式使得原本由于接口不兼容不能一起工作的类可以在一起工作####主要解决在系统中常常要将一些现存的对象放到新环境中，而新环境接口是现存对象不能满足的####何时使用1：系统需要使用现有的类，但是这个类的接口不满足系统需要2：想要建立一个可以重复使用的类，用于一些批次之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作，这些源类不一定有一致的即可3：通过接口转换，将一个类插入到另一个类系中，（比如老虎和飞禽，现在多了一个能飞的老虎，在不增加实体需求下 增加一个适配器，里面包含虎对象，实现飞接口）####如何解决继承或者依赖####关键代码适配器继承或者依赖已经有的对象，实现想要的目标接口####实例1：美国电器110v 中国220v 需要一个适配器来转换2：jdk1.1提供Enumeration接口 现在1.2中提供了iterator接口 ，想要使用1.2jdk 就要把一起系统的Rnumeration接口转换iterator接口3：linux上运行windows程序4：jvm就是一个类似适配器的一个虚拟机####优点1：可以让两个没有关联的类一起运行，2：提高类的复用3：增加类的透明4：灵活####缺点1：过多使用适配器，让系统显得凌乱 ，不容易把握整体，比如明明调用的是a接口但是内部适配成b接口的实现，一个系统中出现太多这种情况会爆炸，如果不是很有必要不适用适配器，而是对系统重构2：由于java只能继承一个类，所以最多只能适配一个适配类，而且目标类必须是抽象类####使用场景有动机的修改一个运行正常的系统接口####注意适配器不是详细设计时候设计的 而是解决在系统上线过程中出现问题####总结：通过一个中间适配器类来增加已有类的功能，这个只是补救方式 最好的方式还是重构项目####代码地址：https://github.com/xuxianyu/myGitHub/tree/master/DisignPattern/src/main/java/com/xxx/structural/adapter]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式笔记(四)：创建型-抽象工厂模式]]></title>
    <url>%2Fming%2Fb2f1ab54.html</url>
    <content type="text"><![CDATA[##抽象工厂模式（Abstract Factory Pattern）####意图提供一个创建一系列相关或者互相依赖的对象接口，无需指定他们具体类####主要解决解决接口选择问题####何时使用系统产品多于一个产品族，而系统只消费其中某一族产品####如何解决在一个产品族中定义多个产品####关键代码在一个工厂里聚合多个同类产品####实例假设生产衣服 有商务男装、商务女装、时尚男装、时尚女装等等、都放在各自种类衣柜中。衣柜就承当抽象工厂的作用。其中衣柜中上衣、裤子 都是单独的产品####优点当一个产品族中多个对象被设计成一起工作的时候，它能保证客户端始终只使用其中一个产品族 不会乱套####缺点产品族扩展困难。要增加一个系列的一个产品 既要在抽象工厂里面加代码又要在具体里面加代码####使用场景1：qq换肤2：生成不同操作系统的程序####注意事项产品族难维护。等级好扩展####个人总结：抽象工厂 用来生成工厂 然后来选择具体的产品####代码地址：https://github.com/xuxianyu/myGitHub/tree/master/DisignPattern/src/main/java/com/xxx/create/abstractfactory]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式笔记(六)：创建型-建造者模式]]></title>
    <url>%2Fming%2F67fc4778.html</url>
    <content type="text"><![CDATA[##建造者模式(builder pattern)####意图将一个复杂构建与其标识相分离，使得同样构建过程构建出不一样的标识####主要解决在创建复杂对象过程中，通常是各个部分子对象用一定算法构建而成;由于需求变化，这个复杂对象各个部分经常面临剧烈变化，但是组合他们成为一个复杂算法是相对稳定的。####何时使用基本部件不变，但是组合经常变化（组合对象不定，算法固定）####如何解决变化部分和不变部分分离####关键代码1：建造者：创建和提供实例2：导演：管理建造出来的实例依赖关系####实例肯德基，有汉堡、可乐、薯条等是不变对象，但是其中他们组合是经常变化的####优点1：建造者独立，容易扩展2：便于细节风险控制####缺点1：产品必须有共通点，因此限制范围2：内部变化复杂的化会出现很多建造类####使用场景1：需要生成复杂对象有复杂的内部结构2：需要生成对象内部属性相互依赖####注意事项建造者模式更加关注零件装配的顺序而工厂模式关注的是产品结果####个人总结：在组合复杂对象的时候 可以采用建造者模式 这样只需要在构建类中区定义生成对象的依赖就可以了####代码地址：https://github.com/xuxianyu/myGitHub/tree/master/DisignPattern/src/main/java/com/xxx/create/builder]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式笔记(五)：创建型-单例模式]]></title>
    <url>%2Fming%2Fb5989355.html</url>
    <content type="text"><![CDATA[##单例模式（Singleton Pattern）####注意1：单例类只能有一个实例2：单例类必须自己创建自己唯一的实例3：单例类必须给其他对象提供这个实例####意图保证一个类仅有一个实例。并提供一个访问它的全局访问点####主要解决一个全局使用的类频繁创建销毁####何时使用控制实例数目。节省系统资源####如何解决判断系统是否已经有这个单例。如果有返回、没有创建####关键代码构造函数私有化####应用实例1：一个党只有一个主席2：多线程中对文件的处理必须是唯一的一个实例来进行。3：设备管理器常常被设计为单例模式。比如一个电脑有两台打印机。在输出的适合不能两台打印同一个文件####优点1：内存中只有一个实例，减少内存开销，2：避免对资源的多重占用####缺点：没有接口、不能继承。和单一职责冲突。####使用场景1：产生唯一序列号2：计数器3：创建比较耗费资源的对象比如io 与数据库链接等####总结：共有 懒汉式线程不安全、懒汉式线程安全（加锁）、饿汉式、双捡锁、登记式、枚举这些方式来创建单例 其中饿汉式，双捡锁，登记式，枚举比较适合平常用。懒汉式要么不 安全 要么效率低下不建议使用####代码地址：https://github.com/xuxianyu/myGitHub/tree/master/DisignPattern/src/main/java/com/xxx/create/singleton]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重写eq 必须重写hashcode的必要性]]></title>
    <url>%2Fming%2F605805fa.html</url>
    <content type="text"><![CDATA[重写eq 必须重写hashCode的原因之前唆代码 每次都单独重写 eq 方法 hashCode从来不重写 这次遇到一个 Set的内容比较 一直返回的不是理想的结果查看源码 发现 其实 最开始是直接使用 == 方式比较 到最后才会用eq方法比较然后顺手写了一波实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116/** * @author ming * @date 2017-10-31 11:30 */public class Test &#123; @org.junit.Test public void test() &#123; Set&lt;A&gt; aSet1 = new HashSet&lt;&gt;(); aSet1.add(new A(&quot;a&quot;, 1)); Set&lt;A&gt; aSet2 = new HashSet&lt;&gt;(); aSet2.add(new A(&quot;a&quot;, 1)); System.out.println(&quot;未重写 eq 和hashCode---------&quot;); System.out.println(aSet1.equals(aSet2)); System.out.println(); Set&lt;B&gt; bSet1 = new HashSet&lt;&gt;(); bSet1.add(new B(&quot;b&quot;, 1)); Set&lt;B&gt; bSet2 = new HashSet&lt;&gt;(); bSet2.add(new B(&quot;b&quot;, 1)); System.out.println(&quot;重写 eq ----------&quot;); System.out.println(bSet1.equals(bSet2)); System.out.println(); Set&lt;C&gt; cSet1 = new HashSet&lt;&gt;(); cSet1.add(new C(&quot;c&quot;, 1)); Set&lt;C&gt; cSet2 = new HashSet&lt;&gt;(); cSet2.add(new C(&quot;c&quot;, 1)); System.out.println(&quot;重写 hashCode ------&quot;); System.out.println(cSet1.equals(cSet2)); System.out.println(); Set&lt;D&gt; dSet1 = new HashSet&lt;&gt;(); dSet1.add(new D(&quot;d&quot;, 1)); Set&lt;D&gt; dSet2 = new HashSet&lt;&gt;(); dSet2.add(new D(&quot;d&quot;, 1)); System.out.println(&quot;重写 eq 和hashCode----&quot;); System.out.println(dSet1.equals(dSet2)); &#125;&#125;@Getter@Setter@NoArgsConstructor@AllArgsConstructorclass A &#123; private String aName; private Integer aNum;&#125;@Getter@Setter@NoArgsConstructor@AllArgsConstructorclass B &#123; private String bName; private Integer bNum; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; B b = (B) o; if (bName != null ? !bName.equals(b.bName) : b.bName != null) return false; return bNum != null ? bNum.equals(b.bNum) : b.bNum == null; &#125;&#125;@Getter@Setter@NoArgsConstructor@AllArgsConstructorclass C &#123; private String cName; private Integer cNum; @Override public int hashCode() &#123; int result = cName != null ? cName.hashCode() : 0; result = 31 * result + (cNum != null ? cNum.hashCode() : 0); return result; &#125;&#125;@Getter@Setter@NoArgsConstructor@AllArgsConstructorclass D &#123; private String dName; private Integer dNum; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; D d = (D) o; if (dName != null ? !dName.equals(d.dName) : d.dName != null) return false; return dNum != null ? dNum.equals(d.dNum) : d.dNum == null; &#125; @Override public int hashCode() &#123; int result = dName != null ? dName.hashCode() : 0; result = 31 * result + (dNum != null ? dNum.hashCode() : 0); return result; &#125;&#125; 此实例看出 对于比较对象是否相同来说 单纯的重写 eq或者 hashCode都是没卵用很多方法底层是包含 == 和eq方法比较的 除非非常熟悉 只用单独写eq或者HashCode否则 都应该重写 避免达不到预期结果]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[guava-cache笔记]]></title>
    <url>%2Fming%2F1be97d35.html</url>
    <content type="text"><![CDATA[## guava cache工具示例12345678910111213141516171819202122232425262728293031323334353637/** * 缓存示例 * * @author ming * @date 2017/8/7 */ @Test public void helloWorldTest() throws ExecutionException &#123; LoadingCache&lt;Long, String&gt; strCache = CacheBuilder.newBuilder().maximumSize(1000) .expireAfterWrite(10, TimeUnit.MINUTES) .build(new CacheLoader&lt;Long, String&gt;() &#123; //有这个键就从缓存中去 没有就根据load方法从新获取 //如果load没有显示抛出异常 可以用getUnchecked查找缓存 如果显示抛出 就不能使用getUnchecked @Override public String load(Long o) throws Exception &#123; return &quot;缓存:&quot; + o; &#125; //批量加载 @Override public Map&lt;Long, String&gt; loadAll(Iterable&lt;? extends Long&gt; keys) throws Exception &#123; Map&lt;Long,String&gt; tempMap = Maps.newConcurrentMap(); keys.forEach(key-&gt;&#123; tempMap.put(key,&quot;缓存:&quot;+key); &#125;); return tempMap; &#125; //重新加载 @Override public ListenableFuture&lt;String&gt; reload(Long key, String oldValue) throws Exception &#123; return super.reload(key, oldValue); &#125; &#125;); System.out.println(strCache.get(1L)); System.out.println(strCache.get(1L)); System.out.println(strCache.get(2L)); &#125; ####适合的场景 通过消耗内存提高速度 预料到某些数据会被频繁查询 缓存数量不会超过内存####需要注意的点 如果显示抛出异常 不可使用getUnchecked(); 可以通过重写load、loadAll、reload方法来进行单个加载获取、组合加载获取、重新加载 getAll 默认是通过load来加载没有缓存的信息 除非重写loadAll####Callable加载可以通过不同的回调函数 来缓存从不同数据源来的数据 不局限于load方法来缓存数据123456789101112131415161718192021222324252627282930/** 回调方式 执行获取缓存 方便实现&quot;如果有缓存则返回；否则运算、缓存、然后返回&quot; * 可以在同一个cache对象中 通过不同方法获取 源数据 * @author ming * @date 2017/8/7 */ @Test public void callableTest() throws ExecutionException &#123; //创建缓存对象 不重写cacheLoader 利用callable来从源数据获取缓存 不管有没有重写 callable优先 Cache&lt;Long,String&gt; cache = CacheBuilder.newBuilder().maximumSize(1000).build(new CacheLoader&lt;Long, String&gt;() &#123; //使用带回调方式获取缓存 优先执行回调方法获取的缓存 @Override public String load(Long key) throws Exception &#123; return &quot;缓存:&quot;+key; &#125; &#125;); //创建 通过回调获取缓存 System.out.println(cache.get(1L, new Callable&lt;String&gt;() &#123; public String call() throws Exception&#123; return &quot;回调缓存:&quot;+1L; &#125; &#125;)); System.out.println(cache.get(2L, new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; return &quot;回调缓存2：&quot;+2; &#125; &#125;)); &#125; ####缓存回收 基于容量回收(size-based eviction)如果只是不超过固定值 直接使用maximumSize()构建 如果要通过不同的权重来计算实现Weigher 定时回收(timed eviction) expireAfterAccess(long, TimeUnit)：缓存项在给定时间内没有被读/写访问，则回收。请注意这种缓存的回收顺序和基于大小回收一样。 expireAfterWrite(long, TimeUnit)：缓存项在给定时间内没有被写访问（创建或覆盖），则回收。如果认为缓存数据总是在固定时候后变得陈旧不可用，这种回收方式是可取的。 基于引用(Reference-based eviction) CacheBuilder.weakKeys()：使用弱引用存储键。当键没有其它（强或软）引用时，缓存项可以被垃圾回收。因为垃圾回收仅依赖恒等式（==），使用弱引用键的缓存用==而不是equals比较键。 CacheBuilder.weakValues()：使用弱引用存储值。当值没有其它（强或软）引用时，缓存项可以被垃圾回收。因为垃圾回收仅依赖恒等式（==），使用弱引用值的缓存用==而不是equals比较值。 CacheBuilder.softValues()：使用软引用存储值。软引用只有在响应内存需要时，才按照全局最近最少使用的顺序回收。考虑到使用软引用的性能影响，我们通常建议使用更有性能预测性的缓存大小限定（见上文，基于容量回收）。使用软引用值的缓存同样用==而不是equals比较值。 显示清除 个别清除：Cache.invalidate(key) 批量清除：Cache.invalidateAll(keys) 清除所有缓存项：Cache.invalidateAll()####监听器removalListener默认是同步进行的 可以通过RemovalListeners.asynchronous(RemovalListener,Executor)装饰成 异步123456789101112131415161718192021222324252627282930313233/**清除缓存监听器 * @author ming * @date 2017/8/8 */ @Test public void listenerTest() throws ExecutionException &#123; RemovalListener&lt;Long,String&gt; removalListener = new RemovalListener&lt;Long, String&gt;() &#123; //移除动作监听器 同步进行 @Override public void onRemoval(RemovalNotification&lt;Long, String&gt; notification) &#123; System.out.println(&quot;\n删除缓存:&quot;+notification); System.out.println(notification.getKey()); System.out.println(notification.getValue()); //清除原因 返回是什么情况下清除的 例如超过大小、手动清除等 System.out.println(notification.getCause()); //是否是自动清除 System.out.println(notification.wasEvicted()); &#125; &#125;; //装饰成异步的 //RemovalListeners.asynchronous(removalListener, new Executor&#123;...&#125;); Cache&lt;Long,String&gt; cache= CacheBuilder.newBuilder().maximumSize(1000) .removalListener(removalListener).build(); //添加缓存 cache.get(1L, new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; return &quot;回调缓存:&quot;+1L; &#125; &#125;); //显示删除缓存 被removalListener监听到 cache.invalidate(1L); &#125; ####刷新 指定刷新 cache.refresh(key) 定时刷新CacheBuilder.refreshAfterWrite(到时间、访问过期的数据才会触发)、CacheBuilder.expireAfterWrite(到时间直接刷新数据)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 刷新缓存 * * @author ming * @date 2017/8/8 */ @Test public void refreshTest() throws ExecutionException, InterruptedException &#123; //定时执行服务 ScheduledExecutorService executor = new ScheduledThreadPoolExecutor(10); LoadingCache&lt;Integer, String&gt; cache = CacheBuilder.newBuilder() .maximumSize(1000) //定时刷新 到时间后 访问过期数据后进行刷新 优先级比expireAfterWrite高 //.refreshAfterWrite(100,TimeUnit.MILLISECONDS) //定时刷新 到时间直接刷新 //.expireAfterWrite(100,TimeUnit.MILLISECONDS) .build(new CacheLoader&lt;Integer, String&gt;() &#123; @Override public String load(Integer key) throws Exception &#123; return &quot;load缓存+&quot; + key; &#125; @Override public ListenableFuture&lt;String&gt; reload(Integer key, String oldValue) throws Exception &#123; //当key &lt;2的时候 直接刷新 当key&gt;=2 异步刷新 if (key &lt; 2) &#123; return Futures.immediateFuture(oldValue); &#125; else &#123; //异步 ListenableFutureTask&lt;String&gt; task = ListenableFutureTask.create(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; return &quot;异步刷新缓存&quot; + System.currentTimeMillis(); &#125; &#125;); executor.execute(task); return task; &#125; &#125; &#125;); System.out.println(cache.get(1)); System.out.println(cache.get(3)); //key&lt;2 cache.refresh(1); System.out.println(cache.get(1)); //key &gt;= 2 异步刷新 cache.refresh(3); //由于是异步刷新 获取最新数据 主线程休眠1s Thread.sleep(1000); System.out.println(cache.get(3)); &#125; ####统计缓存信息guava缓存提供统计缓存信息方法 CacheBuilder.recordStats()开启缓存 cache.stats()获取缓存12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 缓存统计信息 * * @author ming * @date 2017/8/8 */ @Test public void statTest() throws ExecutionException &#123; LoadingCache&lt;Integer, String&gt; cache = CacheBuilder.newBuilder() .maximumSize(1000) //开启缓存统计功能 .recordStats() .build(new CacheLoader&lt;Integer, String&gt;() &#123; @Override public String load(Integer key) throws Exception &#123; return &quot;缓存:&quot; + key; &#125; &#125;); //查询缓存 for (int i = 0; i &lt; 99; i++) &#123; cache.get(i); &#125; //查询已经缓存的数据 此时命中率 1% cache.get(1); CacheStats stats = cache.stats(); //请求次数 System.out.println(&quot;请求中次数:&quot; + stats.requestCount()); //命中次数 System.out.println(&quot;命中次数:&quot; + stats.hitCount()); //命中率 System.out.println(&quot;命中率:&quot; + stats.hitRate()); //miss数量 System.out.println(&quot;miss数量:&quot; + stats.missCount()); //miss 比例 System.out.println(&quot;miss率:&quot; + stats.missRate()); //加载数量 System.out.println(&quot;加载总数量:&quot; + stats.loadCount()); //加载成功数量 System.out.println(&quot;加载成功数量:&quot; + stats.loadSuccessCount()); //加载异常数量 System.out.println(&quot;加载异常数量:&quot; + stats.loadExceptionCount()); //加载异常比例 System.out.println(&quot;加载异常比例&quot; + stats.loadExceptionRate()); //加载总耗时 ns System.out.println(&quot;加载总耗时:&quot; + stats.totalLoadTime()); //加载新值的平均 时间 ns (ns/1000 = ms) System.out.println(&quot;加载源数据平均时间:&quot; + stats.averageLoadPenalty()); //缓存被回收的总数量 显示清除不算 System.out.println(&quot;被自动回收的数量:&quot; + stats.evictionCount()); // 减 本身-other 小于0 返回0 //System.out.println(stats.minus(new CacheStats(...))); // 加 本身+other //System.out.println(stats.plus(new CacheStats(...))); System.out.println(stats); &#125; 总结:guava的cache 适合那些微型项目、或者是一些小地方用用 ;大项目还是得靠 redis或者其他的方式来做;不过这个guava的cache 真心好用 异步加载、缓存刷新、过期策略 、缓存监控、都相当好用]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>guava</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rocketmq使用docker运行出现重复消费]]></title>
    <url>%2Fming%2F814d8f0a.html</url>
    <content type="text"><![CDATA[最近公司网docker切换 现在开发 测试环境切换 我们发现docker环境下 多节点的rocketmq存在一个重复消费的问题 一个消息 被多次消费了@author 欢总rocketmq 版本 3.2.6问题描述：测试环境在docker内部署了两个mq consumer，集群消费模式下，消息理应被平均消费，实际情况是每条消息都被消费了两次。线上环境是同样的配置，没有出现这个问题。关掉dokcer内一个consumer节点，本地再启动一个节点，发现也是正常的。猜想是mq consumer instanceName引起的，如果instanceName一样会重复消费，因为集群消费模式是按instanceName做为唯一消费实例的。翻了下源码发现，如果没有指定instanceName默认会把pid做为instanceName12345678910111213if (this.instanceName.equals(&quot;DEFAULT&quot;)) &#123; this.instanceName = String.valueOf(UtilAll.getPid());&#125;public static int getPid() &#123; RuntimeMXBean runtime = ManagementFactory.getRuntimeMXBean(); String name = runtime.getName(); // format: &quot;pid@hostname&quot; try &#123; return Integer.parseInt(name.substring(0, name.indexOf(&apos;@&apos;))); &#125; catch (Exception e) &#123; return -1; &#125;&#125; 查看dokcer内consumer的pid发现都是1（由于每台容器都是干净的，只跑一个程序，所以pid都是1），所以导致了重复消费，一般情况下跑在物理机上pid是不一样的（这里略坑，如果真碰巧一样就惨了），所以不会有问题。有两种解决方案：1.手动设置instanceName,使每个consumer节点instanceName不一样2.修改docker容器配置，使它运行时使用宿主机的pid ####总结:这个问题 略坑 mmp 大佬果然厉害 一个是rocketmq 如果没有instanceName会使用pid 做instanceName####一个是 docker容器都是纯净的会导致pid相同]]></content>
      <categories>
        <category>坑</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 运行秒退出解决办法]]></title>
    <url>%2Fming%2F52ab603.html</url>
    <content type="text"><![CDATA[###在学习docker的时候 遇到一个坑 就是当docker容器中没有前台运行的程序的时候 docker会认为这个容器没有工作内容会自动关闭这个容器解决方法:在写dockerfile的时候 记得留一个在前台执行的任务 特别是在做那种一般在后台运行的服务 如mysql这样的 需要让他在前台运行 mysqld.service]]></content>
      <categories>
        <category>坑</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot + quartz实现 动态定时任务笔记及其想法]]></title>
    <url>%2Fming%2Fb7d64853.html</url>
    <content type="text"><![CDATA[quartz 集成 到spring boot 中有个偷懒的方法 直接引用 这个 但是这个不是spring组织搞 的1:gradle 依赖配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061buildscript &#123; ext &#123; springBootVersion = &apos;1.5.8.RELEASE&apos; &#125; repositories &#123; mavenCentral() &#125; dependencies &#123; classpath(&quot;org.springframework.boot:spring-boot-gradle-plugin:$&#123;springBootVersion&#125;&quot;) &#125;&#125;apply plugin: &apos;java&apos;apply plugin: &apos;eclipse&apos;apply plugin: &apos;org.springframework.boot&apos;group = &apos;com.ming&apos;version = &apos;1.0&apos;sourceCompatibility = 1.8targetCompatibility = 1.8jar &#123; //指定 main class manifest&#123; attributes &apos;Main-Class&apos;: &apos;com.ming.StartMing&apos; &#125;&#125;repositories &#123; maven &#123; url &quot;http://maven.aliyun.com/nexus/content/groups/public/&quot; &#125; maven &#123; url &quot;http://repo.maven.apache.org/maven2&quot; &#125; mavenCentral()&#125;dependencies &#123; compile(&apos;org.springframework.boot:spring-boot-starter-actuator&apos;) compile(&apos;org.springframework.boot:spring-boot-starter-aop&apos;) compile(&apos;org.springframework.boot:spring-boot-starter-data-jpa&apos;) compile(&apos;org.springframework.boot:spring-boot-starter-mail&apos;) compile(&apos;org.springframework.boot:spring-boot-starter-thymeleaf&apos;) compile(&apos;org.springframework.boot:spring-boot-starter-validation&apos;) compile(&apos;org.springframework.boot:spring-boot-starter-web&apos;) runtime(&apos;org.springframework.boot:spring-boot-devtools&apos;) runtime(&apos;mysql:mysql-connector-java&apos;) //lombok http://blog.csdn.net/victor_cindy1/article/details/72772841 compile(&apos;org.projectlombok:lombok&apos;) testCompile(&apos;org.springframework.boot:spring-boot-starter-test&apos;) compile group: &apos;de.chandre.quartz&apos;, name: &apos;spring-boot-starter-quartz&apos;, version: &apos;1.0.1&apos; compile group: &apos;org.apache.shiro&apos;, name: &apos;shiro-spring&apos;, version: &apos;1.4.0&apos; compile group: &apos;org.apache.shiro&apos;, name: &apos;shiro-core&apos;, version: &apos;1.4.0&apos; compile group: &apos;com.google.guava&apos;, name: &apos;guava&apos;, version: &apos;22.0&apos; compile group: &apos;com.alibaba&apos;, name: &apos;fastjson&apos;, version: &apos;1.2.33&apos; compile group: &apos;org.apache.commons&apos;, name: &apos;commons-lang3&apos;, version: &apos;3.6&apos; compile group: &apos;org.apache.httpcomponents&apos;, name: &apos;httpcore&apos;, version: &apos;4.4.6&apos; compile(group: &apos;org.apache.httpcomponents&apos;, name: &apos;httpclient&apos;, version: &apos;4.5.3&apos;) &#123; exclude(module: &apos;commons-logging&apos;) &#125; compile group: &apos;commons-io&apos;, name: &apos;commons-io&apos;, version: &apos;2.5&apos; compile group: &apos;commons-codec&apos;, name: &apos;commons-codec&apos;, version: &apos;1.8&apos;&#125; 2:指明 quartz 配置文件这个是那个starter-quartz中的配置12quartz: properties-config-location: classpath:/config/application-quatrz.properties 3:配置 quartz就是从 quartz 中copy出来的 改成jdbc 存储12345678910111213141516171819org.quartz.scheduler.instanceName:DefaultQuartzSchedulerorg.quartz.scheduler.rmi.export:falseorg.quartz.scheduler.rmi.proxy:falseorg.quartz.scheduler.wrapJobExecutionInUserTransaction:falseorg.quartz.threadPool.class:org.quartz.simpl.SimpleThreadPoolorg.quartz.threadPool.threadCount:10org.quartz.threadPool.threadPriority:5org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread:trueorg.quartz.jobStore.misfireThreshold:60000#org.quartz.jobStore.class: org.quartz.simpl.RAMJobStore# jdbcorg.quartz.jobStore.class=org.quartz.impl.jdbcjobstore.JobStoreTXorg.quartz.jobStore.tablePrefix=QRTZ_org.quartz.jobStore.dataSource=qzDSorg.quartz.dataSource.qzDS.driver=com.mysql.jdbc.Driverorg.quartz.dataSource.qzDS.URL=jdbc:mysql://localhost:3306/ming?useUnicode=true&amp;characterEncoding=UTF-8org.quartz.dataSource.qzDS.user=rootorg.quartz.dataSource.qzDS.password=ming1234org.quartz.dataSource.qzDS.maxConnections=10 4:重头戏 代理job 使用spring bean 中定义的job先声明 这个是抄袭的 加上我自己的一点点想法原方案 只能支持spring bean 的 我扩展了一波 可使用groovy 来扩充配置、扩充bean前几个步骤都是集成进来 这一步 是将 quartz 的job 代理执行 使用注册在spring 中的job bean 执行 任务 方便管理 可以使用 groovy 动态注入配置,job 方便嵌入其他业务 如日志 等等4.1:继承spring中QuartzJobBean 实现基础的job抽象类通过建立抽象方法doExecute 将任务执行内容代理到实现这个抽象方法的job中 123456789101112131415161718192021222324252627282930313233343536import org.quartz.DisallowConcurrentExecution;import org.quartz.JobExecutionContext;import org.quartz.JobExecutionException;import org.quartz.PersistJobDataAfterExecution;import org.springframework.scheduling.quartz.QuartzJobBean;import java.io.Serializable;/** * 基础job 抽象类 * * @author ming * @date 2017-11-09 16:32 *///表示 Quartz 将会在成功执行 execute() 方法后（没有抛出异常）更新 JobDetail 的 JobDataMap，下一次执行相同的任务（JobDetail）将会得到更新后的值，而不是原始的值。@PersistJobDataAfterExecution//禁止 并发执行 job@DisallowConcurrentExecutionpublic abstract class BaseJob extends QuartzJobBean implements Serializable &#123; @Override protected void executeInternal(JobExecutionContext context) throws JobExecutionException &#123; doExecute(context); &#125; /** * 使用代理执行 * * @param context * @throws JobExecutionException * @author ming * @date 2017-11-09 16:08 */ protected abstract void doExecute(JobExecutionContext context) throws JobExecutionException;&#125; 4.2：建立代理执行类实现doExecute 方法第一 指定 job实例来源于spring 容器第二 可以插入其他业务 例如日志 之类的123456789101112131415161718192021222324252627282930313233343536373839/** * 代理执行 job 前后处理日志 * * @author ming * @date 2017-11-09 16:11 */@Slf4jpublic class ProxyJob extends BaseJob &#123; @Override protected void doExecute(JobExecutionContext context) throws JobExecutionException &#123; /* if (schedulerManageDao == null) &#123; schedulerManageDao = applicationContext.getBean(SchedulerManageDao.class); &#125;*/ // 执行 JobDetail jobDetail = context.getJobDetail(); String jobName = jobDetail.getKey().getName(); BaseProxyJob job; Date beginTime = new Date(); // Long dispatchId = schedulerManageDao.addDispatchLog(ApplicationConfig.SCHEDULER_CLUSTER_NAME, ApplicationConfig.SCHEDULER_INSTANCE_NAME, beginTime.getTime(), 0L, jobName, ScheduleExecuteLog.STATUS_BEGIN, 0L, &quot;&quot;); try &#123; job = SpringBeanManager.getbeanByNameAndType(jobName, BaseProxyJob.class); job.execute(); log.info(&quot;[执行成功]&quot; + jobName); Date endTime = new Date(); // 记录任务完成 //schedulerManageDao.updateDispatchLogById(dispatchId, ScheduleExecuteLog.STATUS_SUCCESS, endTime.getTime(), endTime.getTime() - beginTime.getTime(), null); &#125; catch (Exception e) &#123; log.error(&quot;[执行异常]&quot; + jobName + &quot;:::&quot; + e.getMessage()); Date endTime = new Date(); // 打印异常并发送异常 // String exceptionMessage = ExceptionUtils.getStackTrace(e); //logger.error(&quot;[doProcess][job(&#123;&#125;) 异常：&#123;&#125;]&quot;, jobName, exceptionMessage); //if (dispatchId != null) &#123; // schedulerManageDao.updateDispatchLogById(dispatchId, ScheduleExecuteLog.STATUS_FAILURE, endTime.getTime(), endTime.getTime() - beginTime.getTime(), exceptionMessage); //&#125; &#125; &#125;&#125; 4.3:建立基础代理job抽象类12345678910111213141516171819202122232425262728293031323334353637383940import lombok.extern.slf4j.Slf4j;/** * 定时器具体任务实现任务基类。所有子类需要继承它. * &lt;pre&gt; * 2. 使用&#123;@link #setMemo(String)&#125;可以设置任务结束后备注 * 3. 当任务出现异常时，会被记录到日志里并标记任务失败。所以任务的异常需要抛出来，不要catch掉不抛出。 * 4. 记得实现类加&#123;@link org.springframework.stereotype.Service&#125;注解，让它可以被spring扫描到 * &lt;/pre&gt; * * @author ming * @date 2017-11-09 16:32 */@Slf4jpublic abstract class BaseProxyJob &#123; /** * 任务执行完之后的备注 */ private String memo; /** * 实现 */ public abstract void execute(); public String getMemo() &#123; return memo; &#125; /** * 设置执行后备注 * * @param memo 备注 */ public void setMemo(String memo) &#123; this.memo = memo; &#125;&#125; 4.4:细分job类型这个是在上面的基础上继续细化job的来源类型方便针对不同的job来进行处理 例如 groovy 脚本写的抽象类 需要从数据库中读取相关数据 动态注入到spring 容器中所有的来自groovy 脚本的job抽象类12345678/** * groovy job 实现这个接口 * * @author ming * @date 2017-11-08 16:59 */public abstract class BaseScriptJob extends BaseProxyJob &#123;&#125; 所有直接java写的编译好的job抽象类123456789/** * java 实现的 实现这个接口 * * @author ming * @date 2017-11-08 16:59 */public abstract class BaseSimpleJob extends BaseProxyJob &#123;&#125; 具体demo请参考:http://github.xujiuming.com 下mingqz项目 ####总结:通过编写抽象类 将 具体要执行的业务 代理执行掉 这样 就可以利用spring 的特性 去用groovy 做动态job 避免每次变更 都要从新部署]]></content>
      <categories>
        <category>骚想法</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>quartz</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker配置daemon.json(加速、http访问私服仓库)]]></title>
    <url>%2Fming%2F3022b6f9.html</url>
    <content type="text"><![CDATA[daemon.jsondaemon.json 在linux下呢一般在/etc/docker/daemon.json 目录这个配置主要配置 docker守护进程的相关参数 例如代理、私服仓库、相关网络配置避免直接配置docker.service官方文档地址:https://docs.docker.com/engine/reference/commandline/dockerd/#examples参考国内博客:http://blog.51cto.com/nosmoking/1881034####常用配置1:aliyun的docker加速是可以个人申请一个加速节点的 以下是我自己的加速点做为实例当docker版本超过1.10的时候通过修改daemon配置文件/etc/docker/daemon.json来使用加速器：12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://o4omo0yw.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 2：配置私服仓库地址这个配置 可以避免私服仓库没有https访问导致无法使用的问题12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;insecure-registries&quot;:[&quot;&lt;private repository url&gt;&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker]]></content>
      <categories>
        <category>实战</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux操作文本相关命令笔记]]></title>
    <url>%2Fming%2F5e3a8086.html</url>
    <content type="text"><![CDATA[#####Linux下 操作文本命令太多了 cat echo tee sed等##sed:按行操作文本######sed命令是处理文本的工具 属于管道命令 以行为单位 进行操作文本文件sed [-nefri] ‘command’ ./filecommand 类似 vim的指令command123456a∶新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～c∶取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！d∶删除，因为是删除啊，所以 d 后面通常不接任何咚咚；i∶插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；p∶列印，亦即将某个选择的资料印出。通常 p 会与参数 sed -n 一起运作～s∶取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！ 1:删除123456# 删除第一行 sed &apos;1d&apos; ./file# 删除最后一行sed &apos;$d&apos; ./file# 删除 1 到最后一行sed &apos;1,$d&apos; ./file ######其他用法 参考 man sed]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables笔记]]></title>
    <url>%2Fming%2F5bcc860.html</url>
    <content type="text"><![CDATA[##iptables linux上常用防火墙参考地址：http://www.cnblogs.com/kevingrace/p/6265113.htmliptables 和netfilter关系netfilter 是linux内核中实现的包过滤的函数相关的东西iptables 是一个管理防火墙的工具 真正实现防火墙的还是netfilter语法iptables (选项) (参数)选项man iptables-t&lt;表&gt;：指定要操纵的表；-A：向规则链中添加条目；-D：从规则链中删除条目；-I：向规则链中插入条目；-R：替换规则链中的条目；-L：显示规则链中已有的条目；-F：清楚规则链中已有的条目；-Z：清空规则链中的数据包计算器和字节计数器；-X:删除规则链-N：创建新的用户自定义规则链；-P：定义规则链中的默认目标；-h：显示帮助信息；-p：指定要匹配的数据包协议类型；-s：指定要匹配的数据包源ip地址；-j&lt;目标&gt;：指定要跳转的目标；-i&lt;网络接口&gt;：指定数据包进入本机的网络接口；-o&lt;网络接口&gt;：指定数据包要离开本机所使用的网络接口。1iptables -t 表名 &lt;-A/I/D/R&gt; 规则链名 [规则号] &lt;-i/o 网卡名&gt; -p 协议名 &lt;-s 源IP/源子网&gt; --sport 源端口 &lt;-d 目标IP/目标子网&gt; --dport 目标端口 -j 动作 ####表名提供特定的功能|名称|功能|备注||:–|:–|:–||raw|数据跟踪处理|网址过滤||mangle|数据包修改，包重构|qds||nat|地址转换,网络地址转换|网关路由||filter|包过滤|防火墙规则| 链 名 名称 功能 备注 INPUT 输入数据包 对输入数据包的规则 OUTPUT 输出数据包 对输出数据包的规则 FORWARD 转发数据包 对转发数据的规则 PREROUTING 目标地址转换数据包 DANT POSTOUTING 源地址转换数据包 SNAT 表 和 链的关系图 ####动作 名称 功能 备注 ACCEPT 接受数据包 常用 打开某个端口接受数据 DROP 丢弃数据包 常用 禁止某个端口访问 MATCH 匹配 符合某个ip 或者端口 REJECT 丢弃数据包 可以向发送这个包的源主机发送错误消息 TARGET 指定动作 说明如何处理这个数据包 接受 丢弃 拒绝 JUMP 标识跳转到那个链上 RULE 一个或者多个匹配及其对应目标 REDIRECT 重定向、映射、透明代理 SNAT 源地址转换 DNAT 目标地址转换 MASQUERADE ip伪装 nat 用于adsl LOG 日志记录 ####实例 查看已有的iptables 规则 1234//查看iptables 列表 带数字 iptables -L -n -v //查看iptables 以序号标记iptables -L -n --line-numbers 清除已有的iptables 规则 123iptables -F --flush ：清楚规则链中已有的条目；iptables -X --delete-chain 删除 规则链iptables -Z --flush ：清空规则链中的数据包计算器和字节计数器； *删除 INPUT中的序号为num的规则1iptables -D INPUT num *开放指定端口 就是接受数据包123456789101112# 开启本地回环接口 运行本机访问本机iptables -A INPUT -s 127.0.0.1 -j ACCEPT # 允许已建立或相关连的通行iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT#允许本机所有向外访问iptables -A OUTPUT -j ACCEPT#允许 访问某个端口iptables -A INPUT -p tcp --dport 22 -j ACCEPT 允许访问 22端口# 禁止其他未允许的规则访问iptables -A INPUT -j reject# 禁止其他未允许的转发数据包访问iptables -A FORWARD -j reject 屏蔽ip 12345678# 屏蔽单个ipiptables -I INPUT -s 123.1.1.1 -j DROP# 屏蔽整个网段 123.0.0.0 - 123.255.255.254iptables -I INPUT -s 123.0.0.0/8 -j DROP# 屏蔽123.1.0.0 - 123.1.255.254网段iptables -I INPUT -s 123.1.0.0/16 -j DROP# 屏蔽 123.1.1.0 - 123.1.1.254网段iptables -i INPUT -s 123.1.1.0/24 -j DROP *]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot 自定义mvc MessageConverter 笔记]]></title>
    <url>%2Fming%2Fde4fca49.html</url>
    <content type="text"><![CDATA[指定前后端传输数据格式在前后分离项目中 最麻烦的应该就是 前后端工程师对接后端通过添加mvc消息转换器 返回更加符合前端的数据格式这个数据格式 不是说返回的格式 而是 某些类型的数据的处理 例如 date 可以转换成Long类型的时间戳返回直接继承实现即可 如果是继承WebMvcConfigurerAdapter 实现的mvc 相关配置 可以不用管 这样 它自己会添加到转换器链中如果是继承WebMvcConfigurationSupport 那么 需要重写configureMessageConverters() 手动添加到转换器链中1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 返回数数据格式转换器 * * @author ming * @date 2017-11-10 13:57 */public class MessageConverter extends AbstractHttpMessageConverter&lt;Object&gt; &#123; /** * date 转换为 时间戳 * * @author ming * @date 2017-11-10 13:56 */ ValueFilter filter = (obj, s, v) -&gt; &#123; if (v instanceof Date) &#123; return ((Date) v).getTime(); &#125; return v; &#125;; public MessageConverter() &#123; super(MediaType.ALL); &#125; @Override protected boolean supports(Class&lt;?&gt; clazz) &#123; return true; &#125; @Override protected Object readInternal(Class&lt;?&gt; aClass, HttpInputMessage httpInputMessage) throws IOException, HttpMessageNotReadableException &#123; return null; &#125; @Override public boolean canWrite(Class&lt;?&gt; clazz, MediaType mediaType) &#123; return this.supports(clazz) &amp;&amp; this.canWrite(mediaType); &#125; @Override protected void writeInternal(Object o, HttpOutputMessage httpOutputMessage) throws IOException &#123; FileCopyUtils.copy(JSON.toJSONString(o, filter, SerializerFeature.DisableCircularReferenceDetect).getBytes(), httpOutputMessage.getBody()); &#125;&#125; 这个只是返回数据中数据的类型的格式化 如果是要对返回数据格式进行格式化需要利用对ResponseBodyAdvice进行继承 进行控制器增强处理返回数据格式]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务端推送技术及其实现(轮询、长链接、sse、webSocket)]]></title>
    <url>%2Fming%2F3a488ac5.html</url>
    <content type="text"><![CDATA[前言服务端推送信息方案及其实现轮询 ：就是一直循环访问服务端 服务端压力比较大 利用js的一些定时功能 隔一段时间发起一次请求长轮询:一次请求 服务端吧请求保留 等由数据返回的时候 再返回 管理麻烦长链接 例如用iframe 维护长链接开销较大 而且页面会显示一直在加载 不利于使用flash socket:利用flash插件提供的socket 麻烦 需要会flash flash的缺点无法避免如安全WebSocket： html5技术 利用提供的html5本身特性来实现socket ws或者wss协议 现阶段几乎所有的浏览器最新版都支持 除开个别奇葩版本sse: server-sent event http协议变通实现的 通过服务端向客户端声明 接下来是要发送的是流信息 本质上就是完成一次耗时长的下载web socket服务端推送#####maven依赖1234567891011121314&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/javax.websocket/javax.websocket-api --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.websocket&lt;/groupId&gt; &lt;artifactId&gt;javax.websocket-api&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/javax.servlet/javax.servlet-api --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; #####页面代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;客户端&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt; &lt;input type=&quot;button&quot; id=&quot;bconnection&quot; value=&quot;链接&quot;&gt; &lt;input type=&quot;button&quot; id=&quot;bclose&quot; value=&quot;关闭&quot;&gt; &lt;input type=&quot;button&quot; id=&quot;bsend&quot; value=&quot;发送&quot;&gt; &lt;input type=&quot;text&quot; id=&quot;sessionId&quot; name=&quot;sessionId&quot;&gt; &lt;input type=&quot;text&quot; id=&quot;message&quot; name=&quot;message&quot;&gt; &lt;input type=&quot;button&quot; onclick=&quot;sendServlet()&quot; value=&quot;jdklsjlfs&quot;&gt;&lt;/div&gt;&lt;script src=&quot;http://apps.bdimg.com/libs/jquery/1.6.4/jquery.min.js&quot; type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; //模拟另外个客户向服务器发起推送消息服务 function sendServlet() &#123; $.get(&quot;http://localhost:8080/ws/sendServlet?sessionId=&quot;+$(&quot;#sessionId&quot;).val()+&quot;&amp;message=&quot;+$(&quot;#message&quot;).val()); &#125; //设立全局变量方便后续操作 var socket; //判断是否支持WebSocket if (typeof (WebSocket)==&quot;undefined&quot;)&#123; alert(&quot;浏览器不支持websocket&quot;); &#125; $(&quot;#bconnection&quot;).click(function () &#123; //实例化weosocket 制定服务器地址和端口 socket=new WebSocket(&quot;ws://localhost:8080/ws/websocket/xu&quot;); //打开链接 socket.onopen=function () &#123; console.log(&quot;打开weosocket端口&quot;); socket.send(&quot;客户端发送打开链接请求成功&quot;) &#125;; //获取消息事件 socket.onmessage=function (msg) &#123; console.log(&quot;获取的消息&quot;+msg.data); &#125;; //关闭socket socket.onclose=function () &#123; console.log(&quot;关闭socket&quot;); &#125;; //监听错误 socket.onerror=function () &#123; console.log(&quot;socket发生错误&quot;); &#125; &#125;); //发送消息 $(&quot;#bsend&quot;).click(function () &#123; socket.send(&quot;客户端消息:&quot;+location.href+new Date()); &#125;); //手动关闭socket $(&quot;#bclose&quot;).click(function () &#123; socket.close(); &#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; #####服务端代码 ######websocket链接类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.xxx.websocket;import javax.websocket.*;import javax.websocket.server.PathParam;import javax.websocket.server.ServerEndpoint;import java.io.IOException;import java.util.Date;import java.util.HashMap;import java.util.Map;import java.util.Scanner;/** * Created by xianyu on 17-3-7. * websocket 服务端响应 */@ServerEndpoint(&quot;/websocket/&#123;user&#125;&quot;)public class WebSocketService &#123; private String socketUser; //记录session列表 private static Map&lt;String ,Session&gt; sessionMap=new HashMap&lt;&gt;(); public static void sendMessage(String sessionId,String message)&#123; sessionMap.get(sessionId).getAsyncRemote().sendText(&quot;推送消息：&quot;+message); &#125; //打开socket链接的时候操作 @OnOpen public void onOpen(@PathParam(&quot;user&quot;)String user, Session session) throws IOException &#123; socketUser=user; System.out.println(&quot;链接打开账户为&quot;+user+&quot;sessionid为&quot;+session.getId()); sessionMap.put(session.getId(),session); session.getAsyncRemote().sendText(&quot;服务端成功接受链接;sessionId=&quot;+session.getId()); &#125; //接受消息的时候操作 @OnMessage public String onMessage(String message) &#123; System.out.println(socketUser+&quot;客户的消息&quot;+message); return socketUser+&quot;:&quot;+message; &#125; @OnError public void onError(Throwable t) &#123; t.printStackTrace(); &#125; @OnClose public void onClose(Session session, CloseReason reason) &#123; System.out.println(String.format(&quot;session id 为%s 用户为%s closeReason%s&quot;,session.getId(),socketUser,reason)); &#125;&#125; #####模拟发送服务端推送消息servlet1234567891011121314151617181920212223242526272829303132package com.xxx.websocket;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.util.Date;/** * Created by xianyu on 17-3-7. */public class SendServlet extends HttpServlet &#123; private String messagePrefix=&quot;servlet:&quot;; @Override public void init() throws ServletException &#123; &#125; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; WebSocketService.sendMessage(req.getParameter(&quot;sessionId&quot;),messagePrefix+req.getParameter(&quot;message&quot;)+&quot;||||||||||||&quot;+new Date()); &#125; @Override public void destroy() &#123; super.destroy(); &#125;&#125; 总结webscoket是现阶段实现服务端推送、在线聊天、等等需要使用tcp长链接的地比较合适的一个技术 现在市面上的浏览器最新版有不支持的websocket的 ws 和wss区别 相当于http和https区别一样]]></content>
      <categories>
        <category>实战</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>js</tag>
        <tag>服务端推送</tag>
      </tags>
  </entry>
</search>
